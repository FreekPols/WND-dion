---
downloads:
    - file: 1983-WND.pdf
---
# 1983: Van quark tot tipvane

![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-001.jpg?height=197&width=757&top_left_y=519&top_left_x=608)


![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-001.jpg?height=892&width=1268&top_left_y=1349&top_left_x=347)


## voorwoord

Voor U ligt het verslag van de 18 e 'Woudschoten'conferentie, onder de titel 'Van Quark tot Tipvane'. De conferentie was, zoals de titel al aangeeft, vooral gericht op belangwekkende ontwikkelingen in en rond de natuurkunde. Electronica, windturbines, ijktheorieën, filosofie en ioniserende straling passeerden de revue. Daardoor kreeg 'Woudschoten', anders dan in de voorgaande jaren, een sterk vakinhoudelijk karakter. De binding met de onderwijspraktijk werd gelukkig verzorgd door de vele werkgroepen, waarin nagenoeg alle aspecten van de lezingen weer aan bod kwamen.

Het belangrijkste gebeuren tijdens de conferentie was toch wel het aftreden van Herman Hooymayers en Hans Créton als voorzitter respectievelijk penningmeester van het werkgroepbestuur. Ten overvloede zij nogmaals vermeld, dat dit aftreden niet veroorzaakt wordt door twisten in het bestuur of door een slechte gezondheidstoestand van éën van beiden. De vele, aan hen gerichte, lovende woorden zijn in dit verslag vereeuwigd.
Het bestuur heeft inmiddels uit haar midden een nieuwe voorzitter gekozen in de persoon van Theo Wubbels. Het penningmeesterschap wordt overgenomen door Anne Holvast.
Het verslag omvat de teksten van de meeste lezingen, de verslagen van de werkgroepen, een stukje over de markt en een evaluatie. Prof.Dr.G. 't Hooft en Dr.Ir.J.Lohstroh waren helaas niet in de gelegenheid de letterlijke tekst van hun lezing op schrift te stellen. Van hen hebben we dan ook een artikel opgenomen, dat globaal de inhoud van de gehouden lezing omvat. De evaluatie is, traditiegetrouw, gebaseerd op korte gesprekjes die tijdens de conferentie met een aantal deelnemers gehouden zijn.
Graag wil ik iedereen bedanken die meegewerkt heeft aan het slagen van deze 'Woudschoten'conferentie: de inleiders, de voorzitter, de forumleden, de werkgroephouders, de mensen die de markt verzorgden en de studenten die de evaluatie voor hun rekening genomen hebben.
Inmiddels werkt het bestuur aan het opzetten van de komende 'Woudschoten'conferentie. De veelal gehoorde wens tot uitbreiding van de werkgroepen ten koste van het aantal lezingen zal daarbij helaas niet gehonoreerd kunnen worden. Het bestuur ziet waarschijnlijk geen kans het grote aantal werkgroepen, dat daarvoor nodig is bijeen te brengen. Wel zal zij wellicht enige aanpassingen doorvoeren, waardoor ook de plenaire zittingen aan levendigheid zullen winnen.
Een oproep om deel te nemen aan de activiteiten van de komende 'Woudschoten'conferentie kunt u te zijner tijd van ons verwachten.

P.A.J.Verhagen

## Programma
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-006.jpg?height=1281&width=1476&top_left_y=628&top_left_x=274)

*vrijdag,  16 december 1983*
|Tijd|Programma|
|:---:|:---:|
|13.30-14.40 uur| ontvangst deelnemers|
|14.40-14.50 uur| Opening door de voorzitter van de werkgroep Natuurkunde-Didactiek, Prof.Dr.H.P.Hooymayers|
|14.50-15.00 uur| Informatie over de confferentie door de conferentie-voorzitter. Dr.A.H. 't Hooft, rector van "Het Baarnsch Lyceum", te Baarn|
||BINNENKOMST LAATKOMERS|
|15.00-15.55 uur| Lezing 'Proefprojecten van het nationaal ontwikkelingsprogramma windenergie; organisatie en uitvoering door Ir.G.G.Piepers, Bureau Energie Onderozoek Projecten te Petten|
|15.55-16.25 uur| THEE|
|16.25-17.20 uur|Lezing  'Elementaire  deeltjes en het ijkprincipe' door Prof.Dr.G.'t  Hooft, hoogleraar Theoretische  Natuurkunde aan de  R.U.-Utrecht |
|17.20-17.30 uur | Informatie over de subgroepen en de markt|
|17.30-18.00 uur| aperitief|
|18:00-19.15 uur| DINER|
|19.30-21.00 uur|subgroepen|
|vanaf: 20.45 uur| markt|
|om: 21.15 uur| bar open|

*Zaterdag, 17 december 1983*
|Tijd|Programma|
|:---:|:---:|
| $8.00-9.00$ uur | ontbijt |
| $9.00-9.50$ uur | Lezing 'Natuurkunde, filosofie en onderwijs' door Prof.Dr.S.J.Doorman, hoogleraar in de wijsbegeerte aan de Technische Hogeschool te Delft |
| 9.50-10.40 uur | Lezing 'Ioniserende Straling, radioactiviteit en hun biologische gevolgen' door Prof.Dr.G.H. Barendsen, T.N.O., Radiobiologisch Instituut te Rijswijk/U.v.Amsterdam |
| 10.40-11.05 uur | KOFFIE |
| 11.05-12.30 uur | subgroep |
| 12.30-13.45 uur | LUNCH |
| 13.45-14.30 uur | Lezing 'Chips, wat zit erin en hoe werken ze' door Dr.Ir.J. Lohstroh, Natuurkundig Laboratorium, Philips te Eindhoven |
| 14.30-15.00 unr | THEE |
| 15.00-15.50 uur | Forumdiscussie, forumleden: Drs.H.F. van Aalst Drs.J. van Galen Drs.S. Masschelein Drs.A.v.d. Valk Dr.G. Verkerk |
|15.50-16.00 uur |Sluiting|

## plenaire bijeenkomsten

![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-007.jpg?height=724&width=1255&top_left_y=1281&top_left_x=546)

## Perspectieven voor windenergie 
Jr G. G. Piepers <br> BEOP/ECN Petten <br> HOLEC Ridderkerk 

### INLEIDING

Er is een grote hernieuwde belangstelling over de gehele wereld voor de mogelijkheden van de wind als energiebron. In vele landen, zoals de Verenigde Staten, het Verenigd Koninkrijk, Canada, Zweden, Denemarken, West-Duitsland, Nederland enz., worden door de overheid gefinancierde nationale onderzoeks- en ontwikkelingsprogramma's uitgevoerd. Het doel van al deze programma's is om de technische en economische haalbaarheid te onderzoeken van de introductie van de wind als energiebron ter vervanging van olie en aardgas. De wind, die voortdurend waait over de gehele wereld, bevat een ontzaglijke hoeveelheid kinetische energie. Wegens technische, economische en geografische beperkingen is echter maar een zeer klein deel hiervan winbaar. Hierdoor is de mogelijke bijdrage aan de totaal benodigde hoeveelheid energie, vooral in landen met een hoog gebruik per capita betrekkelijk gering. Voor landen met kleinere behoeften en met een afwijkende economische structuur kan de wind echter een essentiële energiebron zijn.
De wind als energiebron biedt enkele aantrekkelijke voordelen:

- de voorraad is onuitputtelijk
- de toevoer is onafhankelijk van politieke strubbelingen elders in de wereld
- er worden geen schadelijke afvalstoffen gevormd.

Er zijn echter enkele bezwaren die de toepassing in de hedendaagse samenleving belemmeren:

- De kinetische energie-inhoud van de bewegende lucht is per volume-eenheid zeer gering. Hierdoor zijn grote aantallen grote installaties nodig om een voldoende hoeveelheid bruikbare energie aan de wind te kunnen onttrekken.
- Er is veel ruimte nodig, omdat windmolens opgesteld moeten worden vrij van naburige obstakels, zoals hoge bomen en gebouwen.
- Het windaanbod varieert voortdurend op een bijna onvoorspelbare wijze en het vermogen van een windenergie-conversiesysteem is evenredig met de derde macht van de windsnelheid. De beschikbare hoeveelheid energie kan daardoor zeer sterk fluctueren, zowel in perioden van korte duur (uren) als in perioden van langere duur (dagen en weken).
In het algemeen is er een slechte aanpassing van vraag en aanbod van energie.

Een economische gebruik van windenergie is slechts mogelijk in combinatie met een opslagsysteem of in combinatie met een conventionele energiebron (dieselmotor, elektriciteitsnet) voor de opvang van windarme periodes. Dit betekent dat windvermogen in hoofdzaak gebruikt kan worden als bespaarder van fossiele brandstoffen en nauwelijks als vervanger van conventioneel vermogen, tenzij in combinatie met een geschikt opslagsysteem.

Windenergie-conversiesystemen kunnen op twee verschillende manieren worden toegepast, n.l. gecentraliseerd en gedecentraliseerd.
Bij de gecentraliseerde of grootschalige toepassing worden grote aantallen windmolens van grote afmetingen in groepen opgesteld om elektriciteit te produceren welke in het openbare net wordt gevoed. Er is dan geen opslagsysteem nodig omdat windarme periodes kunnen worden opgevangen door bijsturing van het vermogen van de conventionele elektriciteitscentrales. Deze zogenaamde windmolenparken of windcentrales kunnen zijn samengesteld uit 50 tot meer dan 100 windmolens met een nominaal vermogen van 1 tot 3 MW elk.
In het geval van gedecentraliseerde of kleinschalige toepassing van windenergie heeft de gebruiker van de energie de beschikking over zijn eigen windmolen. De capaciteit van de molen wordt zo goed mogelijk aangepast aan het jaarlijks energiegebruik van de eigenaar.
In bijna alle gevallen is echter een opslagsysteem of een conventionele energievoorziening nodig om de perioden met lage windsnelheden op te vangen.
Een aansluiting op het lokale elektriciteitsnet, of het gebruik van een dieselmotor in afgelegen en geissoleerde gebieden zijn geschikte leveranciers van de complementaire energie.

Het is duidelijk dat de windmolen dan voornamelijk dienst doet als bespaarder van fossiele brandstoffen. Het vermogen voor deze toepassing ligt tussen de 10 en enige honderden KW's. Potentiële toepassingsgebieden zijn:

- akkerbouwbedrijven
- tuinbouwbedrijven
- glastuinbouwbedrijven
- melkveehouderijen
- woongemeenschappen
- poldergemalen.

Vooral de energievoorziening van kleine woongemeenschappen in afgelegen gebieden zonder een aansluiting op een elektriciteitsnet biedt enorme mogelijkheden voor windenergie-conversiesystemen. Vanzelfsprekend moeten de windcondities gunstig zijn, maar dat zijn ze in vele streken van de Verenigde Staten, Canada,

Fig. 1
De 25 m HAT te Petten
Windmolen met een horizontale as
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-010.jpg?height=2362&width=1737&top_left_y=491&top_left_x=149)

Brazilië, de Antillen, de Sovjet Unie en in veel ontwikkelingslanden.
Meestal wordt windenergie dan gebruikt in aanvulling op, of als vervanging van energie welke wordt geleverd door dieselmotoren. Het transport van olie naar afgelegen plaatsen is tegenwoordig zeer duur. Zoals in de aanhef reeds is vermeld, wordt in veel landen een onderzoek-, ontwikkelings- en demonstratieprogramma uitgevoerd om de bestaande problemen, die samenhangen met de conversie van windenergie in een bruikbare vorm (elektriciteit of mechanische energie), op te lossen.
Hierbij kunnen drie probleemgebieden worden onderscheiden:

- Technisch: ontwerp, bouw en bedrijf van een betrouwbare, veilige windmolen met een gegarandeerde, voldoende lange, levensduur.
- Economisch: de kosten van windenergie.
- Planologisch: er is voldoende plaats om windmolens te plaatsen zonder in conflict te raken met andere belangen.


### TECHNIEK

Het hoofdprobleem bij het ontwerpen en bouwen van betrouwbare, veilige en betaalbare windmolens is de beheersing van de dynamische reactie op de voortdurend fluctuerende windbelasting. !!indmolens zijn eigenlijk ideale vermoeiingsmachines. Momenteel zijn er, met uitzondering van de kleinere types, nog geen windmolens verkrijgbaar waarvan de betrouwbaarheid op ondubbelzinnige wijze is aangetoond. De problemen nemen toe met de afmetingen van de rotorbladen. Van de verschillende types windmolens komen waarschijnlijk slechts twee basisontwernen in aanmerking voor een economische toepassing vanwege hun betrekkelijk. hoog rendement; de windmolen met horizontale as (fig. 1), welke de meeste overeenkomst vertoont met de oud Hollandse windmolen en de windmolen met verticale as, ook wel Darrieus-rotor genaamd (fig. 2). Beide typen hebben hun specifieke voordelen.
Er zijn geen revolutionaire uitvindingen te verwachten, die de opbrengst van windmolens van een bepaalde afmeting aanzienlijk zullen vergroten. Er is waarschijnlijk éën uitzondering en wel het idee van 'tipvanes'.
Tipvanes zijn kleine hulpvleugels, bevestigd aan het uiteinde van de rotorbladen. Zij vergroten de luchtstroom door het rotoroppervlak en kunnen het opgewekte vermogen per eenheid van het door de rotor bestreken oppervlak, met een factor drie tot vier doen toenemen.
De dynamische problemen van zeer grote rotoren kunnen worden vermeden door toepassing van de multi-windturbine. Deze bestaat uit een aantal kleinere rotoren die zijn bevestigd aan een gemeenschappelijke torenconstructie. Zo'n multi-rotor

Fig. 2
De Pionier I te Amsterdam
Windmolen met verticale as
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-012.jpg?height=2338&width=1730&top_left_y=483&top_left_x=187)
windmolen kan dezelfde hoeveelheid energie produceren als een windmolen met slechts éen rotor van grote afmetingen.
Een belangrijk technisch probleem is de omzetting van windenergie in elektriciteit die geschikt is voor de voeding in het openbare net. De opgewekte elektriciteit moet voldoen aan hoge eisen betreffende spanning en frequentie.
De eenvoudigste manier is de toepassing van een asynchrone generator. Het toerental van deze generator wordt constant gehouden door de verbinding met het elektriciteitsnet. Dit betekent echter tevens een constant toerental van de rotor, hetgeen aanleiding kan geven tot zeer hoge dynamische belastingen op het overbrengmechanisme (tandwielsysteem) als gevolg van windvlagen. Bovendien vraagt een asynchrone generator blindstroom, welke door het net moet worden geleverd. Een betere, maar tevens duurdere oplossing wordt verkregen door de windenergie om te zetten in gelijkstroom, welke vervolgens wordt geconverteerd in wisselstroom met behulp van een statische omzetter.

### ECONOMIE

Het is onmogelijk om in het algemeen de kosten aan te geven van een windenergieconversiesysteem. In het geval van de gecentraliseerde toepassing worden de kosten per geleverd kWh bepaald door de volgende factoren:

1. Kapitaalinvestering

Grote installaties zijn waarschijnlijk relatief het voordeligst. Tot nu toe zijn echter uitsluitend zeer dure prototypes gebouwd, waarvan de kosten variëren van 6.000 tot 25.000 gulden per geīnstalleerd kW generatorvermogen. Met deze getallen als uitgangspunt zijn kosten afgeleid voor grote, in serie gefabriceerde windmolens. Waarden variërende van 1.500 tot 3.000 gulden per geinstalleerde kW worden daarbij haalbaar geacht. Het is echter nog lang niet altijd duidelijk of de kosten voor fundaties en aanvullende elektrotechnische voorzieningen zoals kabels, schakel- en transformatorstations en kortsluitbeveiligingen zijn meegerekend. Tot nu toe zijn nog geen grote series gerealiseerd.

2. Bedrijfs- en onderhoudskosten

Het ontbreken van bewezen betrouwbaarheid bemoeilijkt de afleiding van realistische bedrijfs- en onderhoudskosten voor productie-eenheden uit de ervaringen met prototypes. Amerikaanse fabrikanten schatten de jaarlijkse exploitatiekosten op ongeveer $1 \%$ van de investeringen.

3. Lokale windcondities

Uitsluitend gebieden met een voldoend hoge gemiddelde jaarlijkse windsnelheid zijn van belang. Omdat het windvermogen evenredig is met de derde macht van de windsnelheid, is de geografische ligging van doorslaggevende betekenis voor de economische haalbaarheid.
4. De wijze waarop windcentrales kunnen worden ingepast in het totale systeem van elektriciteitscentrales

Dit vereist een grondige systeemanalyse door de elektriciteitsmaatschappijen, met als doel een optimale regelstrategie vast te stellen, welke leidt tot maximale besparingen aan fossiele brandstoffen en te installeren vermogens.

Bij de decentrale toepassing is een economische evaluatie nog veel ingewikkelder. De geldstroom van de eigenaar van een windmolen wordt beïnvloed door de volgende factoren:

1. Kapitaalinvestering

Er zijn verscheidene fabrikanten van windmolens in de reeks van 10 tot 100 KW . Zij kosten in de orde van 2.000 tot 4.000 gulden per geīnstalleerd KW aan generatorvermogen. De lagere prijs geldt voor de grotere molens. De betrouwbaarheid is echter in vele gevallen nog onvoldoende bewezen.
2. Bedrijfs- en inderhoudskosten Deze kosten lijken redelijk, maar de beschikbare gegevens zijn schaars en slechts geldig voor de eerste bedrijfsjaren.
3. Lokale windcondities

Deze zijn sterk afhankelijk van de geografische ligging. Ook plaatselijke obstakels of de gunstige invloed van hellingen van heuvels hebben een grote invloed op de opbrengst.
4. Het deel van de opgewekte energie dat door eigenaar nuttig kan worden aangewend. Dit is sterk afhankelijk van het energie gebruikspatroon.
5. De mogelijkheid om het restant van de geproduceerde elektriciteit te leveren aan het elektriciteitsbedrijf en de prijs die hiervoor wordt betaald.
6. De bestaande subsidieregelingen en belastingsfaciliteiten.

In Nederland is een terugverdientijd van 6 tot 8 jaar haalbaar onder de volgende aannames:

- huidige prijs (1984) van windmolens
- huidige prijs (1984) van de door de elektriciteitsmaatschappijen geleverde stroom
- gangbare bedrag dat de provinciale elektriciteitsmaatschappijen betalen voor het surplus aan elektriciteit (ca. $11 \mathrm{ct} / \mathrm{kWh}$ )
- gunstige windcondities (kuststreken en de IJsselmeerpolders)
- redelijke afstemming tussen energiebehoefte en energieproductie
- maximaal gebruik makend van de bestaande subsidieregelingen.

Op afgelegen en geīsoleerde plaatsen wordt de terugverdientijd gemakkelijk teruggebracht tot 2 à 3 jaar wegens de hoge kosten van het olietransport. Het is overigens best mogelijk dat de uiteindelijke beslissing om op grote schaal gebruik te maken van windenergie niet uitsluitend wordt bepaald door louter economische overwegingen. Niet eenvoudig te kwantificeren sociale en politieke factoren kunnen een belangrijke rol spelen, zoals de afwezigheid van afvalproblemen en het feit dat het windaanbod onafhankelijk is van de politieke situatie in de wereld.

### PLANOLOGIE

De keuze van geschikte vestigingsplaatsen is zeer belangrijk, omdat de economische haalbaarheid van windenergie-conversiesystemen in hoge mate afhankelijk is van de lokale windcondities.
Zoals in de inleidingen reeds is vermeld, vragen windmolens veel ruimte om voldoende energie aan de wind te kunnen onttrekken. Obstakels in hun omgeving moeten worden vermeden.
In Nederland is het vinden van geschikte lokaties niet eenvoudig vanwege de grote bevolkingsdichtheid. De nog schaarse open ruimtes worden bij voorkeur gereserveerd voor beschermde natuurgebieden of als landelijke bufferzones tussen verstedelijkte gebieden. Er zijn in Nederland geen gebieden meer op het land waar de plaatsing van grote aantallen grote windmolens mogelijk is zonder in conflict te geraken met andere gebruikers van de grond. Dit houdt in dat de overheid zeer zorgvuldig de verschillende economische en sociologische belangen tegen elkaar moet afwegen.
Omdat de mogelijkheden van plaatsing op het land beperkt zullen zijn is een studie uitgevoerd naar de installaties van windmolens op de Noordzee. Op zee is de gemiddelde windsnelheid hoger, zodat de energieproductie van de windmolens aanzienlijk toenaamt. De assemblage- en onderhoudskosten zijn echter ook veel hoger. Bovendien is de beschikbaarheid ook beperkt vanwege het intensieve internationale scheepvaartverkeer.

Bij de keuze naar geschikte lokaties moet ook rekening worden gehouden met de volgende factoren:

- Geluidshinder; in het algemeen valt het lawaai, veroorzaakt door aerodynamische goed ontworpen windmolens, binnen de geldende normen voor geluidshinder.
- Kans op ongelukken; dit heeft vooral betrekking op wegslingerende onderdelen bijvoorbeeld een blad dat bij hoog toerental afbreekt.
- Storing van televisieontvangst en andere telecommunicatiesystemen.
- Vogeltrek.
- Uitwendige vormgeving.
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-016.jpg?height=1308&width=900&top_left_y=1431&top_left_x=941)


### PERSPECTIEVEN

De kansen voor de fabrikanten van windenergiesystemen kunnen worden afgeleid van een ruwe schatting van het marktpotentieel.
De Europese markt is voornamelijk beperkt tot de kuststreken van Ierland, het Verenigde Koninkrijk, het noorden van Duitsland, de Scandinavische landen, Nederland en de Griekse eilanden. Tot nu toe is nog niet veel belangstelling getoond in België, Frankrijk en Portugal, hoewel daar goede mogelijkheden zijn. In het jaar 2000 zouden $z 0^{\prime}$ n 235.000 eenheden, in de vermogensreeks van 10 tot 100 kW geplaatst kunnen zijn, waarvan 60.000 in Ierland en 15.000 in Nederland. Volgens de energienota van de Nederlandse regering wordt gestreefd naar 2000 grote windmolens in het jaar 2000.
In de Verenigde Staten worden de volgende schattingen gehanteerd voor het jaar 2000:

Elektriciteitsbedrijven : 45.000 eenheden van ca. 1,5 MW
Land- en tuinbouw, veelteelt: 130.000 eenheden van ca. 35 kW
Woongemeenschappen : 1.500 .000 eenheden van ca. 10 kW
Genoemde getallen zijn echter alleen haalbaar als de huidige kostprijs van de windmolens een stuk lager komt te liggen (of de prijzen van olie en kolen flink stijgen) en bovendien de betrouwbaarheid van de installaties wordt verbeterd.

De mogelijkheden voor afgelegen en geīsoleerde gebieden in de windrijke streken over de gehele wereld, zijn waarschijnlijk nog veel groter, maar het noemen van aantallen heeft nog weinig zin in het huidige stadium van ontwikkeling.

## Gauge Theories of the Forces between Elementary Particles 

> All the basic forces of nature are now described by theories of this kind. The properties of the forces are deduced from symmetries or regularities apparent in the laws of physics

by Gerard 't Hooft

Aunderstanding of how the world is put together requires a theory of how the elementary particles of matter interact with one another. Equivalently, it requires a theory of the basic forces of nature. Four such forces have been identified, and until recently a different kind of theory was needed for each of them. Two of the forces, gravitation and electromagnetism, have an unlimited range; largely for this reason they are familiar to everyone. They can be felt directly as agencies that push or pull. The remaining forces, which are called simply the weak force and the strong force, cannot be perceived directly because their influence extends only over a short range, no larger than the radius of an atomic nucleus. The strong force binds together the protons and the neutrons in the nucleus, and in another context it binds together the particles called quarks that are thought to be the constituents of protons and neutrons. The weak force is mainly responsible for the decay of certain particles.
A long-standing ambition of physicists is to construct a single master theory that would incorporate all the known forces. One imagines that such a theory would reveal some deep connection between the various forces while accounting for their apparent diversity. Such a unification has not yet been attained, but in recent years some progress may have been made. The weak force and electromagnetism can now be understood in the context of a single theory. Although the two forces remain distinct, in the theory they become mathematically intertwined. What may ultimately prove more important, all four forces are now described by means of theories that have the same general form. Thus if physicists have yet to find a single key that fits all the known locks, at least all the needed keys can be cut from the same blank. The theories in this single favored class are formally designated non-Abelian gauge theories with local symmetry. What is meant by this for-
bidding label is the main topic of this article. For now, it will suffice to note that the theories relate the properties of the forces to symmetries of nature.

$S^{y}$ymmetries and apparent symmetries in the laws of nature have played a part in the construction of physical theories since the time of Galileo and Newton. The most familiar symmetries are spatial or geometric ones. In a snow. flake, for example, the presence of a symmetrical pattern can be detected at a glance. The symmetry can be defined as an invariance in the pattern that is observed when some transformation is applied to it. In the case of the snowflake the transformation is a rotation by 60 degrees, or one-sixth of a circle. If the initial position is noted and the snowflake is then turned by 60 degrees (or by any integer multiple of 60 degrees), no change will be perceived. The snowflake is invariant with respect to 60 -degree rotations. According to the same principle, a square is invariant with respect to 90 -degree rotations and a circle is said to have continuous symmetry because rotation by any angle leaves it unchanged.
Although the concept of symmetry had its origin in geometry, it is general enough to embrace invariance with respect to transformations of other kinds. An example of a nongeometric symmetry is the charge symmetry of electromagnetism. Suppose a number of electrically charged particles have been set out in some definite configuration and all the forces acting between pairs of particles have been measured. If the polarity of all the charges is then reversed, the forces remain unchanged.
Another symmetry of the nongeometric kind concerns isotopic spin, a property of protons and neutrons and of the many related particles called hadrons, which are the only particles responsive to the strong force. The basis of the symmetry lies in the observation that the proton and the neutron are remarkably similar particles. They differ in mass by
only about a tenth of a percent, and except for their electric charge they are identical in all other properties. It therefore seems that all protons and neutrons could be interchanged and the strong interactions would hardly be altered. If the electromagnetic forces (which depend on electric charge) could somehow be turned off, the isotopic-spin symmetry would be exact; in reality it is only approximate.
Although the proton and the neutron seem to be distinct particles and it is hard to imagine a state of matter intermediate between them, it turns out that symmetry with respect to isotopic spin is a continuous symmetry, like the symmetry of a sphere rather than like that of a snowflake. I shall give a simplified explanation of why that is so. Imagine that inside each particle are a pair of crossed arrows, one representing the proton component of the particle and the other representing the neutron component. If the proton arrow is pointing up (it makes no difference what direction is defined as up), the particle is a proton; if the neutron arrow is up, the particle is a neutron. Intermediate positions correspond to quantum-mechanical superpositions of the two states, and the particle then looks sometimes like a proton and sometimes like a neutron. The symmetry transformation associated with isotopic spin rotates the internal indicators of all protons and neutrons everywhere in the universe by the same amount and at the same time. If the rotation is by exactly 90 degrees, every proton becomes a neutron and every neutron becomes a proton. Symmetry with respect to isotopic spin, to the extent it is exact, states that no effects of this transformation can be detected.
All the symmetries I have discussed so far can be characterized as global symmetries; in this context the word global means "happening everywhere at once." In the description of isotopic-spin symmetry this constraint was made explicit: the internal rotation that transforms
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-019.jpg?height=2029&width=519&top_left_y=370&top_left_x=160)

FOUR BASIC FORCES mediate all known interactions among the particles of matter. The forces differ greatly in strength and effective range, but they are all described by theories of the same mathematical form, namely local gauge theories. Electromagnetism and gravitation are said to be of infinite range, although their influence declines as the square of the distance between two interacting particles. The weak force is confined to an exceedingly small range of about 10-15 centimeter. The properties of the strong force are somewhat more complicated. As the strong force is observed acting between hadrons, such as the proton and the neutron (solid colored line), it has a finite
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-019.jpg?height=2029&width=1047&top_left_y=370&top_left_x=741)
range of some $10^{-13}$ centimeter. The strong force also binds together the particles called quarks that make up hadrons, and in that context it could be expected to follow an inverse-square law (broken colored line). The actual behavior is apparently stranger: the force remains constant regardless of distance (dotted colored line). In quantum field theories (diagrams at left) the force between two particles is made manifest through the exchange of a third particle, which is called a virtual particle. The range of the force is determined by the mass of the exchanged virtual particle. Massless virtual particles, sucb as the photon and the graviton, give rise to forces that have infinite range.
protons into neutrons and neutrons into protons is to be carried out everywhere in the universe at the same time. In addition to global symmetries, which are al most always present in a physical theory, it is possible to have a "local" symmetry, in which the convention can be decided independently at every point in space and at every moment in time. Although "local" may suggest something of more modest scope than a global symmetry, in fact the requirement of local symmetry places a far more stringent constraint on the construction of a theory. A global symmetry states that some law of physics remains invariant when the same transformation is applied everywhere at once. For a local symmetry to be observed the law of physics must retain its validity even when a different transformation takes place at each point in space and time.
Gauge theories can be constructed with either a global or a local symmetry (or both), but it is the theories with local symmetry that hold the greatest interest today. In order to make a theory invariant with respect to a local transformation something new must be added: a force. Before showing how this comes about, however, it will be necessary to discuss in somewhat greater detail how forces are described in modern theories of elementary-particle interactions.

TThe basic ingredients of particle theory today include not only particles and forces but also fields. A field is simply a quantity defined at every point throughout some region of space and time. For example, the quantity might be temperature and the region might be the surface of a frying pan. The field then consists of temperature values for every point on the surface.

Temperature is called a scalar quantity, because it can be represented by position along a line, or scale. The corresponding temperature field is a scalar field, in which each point has associated with it a single number, or magnitude. There are other kinds of field as well, the most important for present purposes being the vector field, where at each point a vector, or arrow, is drawn. A vector has both a magnitude, which is represented by the length of the arrow, and a direction, which in three-dimensional space can be specified by two angles; hence three numbers are needed in order to specify the value of the vector. An example of a vector field is the velocity field of a fluid; at each point throughout the volume of the fluid an arrow can be drawn to show the speed and direction of flow.

In the physics of electrically charged objects a field is a convenient device for expressing how the force of electromagnetism is conveyed from one place to another. All charged particles are supposed to emanate an electromagnet-
ic field; each particle then interacts with the sum of all the fields rather than directly with the other particles.

In quantum mechanics the particles themselves can be represented as fields. An electron, for example, can be considered a packet of waves with some finite extension in space. Conversely, it is often convenient to represent a quantummechanical field as if it were a particle. The interaction of two particles through their interpenetrating fields can then be summed up by saying the two particles exchange a third particle, which is called the quantum of the field. For example, when two electrons, each surrounded by an electromagnetic field, approach each other and bounce apart, they are said to exchange a photon, the quantum of the electromagnetic field.

The exchanged quantum has only an ephemeral existence. Once it has been emitted it must be reabsorbed, either by the same particle or by another one, within a finite period. It cannot keep going indefinitely, and it cannot be detected in an experiment. Entities of this kind are called virtual particles. The larger their energy, the briefer their existence. In effect a virtual particle borrows or embezzles a quantity of energy, but it must repay the debt before the shortage can be noticed.

The range of an interaction is related to the mass of the exchanged quantum. If the field quantum has a large mass, more energy must be borrowed in order to support its existence, and the debt must be repaid sooner lest the discrepancy be discovered. The distance the particle can travel before it must be reabsorbed is thereby reduced and so the corresponding force has a short range. In the special case where the exchanged quantum is massless the range is infinite.
The number of components in a field corresponds to the number of quantummechanical states of the field quantum. The number of possible states is in turn related to the intrinsic spin angular momentum of the particle. The spin angular momentum can take on only discrete values; when the magnitude of the spin is measured in fundamental units, it is always an integer or a half integer. Moreover, it is not only the magnitude of the spin that is quantized but also its direction or orientation. (To be more precise, the spin can be defined by a vector parallel to the spin axis, and the projections, or components, of this vector along any direction in space must have values that are integers or half integers.) The number of possible orientations, or spin states, is equal to twice the magnitude of the spin, plus one. Thus a particle with a spin of one-half, such as the electron, has two spin states: the spin can point parallel to the particle's direction of motion or antiparallel to it. A spin-one particle has three orientations, namely parallel, antiparallel and trans-
verse. A spin-zero particle has no spin axis; since all orientations are equivalent, it is said to have just one spin state.

A scalar field, which has just one component (a magnitude), must be represented by a field quantum that also has one component, or in other words by a spin-zero particle. Such particles are therefore called scalar particles. Similarly, a three-component vector field requires a spin-one field quantum with three spin states: a vector particle. The electromagnetic field is a vector field, and the photon, in conformity with these specifications, has a spin of one unit. The gravitational field is a more complicated structure called a tensor and has 10 components; not all of them are independent, however, and the quantum of the field, the graviton, has a spin of two units, which ordinarily corresponds to five spin states.

In the cases of electromagnetism and gravitation one further complication must be taken into account. Since the photon and the graviton are massless, they must always move with the speed of light. Because of their velocity they have a property not shared by particles with a finite mass: the transverse spin states do not exist. Although in some formal sense the photon has three spin states and the graviton has five, in practice only two states can be detected.

TThe first gauge theory with local symmetry was the theory of electric and magnetic fields introduced in 1868 by James Clerk Maxwell. The foundation of Maxwell's theory is the proposition that an electric charge is surrounded by an electric field stretching to infinity, and that the movement of an electric charge gives rise to a magnetic field also of infinite extent. Both fields are vector quantities, being defined at each point in space by a magnitude and a direction.

In Maxwell's theory the value of the electric field at any point is determined ultimately by the distribution of charges around the point. It is often convenient, however, to define a potential, or voltage, that is also determined by the charge distribution: the greater the density of charges in a region, the higher its potential. The electric field between two points is then given by the voltage difference between them.

The character of the symmetry that makes Maxwell's theory a gauge theory can be illustrated by considering an imaginary experiment. Suppose a system of electric charges is set up in a laboratory and the electromagnetic field generated by the charges is measured and its properties are recorded. If the charges are stationary, there can be no magnetic field (since the magnetic field arises from movement of an electric charge); hence the field is purely an electric one. In this experimental situation a global symmetry is readily perceived:
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-021.jpg?height=1004&width=1188&top_left_y=416&top_left_x=163)
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-021.jpg?height=960&width=1650&top_left_y=1496&top_left_x=166)

CONCEPT OF A FIELD, a quantity defined at each point through out some region of space and time, is important in the construction of gauge theories. A scalar field has only a magnitude at each point; in this example the magnitude is given by the area of the dots. A vec tor field has both a magnitude and a direction and can be illustrated by drawing an arrow at each point A scalar field might represent a quantity such as the temperature or the density of a fluid, whereas a vector field could represent its velocity. In quantum field theories
the influence of a field can be embodied in a virtual particle. Tl: number of components in the field is reflected in the number of di tinct orientations of the particle, which in turn depends on its spin asigular momentum. A scalar field has just one component (its value can be given by a single number) and is represented by a spin-zero particle with one spin state, or orientation. A vector field in threcdimensional space has three components (a magnitude and two angles), and it corresponds to a spin-one particie with three spin states
the symmetry transformation consists in raising the entire laboratory to a high voltage, or in other words to a high electric potential. If the measurements are then repeated, no change in the electric field will be observed. The reason is that the field, as Maxwell defined it, is determined only by differences in electric potential, not by the absolute value of the potential. It is for the same reason that a squirrel can walk without injury on an uninsulated power line.

This property of Maxwell's theory amounts to a symmetry: the electric field is invariant with respect to the addition or subtraction of an arbitrary overall potential. As noted above, however, the symmetry is a global one, because the result of the experiment remains constant only if the potential is changed everywhere at once. If the potential were raised in one region and not in another, any experiment that crossed the boundary would be affected by the potential difference, just as a squirrel is affected if it touches both a power line and a grounded conductor.

A complete theory of electromagnetic fields must embrace not only static arrays of charges but also moving charges. In order to do that the global symmetry of the theory must be converted into a local symmetry. If the electric field were the only one acting between charged particles, it would not have a local symmetry. Actually when the charges are in motion (but only then); the electric field is not the only one present: the movement itself gives rise to a second field. namely the magnetic field. It is the effects of the magnetic field that restore the local symmetry.
Just as the electric field depends ultimately on the distribution of charges but can conveniently be derived from an electric potential, so the magnetic field is generated by the motion of the charges but is more easily described as resulting from a magnetic potential. It is in this system of potential fields that local transformations can be carried out leaving all the original electric and magnetic fields unaltered. The system of dual, interconnected fields has an exact local symmetry even though the electric field alone does not. Any local change in the electric potential can be combined with a compensating change in the magnetic potential in such a way that the electric and magnetic fields are invariant.

Maxwell's theory of electromagnetism is a classical or non-quantummechanical one, but a related symmetry can be demonstrated in the quantum theory of electromagnetic interactions. It is necessary in that theory to describe the electron as a wave or a field, a convention that in quantum mechanics can be adopted for any material particle. It turns out that in the quantum theory of
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-022.jpg?height=843&width=1099&top_left_y=344&top_left_x=700)

- ROTATION BY 90 DEGREES IN ABSTRACT INTERNAL SPACE
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-022.jpg?height=246&width=748&top_left_y=1318&top_left_x=799)

ISOTOPIC-SPIN SYMMETRY

SYMMETRIES OF NATURE determine the properties of forces in gauge theories. The familiar symmetry of a snowflake can be characterized by noting that the pattern is unchanged when it is rotated 60 degrees; the snowflake is said to be invariant with respect to such rotations. In physics nongeometric symmetries are introduced. Charge symmetry, for example, is the invariance of the forces acting among a set of charged particles when the polarities of all the charges are reversed. Isotopic-spin symmetry is based on the observation that little would be changed in the strong interactions of matter if the identities of all protons and neutrons were interchanged. Hence proton and neutron become merely the alternative states of a single particle, the nucleon, and transitions between the states can be made (or imagined) by adjusting the orientation of an indicator in an internal space. It is symmetries of this kind, where the transformation is an internal rotation or a phase shift, that are referred to as gauge symmetries.
electrons a change in the electric potential entails a change in the phase of the electron wave.

The electron has a spin of one-half unit and so has two spin states (parallel and antiparallel). It follows that the associated field must have two components. Each of the components must be represented by a complex number, that is, a number that has both a real, or ordinary, part and an imaginary part, which includes as a factor the square root of -1 . The electron field is a moving packet of waves, which are oscillations in the amplitudes of the real and the imaginary components of the field. It is important to emphasize that this field is not the electric field of the electron but instead is a matter field. It would exist even if the electron had no electric charge. What the field defines is the probability
of finding an electron in a specified spin state at a given point and at a given moment. The probability is given by the sum of the squares of the real and the imaginary parts of the field.

In the absence of electromagnetic fields the frequency of the oscillations in the electron field is proportional to the energy of the electron, and the wavelength of the oscillations is proportional to the momentum. In order to define the oscillations completely one additional quantity must be known: the phase. The phase measures the displacement of the wave from some arbitrary reference point and is usually expressed as an angle. If at some point the real part of the oscillation, say, has its maximum positive amplitude, the phase at that point might be assigned the value zero degrees. Where the real part next falls to
zero the phase is 90 degrees and where it reaches its negative maximum the phase is 180 degrees. In general the imaginary part of the amplitude is 90 degrees out of phase with the real part, so that whenever one part has a maximal value the other part is zero.

It is apparent that the only way to determine the phase of an electron field is to disentangle the contributions of the real and the imaginary parts of the amplitude. That turns out to be impossible, even in principle. The sum of the squares of the real and the imaginary parts can be known, but there is no way of telling at any given point or at any moment how much of the total derives from the real part and how much from the imaginary part. Indeed, an exact symmetry of the theory implies that the two contributions are indistinguishable. Differences in the phase of the field at two points or at two moments can be measured, but not the absolute phase.

The finding that the phase of an electron wave is inaccessible to measurement has a corollary: the phase cannot have an influence on the outcome of any possible experiment. If it did, that experiment could be used to determine the phase. Hence the electron field exhibits a symmetry with respect to arbitrary changes of phase. Any phase angle can be added to or subtracted from the electron field and the results of all experiments will remain invariant.

This principle can be made clearer by considering an example: the two-slit diffraction experiment with electrons, which is the best-known demonstration of the wavelike nature of matter. In the experiment a beam of electrons passes through two narrow slits in a screen and the number of electrons reaching a second screen is counted. The distribution of electrons across the surface of the second screen forms a diffraction pattern of alternating peaks and valleys.

The quantum-mechanical interpretation of this experiment is that the electron wave splits into two segments on striking the first screen and the two diffracted waves then interfere with each other. Where the waves are in phase the interference is constructive and many electrons are counted at the second screen; where the waves are out of phase destructive interference reduces the count. Clearly it is only the difference in phase that determines the pattern formed. If the phases of both waves were shifted by the same amount, the phase difference at each point would be unaffected and the same pattern of constructive and destructive interference would be observed.

It is symmetries of this kind, where the phase of a quantum field can be adjusted at will, that are called gauge symmetries. Although the absolute value of the phase is irrelevant to the outcome of experiments, in constructing a theory of
electrons it is still necessary to specify the phase. The choice of a value, which can be made as the theorist pleases, is called a gauge convention.

Gauge symmetry is not a very descriptive term for such an invariance, but the term has a long history and cannot now be dislodged. It was introduced in about 1920 by Hermann Weyl, who was then attempting to formulate a theory that would combine electromagnetism and the general theory of relativity. Weyl was led to propose a theory that remained invariant with respect to arbitrary dilatations or contractions of space. In the theory a separate standard of length and time had to be adopted at every point in space-time. He compared the choice of a scale convention to a choice of gage blocks; the polished steel blocks employed by machinists as a standard of length. The theory was nearly correct, the necessary emendation being to replace "length scales" by "phase angles." Writing in German, Weyl had referred to "Eich Invarianz," which was initially translated as "calibration invariance," but the alternative translation "gauge" has since become standard.

The symmetry of the electron matter field described above is a global symmetry: the phase of the field must be shifted in the same way everywhere at once. It can easily be demonstrated that a theory of electron fields alone, with no other forms of matter or radiation, is not invariant with respect to a corresponding local gauge transformation. Consider again the two-slit diffraction experiment with electrons. An initial experiment is carried out as before and the electron-diffraction pattern is recorded. Then the experiment is repeated, but one slit is fitted with the electron-optical equivalent of a half-wave plate, a device that shifts the phase of a wave by 180 degrees. When the waves emanating from the two slits now interfere, the phase difference between them will be altered by 180 degrees. As a result wherever the interference was constructive in the first experiment it will now be destructive, and vice versa. The observed diffraction pattern will not be unchanged; on the contrary, the positions of all the peaks and depressions will be interchanged.

Suppose one wanted to make the theory consistent with a local gauge symmetry. Perhaps it could be fixed in some way; in particular, perhaps another field could be added that would compensate for the changes in electron phase. The new field would of course have to do more than mend the defects in this one experiment. It would have to preserve the invariance of all observable quantities when the phase of the electron field was altered in any way from place to place and from moment to moment. Mathematically the phase shift must be
allowed to vary as an arbitrary function of position and time.
Although it may seem improbable, a field can be constructed that meets these specifications. It turns out that the required field is a vector one, corresponding to a field quantum with a spin of one unit. Moreover, the field must have infinite range, since there is no limit to the distance over which the phases of the electron fields might have to be reconciled. The need for infinite range implies that the field quantum must be massless. These are the properties of a field that is already familiar: the electromagnetic field, whose quantum is the photon.

How does the electromagnetic field ensure the gauge invariance of the electron field? It should be remembered that the effect of the electromagnetic field is to transmit forces between charged particles. These forces can alter the state of motion of the particles; what is most important in this context, they can alter the phase. When an electron absorbs or emits a photon, the phase of the electron field is shifted. It was shown above that the electromagnetic field itself exhibits an exact local symmetry; by describing the two fields together the local symmetry can be extended to both. of them.

The connection between the two fields lies in the interaction of the electron's charge with the electromagnetic field. Because of this interaction the propage. tion of an electron matter wave in an electric field can be described properly only if the electric potential is specified. Similarly, to describe an electron in a magnetic field the magnetic vector potential must be specified. Once these two potentials are assigned definite val. ues the phase of the electron wave is fixed everywhere. The local symmetry of electromagnetism, however, allows the electric potential to be given any arbitrary value, which can be chosen independently at every point and at every moment. For this reason the phase of the electron matter field can also take on any value at any point, but the phase will always be consistent with the convention adopted for the electric and the magnetic potentials.

What this means in the two-slit diffraction experiment is that the effects of an arbitrary shift in the phase of the electron wave can be mimicked by applying an electromagnetic field. For example, the change in the observed interference pattern caused by interposing a half-wave plate in front of one slit couid be caused instead by placing the sl:ts between the poles of a magnet. From tic resulting pattern it would be impossitle to tell which procedure had been fol. lowed. Since the gauge conventions for the electric and the magnetic potenti:ls can be chosen locally, so can the phase of the electron field.

The theory that results from combin-
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-024.jpg?height=858&width=1643&top_left_y=365&top_left_x=179)

GAUGE SYMMETRY OF ELECTROMAGNETISM is an invariance with respect to shifts in the phase of the matter field that represents an election. The phase itself cannot be measured, but it hisa an infuence on such observable quantities as the interference pattern formed when the waves of an electron field pass through a pair of slits. The peaks in this pattern are found wherever the waves are in phase, and the nodes are found where the waves are out of phase. A
shift in phase greatly alters the configuration of the field, but it leaves the observable interference pattern unchanged. The symmetry is an exact one, so that the phase shift cannot be detected. It is therefore only a matter of convention what phase is chosen in any theoretical description of the field. In the absence of forces acting between the electrons, however, the symmetry is a global one: the observed pat tern is invariant oaly if the same phase shift is applied everywhere.
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-024.jpg?height=852&width=832&top_left_y=1564&top_left_x=182)

LOCAL GAUGE SYMMETRX of the electron matter field is restored when magnetic fields are taken into account. Shifting the phase of one diffracted electron beam but not the other clearly alters the observed interference pattern (diagram at leff). The same effect can be obtained, however, by introducing a small magnetic field perpendicular to the electron beam and between the slits (diagram at right). Remarkably, the magnetic field Induces the phase shift even when shields are arranged so that the field cannot penetrate the region
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-024.jpg?height=857&width=843&top_left_y=1562&top_left_x=988)
where the electron waves propagate and interfere. An experimenter examining the interference patterns could not distinguish between the effects of a phase shift imposed arbitrarily on one electron beam and the effects of a magnetic field introduced between the slits. Any local shift in the phase of the electron matter field could therefore be reproduced by electric and magnetic fields, and so the phase of the electron field is arbitrary. The theory that combines electron matter fields with electric and magnetic fields is quantum electrodynamics.
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-025.jpg?height=865&width=842&top_left_y=394&top_left_x=157)

GAUGE SYMMETRY OF ELECTROMAGNETISM is an invariance with respect to shifts in the phase of the matter Gield that represents an electron. The phase itself cannot be measured, but it has an influence on such observable quantities as the interference pattern formed when the waves of an electron field pass through a pair of slits. The peaks in this pattern are found wherever the waves are in phase, and the nodes are found where the waves are out of phase. A
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-025.jpg?height=868&width=833&top_left_y=395&top_left_x=961)
shift in phase greatly alters the configuration of the field, but it leaves the observable interference pattern unchanged. The symmetry is an exact one, so that the phase shift cannot be detected. It is therefore only a matter of convention what phase is chosen in any theoretical description of the field. In the absence of forces acting between the electrons, however, the syimmetry is a global one: the observed pattern is invariant only if the same phase shift is applied everywhere.
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-025.jpg?height=853&width=871&top_left_y=1602&top_left_x=157)

LOCAL GAUGE SYMMETRY of the electron matter field is restored when magnetic fields are taken into account. Shifting the phase of one diffracted electron beam but not the other clearly alters the observed interference pattern (diagram at left). The same effect can be obtained, bowever, by introducing a small magnetic field perpendicular to the electron beam and between the slits (diagram at right). Remarkably, the magnetic field induces the phase shift even when shields are arranged so that the field cannot penetrate the region
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-025.jpg?height=850&width=829&top_left_y=1601&top_left_x=972)
where the electron waves propagate and interfere. An experimenter examining the interfereoce patterns could not distinguish between the effects of a phase shift imposed arbitrarily on one electron beam and the effects of a magnetic field introduced between the slits. Any local shift in the phase of the electron matter field could therefore be reproduced by electric and magnetic fields, and so the phase of the electron field is arbitrary. The theory that combines electron matter fieids with electric and magnetic fields is quantum electrodynamics.
ing electron matter fields with electromagnetic fields is called quantum electrodynamics. Formulating the theory and proving its consistency was a labor of some 20 years, begun in the 1920's by P. A. M. Dirac and essentially completed in about 1948 by Richard P. Feynman, Julian Schwinger, Sin-itiro Tomonaga and others.

TThe symmetry properties of quantum electrodynamics are unquestionably appealing, but the theory can be invested with physical significance only if it agrees with the results of experiments. Indeed, before sensible experimental predictions can even be made the theory must pass certain tests of internal consistency. For example, quantum-mechanical theories predict the probabilities of events: the probabilities must not be negative, and all the probabilities tak. en together must add up to 1 . In addition energies must be assigned positive values but should not be infinite.
It was not immediately apparent that quantum electrodynamics could qualify as a physically acceptable theory. One problem arose repeatedly in any attempt to calculate the result of even
the simplest electromagnetic interactions, such as the interaction between two electrons. The likeliest sequence of events in such an encounter is that one electron emits a single virtual photon and the other electron absorbs it. Many more complicated exchanges are also possible, however; indeed, the ir number is infinite. For example, the electrons could interact by exchanging two photons, or three, and so on. The total probability of the interaction is determined by the sum of the contributions of all the possible events.
Feynman introduced a systematic procedure for tabulating these contributions by drawing diagrams of the events in one spatial dimension and one time dimension. A notably troublesome class of diagrams are those that include "loops," such as the loop in space-time that is formed when a virtual photon is emitted and later reabsorbed by the same electron. As was shown above, the maximum energy of a virtual particle is limited only by the time needed for it to reach its destination. When a virtual photon is emitted and reabsorbed by the same particle, the distance covered and the time required can be reduced to

GLOBAL ISOTOPIC-SPIN ROTATION
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-026.jpg?height=457&width=1089&top_left_y=1403&top_left_x=153)

LOCAL ISOTOPIC-SPIN ROTATION
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-026.jpg?height=437&width=1082&top_left_y=1886&top_left_x=157)

ISOTOPIC-SPIN SYMMETRY serves as the basis of another gauge theory, first discussed in 1954 by C. N. Yang and Robert L. Mills. If isotopic-spin symmetry is valid, the choice of which position of the internal arrow indicates a proton and which a neutron is entirely a matter of convention. Global symmetry (upper diagram) requires the same convention to be adopted everywhere, and any rotation of the arrow must be made in the same way at every point. In the Yang-Mills theory isotopic spin is made a local symmetry (lower diagram), so that the orientation of the arrow is allowed to vary from place to place. In order to preserve the invariance of all observable quantities with respect to such local isotopic-spin transformations it is necessary to introduce at least six fields, corresponding to three massless vector particies, or vector bosons. One of these particles can be identified as the photon; the other two carry electric charge. The theory has been influential, but in its original form it was unrealistic. It makes protons and neutrons indistinguishable and predicts massless charged particles that do not exist.
zero, and so the maximum energy can be infinite. For this reason some diagrams with loops make an infinite contribution to the strength of the interaction.

The infinities encountered in quantum electrodynamics led initially to predictions that have no reasonable interpretation as physical quantities. Every interaction of electrons and photons was assigned an infinite probability. The infinities spoiled even the description of an isolated electron: because the electron can emit and reabsorb virtual particles it is found to have infinite mass and infinite charge.

The cure for this plague of infinities is the procedure called renormalization. Roughly speaking, it works by finding one negative infinity for each positive infinity, so that in the sum of all the possible contributions the infinities cancel. The achievement of Schwinger and of the other physicists who worked on the problem was to show that a finite residue could be obtained by this method. The finite residue is the theory's prediction. It is uniquely determined by the requirement that all interaction probabilities come out finite and positive.

The rationale of this procedure can be explained as follows. When a measurement is made on an electron, what is actually measured is not the mass or the charge of the pointlike particle with which the theory begins but the properties of the electron together with its enveloping cloud of virtual particles. Only the net mass and charge, the measurable quantities, are required to be finite at all stages of the calculation. The properties of the pointlike object, which are called the "bare" mass and the "bare" charge. are not well defined.

Initially it appeared that the bare mass would have to be assigned a value of negative infinity, an absurdity that made many physicists suspicious of the renormalized theory. A more careful analysis, however, has shown that if the bare mass is to have any definite value, it tends to zero. In any case all quantities with implausible values are unobservable, even in principle. Another objection to the theory is more profound: mathematically quantum electrodynamics is not perfect. Because of the methods that must be used for making predictions in the theory the predictions are limited to a finite accuracy of some hundreds of decimal places.

Clearly the logic and the internal consistency of the renormalization method leave something to be desired. Perhaps the best defense of the theory is simply that it works very well. It has yielded results that are in agreement with experiments to an accuracy of about one part in a billion, which makes quantum electrodynamics the most accurate physical theory ever devised. It is the model for theories of the
other fundamental forces and the standard by which such theories are judged.
At the time quantum electrodynamics was completed another theory based on a local gauge symmetry had already been known for some 30 years. It is Einstein's general theory of relativity. The symmetry in question pertains not to a field distributed through space and time but to the structure of space-time itself.
Every point in space-time can be labeled by four numbers, which give its position in the three spatial dimensions and its sequence in the one time dimension. These numbers are the coordinates of the event, and the procedure for assigning such numbers to each point in space-time is a coordinate system. On the earth, for example, the three spatial coordinates are commonly given as longitude, latitude and altitude; the time coordinate can be given in hours past noon. The origin in this coordinate system, the point where all four coordinates have values of zero, lies at noon at sea level where the prime meridian crosses the Equator.
The choice of such a coordinate system is clearly a matter of convention. Ships at sea could navigate just as successfully if the origin of the coordinate system were shifted to Utrecht in the Netherlands. Every point on the earth and every event in its history would have to be assigned new coordinates, but calculations made with those coordinates would invariably give the same results as calculations made in the old system. In particular any calculation of the distance between two points would give the same answer.
The freedom to move the origin of a
coordinate system constitutes a symmetry of nature. Actually there are three related symmetries: all the laws of nature remain invariant when the coordinate system is transformed by translation, by rotation or by mirror reflection. It is vital to note, however, that the symmetries are oniy global ones. Each symmetry transformation can be defined as a formula for finding the new coordinates of a point from the old coordinates. Those formulas must be applied simultaneously in the same way to all the points.

TThe general theory of relativity stems from the fundamental observation that the structure of space-time is not necessarily consistent with a coordinate system made up entirely of straight lines meeting at right angles; instead a curvilinear coordinate system may be needed. The lines of longitude and latitude employed on the earth constitute such a system, since they follow the curvature of the earth.

In such a system a local coordinate transformation can readily be imagined. Suppose height is defined as vertical distance from the ground rather than from mean sea level. The digging of a pit would then alter the coordinate system, but only at those points directly over the pit. The digging itself represents the local coordinate transformation. It would appear that the laws of physics (or the rules of navigation) do not remain invariant after such a transformation, and in a universe without gravitational forces that would be the case. An airplane set to fly at a constant height would dip suddenly when it flew over the excavation, and the accelerations
needed to follow the new profile of the terrain could readily be detected.
As in electrodynamics, local symmetry can be restored only by adding a new field to the theory; in general relativity the field is of course that of gravitation. The presence of this field offers an alternative explanation of the accelerations detected in the airplane: they could result not from a local change in the coordinate grid but from an anomaly in the gravitational field. The source of the anomaly is of no concern: it could be a concentration of mass in the earth or a distant object in space. The point is that any local transformation of the coordinate system could be reproduced by an appropriate set of gravitational fields. The pilot of the airplane could not distinguish one effect from the other.
Both Maxwell's theory of electromagnetism and Einstein's theory of gravitation owe much of their beauty to a local gauge symmetry; their success has long been an inspiration to theoretical physicists. Until recently theoretical accounts of the other two forces in nature have been less satisfactory. A theory of the weak force formulated in the 1930's by Enrico Fermi accounted for some basic features of the weak interaction, but the theory lacked local symmetry. The strong interactions seemed to be a jungle of mysterious fields and resonating particles. It is now clear why it took so long to make sense of these forces: the necessary local gauge theories were not understood.
The first step was taken in 1954 in a theory devised by C. N. Yang and Robert L. Mills, who were then at the Brookhaven National Laboratory. A similar idea was proposed independently at

ABELIAN TRANSFORMATION
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-027.jpg?height=228&width=1632&top_left_y=1821&top_left_x=174)

NON-ABELIAN TRANSFORMATION
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-027.jpg?height=220&width=843&top_left_y=2224&top_left_x=178)

EFFECTS OF REPEATED TRANSFORMATIONS distinguish quantum electrodynamics, which is an Abelian theory, from the YangMills theory, which is non-Abelian. An Abelian transformation is commutative: If two transformations are applied in succession, the outcome is the same no matter which sequence is chosen. An example is rotation in two dimensions. Non-Abelian transformations are not commutative, so that two transformations will generally yield differ-
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-027.jpg?height=210&width=775&top_left_y=2232&top_left_x=1041)
ent results if their sequence is reversed. Rotations in three dimensions exhibit this dependence on sequence. Quantum electrodynamics is Abelian in that successive phase shifts can be applied to an electron field without regard to the sequence. The Yang-Milk theory is non-Abelian because the net effect of two isotopic-spin rotations is generally different if the sequence of rotations is reversed. One sequence might yield a proton and the opposite sequence a neutron.
about the same time by R. Shaw of the University of Cambridge. Inspired by the success of the other gauge theories, these theories begin with an established global symmetry and ask what the consequences would be if it were made a local symmetry.

The symmetry at issue in the YangMills theory is isotopic-spin symmetry, the rule stating that the strong interac-
tions of matter remain invariant (or nearly so) when the identities of protons and neutrons are interchanged. In the global symmetry any rotation of the internal arrows that indicate the isotopicspin state must be made simultaneously everywhere. Postulating a local symmetry allows the orientation of the arrows to vary independently from place to place and from moment to moment. Ro-

UNBROKEN SYMMETRY

MASSLESS VECTOR BOSON
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-028.jpg?height=696&width=554&top_left_y=827&top_left_x=180)

BROKEN SYMMETRY

MASSIVE VECTOR BOSON
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-028.jpg?height=166&width=542&top_left_y=826&top_left_x=736)

$$
\therefore
$$

![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-028.jpg?height=380&width=550&top_left_y=1170&top_left_x=729)

GHOST OF MASSLESS SCALAR BOSON
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-028.jpg?height=577&width=1096&top_left_y=1659&top_left_x=181)

HIGGS MECHANISM can lend mass to the photonlike vector bosons of the Yang-Mills theory, thereby making the theory more realistic. The massless bosons have three possible spin orientations (parallel, antiparallel and transverse to the direction of motion), but only two of these are observable; the transverse state does not exist, a peculiarity of all massless particles, which move with the speed of light. If the Yang-Mills particles were to acquire a mass, the transverse state would become observable, and this added mode of motion must have some source. In the Higgs mechanism the source is an extra scalar field, corresponding to a massless spin-zero boson. The Yang-Mills particle is said to "eat" the Higgs boson, which thereupon becomes an unobservable "ghost." The Higgs field also provides a frame of reference (gray arrows) in which protons can be distinguished from neutrons. The arrow of the Higgs field rotates along with the other arrows in a gauge transformation, and so there is no absolute orientation, but the relative orientation of the isotopic-spin arrows can be measured with respect to the Higgs arrow. The symmetry of the theory, which without the Higgs mechanism would have abolished all differences between the proton and the neutron, has not been lost but only hidden.
tations of the arrows can depend on any arbitrary function of position and time. This freedom to choose different conventions for the identity of a nuclear particle in different places constitutes a local gauge symmetry.

As in other instances where a global symmetry is converted into a local one, the invariance can be maintained only if something more is added to the theory. Because the Yang-Mills theory is more complicated than earlier gauge theories it turns out that quite a lot more must be added. When isotopic-spin rotations are made arbitrarily from place to place, the laws of physics remain invariant only if six new fields are introduced. They are all vector fields, and they all have infinite range.

The Yang-Mills fields are constructed on the model of electromagnetism, and indeed two of them can be identified with the ordinary electric and magnetic fields. In other words; they describe the field of the photon. The remaining Yang-Mills fields can also be taken in pairs and interpreted as electric and magnetic fields, but the photons they describe differ in a crucial respect from the known properties of the photon: they are still massless spin-one particles, but they carry an electric charge. One photon is negative and one is positive.

TThe imposition of an electric charge on a photon has remarkable consequences. The photon is defined as the field quantum that conveys electromagnetic forces from one charged particle to another. If the photon itself has a charge, there can be direct electromag. netic interactions among the photons. To cite just one example, two photons with opposite charges might bind together to form an "atom" of light. The familiar neutral photon never interacts with itself in this way.
The surprising effects of charged photons become most apparent when a local symmetry transformation is applied more than once to the same particle. In quantum electrodynamics, as was pointed out above, the symmetry operation is a local change in the phase of the elec. tron field, each such phase shift being accompanied by an interaction with the electromagnetic field. It is easy to imagine an electron undergoing two phase shifts in succession, say by emitting a photon and later absorbing one. Intuition suggests that if the sequence of the phase shifts were reversed, so that first a photon was absorbed and later one was emitted, the end result would be the same. This is indeed the case. An unlimited series of phase shifts can be made, and the final result will be simply the algebraic sum of all the shifts no matter what their sequence.
In the Yang-Mills theory, where the symmetry operation is a local rotation of the isotopic-spin arrow, the result of
multiple transformations can be quite different. Suppose a hadron is subjected to a gauge transformation, $A$, followed soon after by a second transformation, $B$ : at the end of this sequence the isotop-ic-spin arrow is found in the orientation that corresponds to a proton. Now suppose the same transformations were applied to the same hadron but in the reverse sequence: $B$ followed by $\boldsymbol{A}$. In general the final state will not be the same; the particle may be a neutron instead of a proton. The net effect of the two transformations depends explicitly on the sequence in which they are applied.

Because of this distinction quantum electrodynamics is called an Abelian theory and the Yang-Mills theory is called a non-Abelian one. The terms are borrowed from the mathematical theory of groups and honor Niels Henrik Abel, a Norwegian mathematician who lived in the early years of the 19 th century. Abelian groups are made up of transformations that, when they are applied one after another, have the commutative property; non-Abelian groups are not commutative.

Commutation is familiar in arithme-
tic as a property of addition and multiplication, where for any numbers $A$ and $B$ it can be stated that $A+B=B+A$ and $A \times B=B \times A$. How the principle can be applied to a group of transformations can be illustrated with a familiar example: the group of rotations. All possible rotations of a two-dimensional object are commutative, and so the group of such rotations is Abelian. For instance, rotations of +60 degrees and -90 degrees yield a net rotation of -30 degrees no matter which is applied first. For a three-dimensional object free to rotate about three axes the commutative law does not hold, and the group of three-dimensional rotations is nonAbelian. As an example, consider an airplane heading due north in level flight. A 90 -degree yaw to the left followed by a 90 -degree roll to the left leaves the airplane heading west with its left wing tip pointing straight down. Reversing the sequence of transformations, so that a 90 -degree roll to the left is followed by a 90 -degree left yaw, puts the airplane in a nose dive with the wings aligned on the north-south axis.

Like the Yang-Mills theory, the gen-
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-029.jpg?height=937&width=1091&top_left_y=1371&top_left_x=140)

WEINBERG-SALAM-WARD MODEL incorporates electromagnetism and the weak force in a local gauge theory. The model applies to the interactions of the particles called leptons, which include the electron ( $e^{-}$), the muon ( $\mu^{-}$) and two kinds of neutrino ( $\nu_{e}$ and $\nu_{\mu}$ ). A requirement that the interactions of these particles remain invariant with respect to local transformations of a leptonic equivalent of isotopic spin gives rise to four massless fields. Three of these fields are then given a mass through the Higgs mechanism; they become the intermediate vector bosons $\boldsymbol{W}^{+}, \boldsymbol{W}^{-}$and $\boldsymbol{Z}^{\circ}$. The fourth vector boson is the photon. Three of the Higgs particles are eaten by the vector bosons and become ghosts, but a fourth is left over and should be observable. The theory does not truly unify the electromagnetic forces and the weak forces because the photon is still in a family of its own. A theory proposed by Howard Georgi and Slieldon Lee Glashow suggested a more profound unification, where the photon and the massive vector bosons were in the same family, but that theory is now contradicted by experiment.
eral theory of relativity is non-Abelian: in making two successive coordinate transformations, the order in which they are made usually has an effect on the outcome. In the past 10 years or so several more non-Abelian theories have been devised, and even the electromag. netic interactions have been incorporated into a larger theory that is non-Abelian. For now, at least, it seems all the forces of nature are governed by nonAbelian gauge theories.

TThe Yang-Mills theory has proved to be of monumental importance, but as it was originally formulated it was totally unfit to describe the real world. A first objection to it is that isotopic-spin symmetry becomes exact, with the result that protons and neutrons are indistinguishable; this situation is obviously contrary to fact. Even more troubling is the prediction of electrically charged photons. The photon is necessarily massless because it must have an infinite range. The existence of any electrically charged particle lighter than the electron would alter the world beyond recognition. Of course, no such particle has been observed. In spite of these difficulties the theory has great beauty and philosophical appeal. One strategy adopted in an attempt to fix its defects was to artificially endow the charged field quanta with a mass greater than zero.
Imposing a mass on the quanta of the charged fields does not make the fields disappear, but it does confine them to a finite range. If the mass is large enough, the range can be made as small as is wished. As the long-range effects are removed the existence of the fields can be reconciled with experimental observations. Moreover, the selection of the neutral Yang-Mills field as the only real long-range one automatically distinguishes protons from neutrons. Since this field is simply the electromagnetic field, the proton and the neutron can be distinguished by their differing interactions with it, or in other words by their differing electric charges.

With this modification the local symmetry of the Yang-Mills theory would no longer be exact but approximate, since rotation of the isotopic-spin arrow would now have observable consequences. That is not a fundamental objection: approximate symmetries are quite commonplace in nature. (The bilateral symmetry of the human body is only approximate.) Moreover, at distance scales much smaller than the range of the massive components of the Yang-Mills field, the local symmetry becomes better and better. Thus in a sense the microscopic structure of the theory could remain locally symmetric, but not its predictions of macroscopic, observable events.

The modified Yang-Mills theory was easier to understand, but the theory still
had to be given a quantum-mechanical interpretation. The problem of infinities turned out to be severer than it had been in quantum electrodynamics, and the standard recipe for renormalization would not solve it. New techniques had to be devised.

An important idea was introduced in 1963 by Feynman: it is the notion of a "ghost" particle, a particle added to a theory in the course of a calculation that vanishes when the calculation is finished. It is known from the outset that the ghost particle is fictitious, but its use can be justified if it never appears in the final state. This can be ensured by mak. ing certain the total probability of producing a ghost particle is always zero.

Among theoretical groups that continued work on the Yang-Mills theory the ghost-particle method was taken seriously only at the University of Utrecht, where I was then a student. Martin J. G. Veltman, my thesis adviser, together with John S. Bell of the European Organization for Nuclear Research (CERN) in Geneva, was led to the conclusion that the weak interac. tions might be described by some form of the Yang-Mills theory. He undertook a systematic analysis of the renormalization problem in the modified YangMills model (with massive charged fields), examining each class of Feynman diagrams in turn. The diagrams having no closed loops were readily

HADRONS
HADRONS
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-030.jpg?height=1336&width=1096&top_left_y=1010&top_left_x=138)

NEUTRAL ELECTROMAGNETIC CURRENT
NEUTRAL WEAK CURRENT
NEUTRAL WEAK CURRENTS provide the decisive test of the Weinberg-Salam-Ward model. It once appeared that all weak interactions involved a transfer of electric charge between the interacting particles; these events could be explained by just two intermediate vector bosons, the $\boldsymbol{W}$ - and the $\boldsymbol{w}$-. Events in which no charge was transferred were characteristic of electromagnetic interactions, where the exchanged virtual particle is a photon. The Weinberg-Salam-Ward model predicts that weak interactions can also proceed without charge transfer; these neutral weak curreats are mediated by the neutral boson $Z^{0}$, which is identical with the photon except that it has a very large mass. Neutral weak currents were first observed in 1973.
shown to make only finite contributions to the total interaction probability. The diagrams with one loop do include infinite terms, but by exploiting the properties of the ghost particles it was possible to make the positive infinities and the negative ones cancel exactly.

As the number of loops increases, the number of diagrams rises steeply; moreover, the calculations required for each diagram become more intricate. To assist in the enormous task of checking all the two-loop diagrams a computer program was written to handle the algebraic manipulation of the probabilities. The output of the program is a list of the coefficients of the infinite quantities remaining after the contributions of all the diagrams have been summed. If the infinities are to be expunged from the theory, the coefficients must without exception be zero. By. 1970 the results were known and the possibility of error had been excluded; some infinities remained.

The failure of the modified Yang. Mills theory was to be blamed not on any defect in the Yang-Mills formulation itself but rather on the modifications. The masses of the charged fields had to be put in "by hand" and as a result the invariance with respect to local isotopic-spin rotations was not quite . perfect. It was suggested at the time by the Russian investigators L. D. Faddeev, V. N. Popov, E. S. Fradkin and I. V. Tyutin that the pure Yang-Mills theory, with only massless fields, could indeed be renormalized. The trouble with this theory is that it not only is unrealistic but also has long-range fields that are difficult to work with.

In the meantime another new ingredient for the formulation of gauge theories had been introduced by F. Englert and Robert H. Brout of the University of Brussels and by Peter Higgs of the University of Edinburgh. They found a way to endow some of the Yang-Mills fields with mass while retaining exact gauge symmetry. The technique is now called the Higgs mechanism.

The fundamental idea of the Higgs mechanism is to include in the theory an extra field, one having the peculiar property that it does not vanish in the vacuum. One usually thinks of a vacuum as a space with nothing in it, but in physics the vacuum is defined more precisely as the state in which all fields have their lowest possible energy: For most fields the energy is minimized when the value of the field is zero everywhere, or in other words when the field is "turned off." An electron field, for example, has its minimum energy when there are no electrons. The Higgs field is unusual in this respect. Reducing it to zero costs energy; the energy of the field is smallest when the field has some uniform value greater than zero.

The effect of the Higgs field is to pro-
vide a frame of reference in which the orientation of the isotopic-spin arrow can be determined. The Higgs field can be represented as an arrow superposed on the other isotopic-spin indicators in the imaginary internal space of a hadron. What distinguishes the arrow of the Higgs field is that it has a fixed length, established by the vacuum value of the field. The orientation of the other iso-topic-spin arrows can then be measured with respect to the axis defined by the Higgs field. In this way a proton can be distinguished from a neutron.

It might seem that the introduction of the Higgs field would spoil the gauge symmetry of the theory and thereby lead again to insoluble infinities. In actuality, however, the gauge symmetry is not destroyed but merely concealed. The symmetry specifies that all the laws of physics must remain invariant when. the isotopic-spin arrow is rotated in an arbitrary way from place to place. This implies that the absolute orientation of the arrow cannot be determined; since any experiment for measuring the orientation would have to detect some variation in a physical quantity when the arrow was rotated. With the inclusion of the Higgs field the absolute orientation of the arrow still cannot be determined because the arrow representing the Higgs field also rotates during a gauge transformation. All that can be measured is the angle between the arrow of the Higgs field and the other isotopic-spin arrows, or in other words their relative orientations.

The Higgs mechanism is an example of the process called spontaneous symmetry breaking, which was already well established in other areas of physics. The concept was first put forward by Werner Heisenberg in his description of ferromagnetic materials. Heisenberg pointed out that the theory describing a ferromagnet has perfect geometric symmetry in that it gives no special distinction to any one direction in space. When the material becomes magnetized, however, there is one axis-the direction of magnetization-that can be distinguished from all other axes. The theory is symmetrical but the object it describes is not. Similarly, the Yang-Mills theory retains its gauge symmetry with respect to rotations of the isotopic-spin arrow, butt the objects described-protons and neutrons-do not express the symmetry.

How does the Higgs mechanism lend mass to the quanta of the Yang-Milis field? The process can be explained as follows. The Higgs field is a scalar quantity, having only a magnitude, and so the quantum of the field must have a spin of zero. The Yang-Mills fields are vectors, like the electromagnetic field, and are represented by spin-one quanta. Ordinarily a particle with a spin of one unit has three spin states (oriented parallel, antiparallel and transverse to its direc-
tion of motion), but because the YangMills particles are massless and move with the speed of light they are a special case; their transverse states are missing. If the particles were to acquire a mass, they would lose this special status and all three spin states would have to be observable. In quantum mechanics the accounting of spin states is strict and the extra state must come from somewhere; it comes from the Higgs field. Each Yang-Mills quantum coalesces with one Higgs particle; as a result the Yang-Mills particle gains mass and a spin state, whereas the Higgs particle disappears. A picturesque description of this process has been suggested by Abdus Salam of the International Center for Theoretical Physics in Trieste: the massless Yang-Mills particles "eat" the Higgs particles in order to gain weight, and the swallowed Higgs particles become ghosts.

$\mathrm{I}^{\mathrm{n}}$n 1971, Veltman suggested that I inI vestigate the renormalization of the pure Yang-Mills theory. The rules for constructing the needed Feynman diagrams had already been formulated by Faddeev, Popov, Fradkin and Tyutin, and independently by Bryce $S$. DeWitt of the University of Texas at Austin and Stanley Mandelstam of the University of California at Berkeley. I could adapt to the task the powerful methods for renormalization studies that had been developed by Veltman.
Formally the results were encouraging, but if the theory was to be a realistic one, some means had to be found to confine the Yang-Mill's fields to a finite range. I had just learned at a summer school how Kurt Symanzik of the German Electron Synchrotron and Benjamin W. Lee of the Fermi National Accelerator Laboratory had successfully handled the renormalization of a theoretical model in which a global symmetry is spontaneously broken. It therefore seemed natural to try the Higgs mechanism in the Yang-Mills theory, where the broken symmetry is a local one.

A few simple models gave encouraging results: in these selected instances all infinities canceled no matter how many gauge particles were exchanged and no matter how many loops were included in the Feynman diagrams. The decisive test would come when the theory was checked by the computer program for infinities in all possible diagrams with two loops. The results of that test were available by July, 1971; the output of the program was an uninterrupted string of zeros. Every infinity canceled exactly. Subsequent checks showed that infinities were also absent even in extremely complicated Feynman diagrams. My results were soon confirmed by others, notably by Lee and by Jean Zinn-Justin of the Saclay Nuclear Research Center near Paris.

The Yang-Mills theory had begun as a model of the strong interactions, but by the time it had been renormalized interest in it centered on applications to the weak interactions. In 1967 Steven Weinberg of Harvard University and independently (but later) Salam and John C. Ward of Johns Hopkins University had proposed a model of the weak interactions based on a version of the YangMills theory in which the gauge quanta take on mass through the Higgs mechanism. They speculated that it might be possible to renormalize the theory, but they did not demonstrate it. Their ideas therefore joined many other untested conjectures until some four years later, when my own results showed it was just that subclass of Yang-Mills theories incorporating the Higgs mechanism that can be renormalized.

The most conspicuous trait of the weak force is its short range: it has a significant influence only to a distance of $10^{-16}$ centimeter, or roughly a hundredth the radius of a proton. The force is weak largely because its range is so short: particles are unlikely to approach each other closely enough to interact. The short range implies that the virtual particles exchanged in weak interactions must be very massive. Present estimates run to between 80 and 100 times the mass of the proton.

The Weinberg-Salam-Ward model actually embraces both the weak force and electromagnetism. The conjecture on which the model is ultimately founded is a postulate of local invariance with respect to isotopic spin; in order to preserve that invariance four photonlike fields are introduced, rather than the three of the original Yang-Mills theory. The fourth photon could be identified with some primordial form of electromagnetism. It corresponds to a separate force, which had to be added to the theory without explanation. For this reason the model should not be called a unified field theory. The forces remain distinct; it is their intertwining that makes the model so peculiar.

At the outset all four of the fields in the Weinberg-Salam-Ward model are of infinite range and therefore must be conveyed by massless quanta; one field carries a negative electric charge, one carries a positive charge and the other two fields are neutral. The spontaneous symmetry breaking introduces four Higgs fields, each field represented by a scalar particle. Three of the Higgs fields are swallowed by Yang-Mills particles, so that both of the charged Yang-Mills particles and one of the neutral ones take on a large mass. These particles are collectively named massive intermediate vector bosons, and they are designated $W^{+}, W^{-}$and $Z^{0}$. The fourth YangMills particle, which is a neutral one, remains massless: it is the photon of electromagnetism. Of the Higgs parti-
cles, the three that lend-mass to the Yang-Mills particles become ghosts and are therefore unobservable, but the last Higgs particle is not absorbed, and it should be seen if enough energy is available to produce it.
The most intriguing prediction of the model was the existence of the $Z^{0}$, a particle identical with the photon in all respects except mass, which had not been included in any of the earlier, provisional accounts of the weak force. Without the $Z^{0}$ any weak interaction would necessarily entail an exchange of electric charge. Events of this kind are called charged-weak-current events. The $Z^{0}$ introduced a new kind of weak interaction, a neutral-weak-current event. By exchanging a $Z^{0}$, particles would interact without any transfer of charge and could retain their original identities. Neutral weak currents were first observed in 1973 at CERN.

The elaboration of a successful gauge theory of the strong interactions, which are unique to hadrons, could not be undertaken until a fundamental fact about the hadrons was understood: they are not elementary particles. A model of hadrons as composite objects was proposed in 1963 by Murray Gell-Mann of the California Institute of Technology; a similar idea was introduced independently and at about the same time by Yuval Ne'eman of Tel Aviv University and George Zweig of Cal Tech. In this model hadrons are made up of the smaller particles Gell-Mann named quarks. A hadron can be built out of quarks according to either of two blueprints. Combining three quarks gives rise to a baryon, a class of hadrons that includes the proton and the neutron. Binding together one quark and one antiquark makes a meson, a class typified by the pions. Every known hadron can be accounted for as one of these allowed combinations of quarks.

In the original model there were just three kinds of quark, designated "up," "down" and "strange." James D. Bjorken of the Stanford Linear Accelerator Center and Sheldon Lee Glashow of Harvard soon proposed adding a fourth quark bearing a property called charm. In 1971 a beautiful argument by Glashow, John Iliopoulos of Paris and Luciano Maiani of the University of Rome showed that a quark with charm is needed to cure a discrepancy in the gauge theory of weak interactions. Charmed quarks, it was concluded, must exist if both the gauge theory and the quark theory are correct. The discovery in 1974 of the $J$ or psi particle, which consists of a charmed quark and a charmed antiquark, supported the Weinberg-SalamWard model and persuaded many physicists that the quark model as a whole should be taken seriously. It now appears that at least two more "flavors," or

FERMIONS (SPIN = $1 / 2$ )

 SCALAR PARTICLES (SPIN $=0$

NONE
QUARK MODEL describes all hadrons, including the proton and the neutron, as being composite particles made up of the smaller entities called quarks. In the original form of the model the quarks were assumed to come in three "flavors," labeled $u, d$ and $s$, each of which is now said to have three possible "colors," red, green and blue. There are also antiquarks with the corresponding anticolors cyan, magenta and yellow. The interactions of the quarks are now de scribed by means of a gauge theory based on invariance with respect to local transformations of color. Sixteen fields are needed to hold this invariance. They are taken in pairs to make up eight massless vector bosons, called gluons, each bearing a combination of color and anticolor.
kinds, of quark are needed; they have been labeled "top" and "bottom."

The primary task of any theory of the strong interactions is to explain the peculiar rules for building hadrons out of quarks. The structure-of a meson is not too difficult to account for: since the me son consists of a quark and an antiquark, it is merely necessary to assume that the quarks carry some property analogous to electric charge. The binding of a quark and an añtiquark would then be explained on the principle that opposite charges attract, just as they do in the hydrogen atom. The structure of the baryons, however, is a deeper enigma. To explain how three quarks can form a bound state one must assume that three like charges attract.
The theory that has evolved to explain the strong force prescribes exactly these interactions. The analogue of electric charge is a property called color (although it can have nothing to do with the colors of the visible spectrum). The term color was chosen because the rules for forming hadrons can be expressed succinctly by requiring all allowed com binations of quarks to be "white," or colorless. The quarks are assigned the primary colors red, green and blue; the antiquarks have the complementary "anticolors" cyan, magenta and yellow Each of the quark flavors comes in all three colors, so that the introduction of the color charge triples the number of distinct quarks.

From the available quark pigments there are two ways to create white: by mixing all three primary colors or by mixing one primary color with its complementary anticolor. The baryons are made according to the first scheme: the three quarks in a baryon are required to
have different colors, so that the three primary hues are necessarily represented. In a meson a color is always accom panied by its complementary anticolor
The theory devised to account for these baffling interactions is modeled directly on quantum electrodynamics and is called quantum chromodynam ics. It is a non-Abelian gauge theory. The gauge symmetry is an invariance with respect to local transformations of quark color.

It is easy to imagine a global color symmetry. The quark colors, like the isotopic-spin states of hadrons, might be indicated by the orientation of an arrow in some imaginary internal space. Successive rotations of a third of a turn would change a quark from red to green to blue and back to red again. In a bary on, then, there would be three arrows, with one arrow set to each of the three colors. A global symmetry transforma tion, by definition, must affect all three arrows in the same way and at the same time. For example, all three arrows might rotate clockwise a third of a turn. As a result of such a transformation all three quarks would change color, but all observable properties of the hadron would remain as before. In particular there would still be one quark of each color, and so the baryon would remain colorless.

Quantum chromodynamics requires that this invariance be retained even when the symmetry transformation is a local one. In the absence of forces or interactions the invariance is obviously lost. Then a local transformation can change the color of one quark but leave the other quarks unaltered, which would give the hadron a net color. As in other gauge theories, the way to restore the
invariance with respect to local symmetry operations is to introduce new fields. In quantum chromodynamics the fields needed are analogous to the electromagnetic field but are much more complicated; they have eight times as many components as the electromagnetic field has. It is these fields that give rise to the strong force.

TThe quanta of the color fields are called gluons (because they glue the quarks together). There are eight of them, and they are all massless and have a spin angular momentum of one unit. In other words, they are massless vector bosons like the photon. Also like the photon the gluons are electrically neutral, but they are not color-neutral. Each gluon carries one color and one anticolor. There are nine possible combinations of a color and an anticolor, but one of them is equivalent to white and is excluded, leaving eight distinct gluon fields.
The gluons preserve local color sym-
metry in the following way. A quark is free to change its color, and it can do so independently of all other quarks, but every color transformation must be accompanied by the emission of a gluon, just as an electron can shift its phase only by emitting a photon. The gluon, propagating at the speed of light, is then absorbed by another quark, which will have its color shifted in exactly the way needed to compensate for the origina! change. Suppose, for example, a red quark changes its color to green and in the process emits a gluon that bears the colors red and antigreen. The gluon is then absorbed by a green quark, and in the ensuing reaction the green of the quark and the antigreen of the gluon annihilate each other, leaving the second quark with a net color of red. Hence in the final state as in the initial state there is one red quark and one green quark. Because of the continual arbitration of the gluons there can be no net change in the color of a hadron, even though the quark colors vary freely from point to
point. All hadrons remain white, and the strong force is nothing more than the system of interactions needed to maintain that condition.
In spite of the complexity of the gluon fields, quantum electrodynamics and quantum chromodypamics are remarkably similar in form. Most notably the photon and the gluon are identical in their spin and in their lack of mass and electric charge. It is curious, then, that the interactions of quarks are very different from those of electrons.
Both electrons and quarks form bound states, namely atoms for the electrons and hadrons for the quarks. Electrons, however, are also observed as independent particles; a small quantity of energy suffices to isolate an electron by ionizing an atom. An isolated quark has never been detected. It seems to be impossible to ionize a hadron, no matter how much energy is supplied. The quarks are evidently bound so tightly that they cannot be pried apart; paradoxically, however, probes of the in-
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-033.jpg?height=1123&width=1640&top_left_y=1328&top_left_x=145)

COLOR SYMMETEY requires that every badron remain white, or colorless, even when the colors of its constituent quarks have been altered. The color of a quark can be indicated by the position of an arrow in an imaginary internal space. Global symmetry is easily achieved. If a hadron initially consists of three quarks, one in each of the three colors, then any synchronized rotation of all three of the arrows must leave the overall balance of the colors unchanged. In the absence of forces between the quarks, however, the global symmetry cannot be
converted into a local symmetry. Changiag the postion of one color arrow while leaving the other two arrows fired gives the hadron a net color. In order to preserve the local color symmetry, forces must be introduced. In particular when the color of one quark is changed, a virtual particle must be emitted that will readjust the colors of the other quarks so that the hadron as a whole will remain colorless. The fields that are required to ensure the colorlessness of all the hadrons are the eight gluon fields of quantum chromodynamics.
ternal structure of hadrons show the quarks moving freely, as if they were not bound at all.
Gluons too have not been seen directly in experiments. Their very presence in the theory provokes objections like those raised against the pure, massless Yang-Mills theory. If massless particles that so closely resemble the photon existed, they would be easy to detect and they would have been known long ago. Of course, it might be possible to give the gluons a mass through the Higgs mechanism. With eight gluons to be concealed in this way, however, the project becomes rather cumbersome. Moreover, the mass would have to be large or the gluons would have been produced by now in experiments with high-energy accelerators; if the mass is large, however, the range of the quarkbinding force becomes toठ small.

Atentative resolution of this quandary has been discovered not by modifying the color fields but by examining their properties in greater detail. In discussing the renormalization of quantum electrodynamics I pointed out that even an isolated electron is surrounded by a cloud of virtual particles, which it constantly emits and reabsorbs. The virtual particles include not only neutral ones, such as the photon, but also pairs of oppositely charged particles, such as electrons and their antiparticles, the positrons. It is the charged virtual particles. in this cloud that under ordinary circumstances conceal the "infinite" negative bare charge of the electron. In the vicinity of the bare charge the elec-tron-positron pairs become slightly polarized: the virtual positrons; under the attractive influence of the bare charge, stay closer to it on the average than the virtual electrons, which are repelled. As a result the bare charge is partially neutralized; what is seen at long range is the difference between the bare charge and the screening charge of the virtual positrons. Only when a probe approaches to within less than about $10^{-10}$ centimeter do the unscreened effects of the bare charge become significant.

It is reasonable to suppose the same process would operate among color charges, and indeed it does. A red quark is enveloped by pairs of quarks and antiquarks, and the antired charges in this cloud are attracted to the central quark. and tend to screen its charge. In quantum chromodynamics, however, there is a competing effect that is not present in quanium electrodynamics. Whereas the photon carries no electric charge and therefore has no direct influence on the screening of electrons, gluons do bear a color charge. (This distinction expresses the fact that quantum electrodynamics is an Abelian theory and quantum chromodynamics is a non-Abelian one.) - Virtual gluon pairs also form a cloud
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-034.jpg?height=543&width=1094&top_left_y=328&top_left_x=699)

EXCHANGE OF GLUONS maintains a baryon (made up of three quarks) or a meson (made up of a quark and an antiquark) coloriess. In this process the total color of the particles is conserved. For example, a red quark can be converted into a green quark only by emitting a gluon that bears the color red and the anticolor magenta; the magenta can be interpreted as antigreen. Hence the red of the quark is carried off by the red of the gluon, and green and antigreen are created in equal quantities. If the gluon is absorbed by a green quark, the green of the quark and the antigreen of the gluon annihilate each other, leaving the second quark with the color red.
around a colored quark, but it turns out that the gluons tend to enhance the color charge rather than attenuate it. It is as if the red component of a gluon were attracted to a red quark and therefore added its charge to the total effective charge. If there are no more than 16 flavors of quark (and at present only six are known), the "antiscreening" by gluons is the dominant influence.
This curious behavior of the gluons follows from rather involved calculations, and the interpretation of the results depends on how the calculation was done. When I calculate it, I find that the force responsible is the color analogue of the gluon's magnetic field. It is also significant, however, that virtual
gluons can be emitted singly, whereas virtual quarks always appear as a quark and an antiquark. A single gluon, bearing a net color charge, enhances the force acting between two other color charges.

As a result of this "antiscreening" the effective color charge of a quark grows larger at long range than it is close by. A distant quark reacts to the combined fields of the central quark and the reinforcing gluon charges; at close range, once the gluon cloud has been penetrated, only the smaller bare charge is effective. The quarks in a hadron therefore act somewhat as if they were connected by rubber bands: at very close range, where the bands are slack, the quarks
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-034.jpg?height=483&width=1094&top_left_y=1760&top_left_x=693)

POLARIZATION OF THE VACUUM explains to some extent the peculiar force law that seems to allow quarks complete freedom of movement within a bindron but forbids the isolation of quarlos or gluons. In quantum electrodynamics (left) pairs of virtual electrons and antielectrons surround any isolated charge, such as an electron. Beconse of electrostatic forces the positively charged antielectrons tend to remain nearer the nevitive deletion charge and thereby cancel part of it. The observed electron charge is the difference between the "bare" charge and the screening charge of virtual antielectrons. Similarly, paiss of virteal quarlos diminish the strength of the force between a real quark and a real antiquark. In quantua chromodynamics, however, there is a competing effect not found in quantum electrodynamies. Because the gluon also has a color charge (whereas the photon has no electric charge), virtual gluons also have an influence on the magnitude of the color force between quarks. The gluons do not screen the quark charge but enhance it. As a result the color charge is weak and the quarks move freely as long as they are close. At long range infinite energy may be needed to separate two quarks.
move almost independently, but at a greater distance, where the bands are stretched taut, the quarks are tightly bound.

The polarization of virtual gluons leads to a reasonably precise account of the close-range behavior of quarks. Where the binding is weak, the expected motion of the particles can be calculated successfully. The long-range interactions, and most notably the failure of quarks and gluons to appear as free particles, can probably be attributed to the same mechanism of gluon antiscreening. It seems likely that as two color charges are pulled apart the force between them grows stronger indefinitely, so that infinite energy would be needed to create a macroscopic separation. This phenomenon of permanent quark confinement may be linked to certain special mathematical properties of the gauge theory. It is encouraging that permanent confinement has indeed been found in some highly simplified models of the theory. In the full-scale theory all methods of calculation fail when the forces become very large, but the principle seems sound. Quarks and gluons may therefore be permanently confined in hadrons.
If the prevailing version of quantum
chromodynamics turns out to be correct, color symmetry is an exact symmetry and the colors of particles are completely indistinguishable. The theory is a pure gauge theory of the kind first proposed by Yang and Mills. The gauge fields are inherently long-range and formally are much like the photon field. The quantum-mechanical constraints on those fields are so strong, however, that the observed interactions are quite unlike those of electromagnetism and even lead to the imprisonment of an entire class of particles.

Even where the gauge theories are right they are not always useful. The calculations that must be done to predict the result of an experiment are tedious, and except in quantum electrodynamics high accuracy can rarely be attained. It is mainly for practical or technical reasons such as these that the problem of quark confinement has not been solved. The equations that describe a proton in terms of quarks and gluons are about as complicated as the equations that describe a nucleus of medium size in terms of protons and neutrons. Neither set of equations can be solved rigorously.

In spite of these limitations the gauge
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-035.jpg?height=355&width=993&top_left_y=1430&top_left_x=168)
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-035.jpg?height=497&width=1089&top_left_y=1794&top_left_x=163)

GRAVITON (SPIN = 2)
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-035.jpg?height=62&width=65&top_left_y=2321&top_left_x=606)
STANDARD MODRi of elementary-particle interactions describes the four forces of nature by means of three aden-Abelian gauge theories. The fundamental particles of matter are six leptons and six flavors ef eark, each of the flavors being present in three colors. Electromngnetism and the weak force are mediated by the gauge particles of the Weinberg-Salam-Ward model, namely the massless photon and a triplet of very massive vector bosons, the $\mathbf{W}^{+}, \mathrm{W}^{-}$ and $2^{\circ}$. The strong force is attributed to the eight massless gluons of quantum chromodynamics. Gravitation results from the exchange of a massless spin-two particle, the graviton, which is described by another local gauge theory: the general theory of relativity. In addition there is one surviving Higgs particle, which is massive and electrically neutral. In the coming years the search for the massive vector bosons and the Higes particle will serve as tests of this synthesis.
theories have made an enormous contribution to the understanding of elementary particles and their interactions. What is most significant is not the philosophical appeal of the principle of local symmetry, or even the success of the individual theories. Rather it is the growing conviction that the class of theories now under considertation includes all possible theories for any system of particles whose mutual interactions are not too strong. Experiment shows that if particles remain closer together than about $10^{-14}$ centimeter, their total interaction, including the effects of all forces whether known or not, is indeed small. (The quarks are a special case: although the interactions between them are not small, those interactions can be attributed to the effects of virtual particles, and the interactions of the virtual particles are only moderate.) Hence it seems reasonable to attempt a systematic fitting of the existing gauge theories to experimental data.

TThe mathematics of the gauge theories is rigid, but it does leave some freedom for adjustment. That is, the predicted magnitude of an interaction between particles depends not only on the structure of the theory but also. on the values assigned to certain free parameters, which must be considered constants of nature. The theory remains consistent no matter what choice is made for these constants, but the experimental predictions depend strongly on what values are assigned to the constants. Although the constants can be measured by doing experiments, they can never be derived from the theory. Examples of such constants of nature are the charge of the electron and the masses of elementary particles such as the electron and the quarks.

The strength of the gauge theories is that they require comparatively few such free parameters: about 18 constants of nature must be supplied to account for all the known forces. The tangled phenomena of the strongly interacting particles, which seemed incomprehensible 15 years ago, can now be unraveled by means of a theory that includes only a handful of free parameters. Among these all but three are small enough to be safely ignored.
Even if the free parameters have been reduced to a manageable number, they remain an essential part of the theory. No explanation can be offered of why they assume the values they do. The fundamental questions that remain unanswered by the gauge theories center on these apparent constinats of nature. Why do the quarks and the other elementary particles have the masses they do? What determines the mass of the Higgs particle? What determines the fundamental unit of electric charge or the strength of the color force? The answers to such questions cannot come from the existing
gauge theories but only from a more comprehensive theory.

In the search for a larger theory it is natural to apply once more a recipe that has already proved successful. Hence the obvious program is to search for global symmetries and explore the consequences of making them local symmetries. This principle is not a necessary one, but it is worth trying. Just as Maxwell's theory combined electricity and magnetism and the Weinberg-SalamWard model linked electromagnetism and the weak force, so perhaps some larger theory could be found to embrace both the Weinberg-Salam-Ward model and quantum chromodynamics. Such a theory might in principle be constructed on the model of the existing gauge theories. A more sweeping symmetry of nature must be found; making this symmetry a local one would then give rise to the strong force, the weak force and electromagnetism. In the bargain yet more forces, exceedingly weak and so far unobserved, may be introduced.

Work on such theories is proceeding, and it has lately concentrated on symmetries that allow transformations between quarks and leptons, the class of particles that includes the electron. It is my belief the schemes proposed so far are not convincing. The grand symmetry they presuppose must be broken in order to account for the observed disparities among the forces, and that requires several Higgs fields. The resulting theory has as many arbitrary constants of nature as the less comprehensive the-
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-036.jpg?height=1320&width=900&top_left_y=250&top_left_x=967) ories it replaces.
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-036.jpg?height=750&width=1041&top_left_y=1978&top_left_x=188)

A quite different and more ambitious approach to unification has recently been introduced under the terms "super symmetry" and "supergravity." It gath ers into a single category particles with various quantities of angular momentum; up to now particles with different spins were always assigned to separate categories. The utility of the supersymmetric theories has yet to be demonstrated, but they hold much promise. They offer a highly restrictive description of some hundreds of particles, including the graviton, in terms of only a few adjustable parameters. So far the results do not much resemble the known physical world, but that was also true of the first Yang-Mills theory in 1954
The form of unification that has been sought longest and most ardently is a reconciliation of the various quantum field theories with the general theory of relativity. The gravitational field seems to lead inevitably to quantized theories that cannot be renormalized. At extremely small scales of distance ( $10^{-33}$ centimeter) and time (10-44 second) quantum fluctuations of space-time itself become important, and they call into question the very meaning of a space-time continuum. Here lie the present limits not merely of gauge theo ries but of all known physical theories.

## Natuurkunde, Filosofie en Onderwijs 

 Prof dir S.J. Doorman
### INLEIDING

In deze voordracht wil ik proberen iets te zeggen over twee vragen, te weten:
a) Kunnen ontwikkelingen in de natuurkunde gevolgen hebben voor onze filosofische opvattingen?
b) Zo ja, hebben dergelijke gevolgen consequenties voor het natuurkunde-onderwijs?
Mijn antwoord op de eerste vraag zal bevestigend luiden. Ik wijs erop dat zulks eigenlijk merkwaardig is. Doorgaans hebben filosofische theorieën en opvattingen een zodanig abstract en conceptueel karakter dat het nauwelijks plausibel schijnt te zijn om te veronderstellen dat wetenschappelijke opvattingen over de werkelijkheid in verband gebracht kunnen worden met filosofische speculaties. Indien filosofen echter hun ambacht zó zien, dat filosofische opvattingen voldoende formeel precies onder woorden gebracht moeten worden om weerlegging van die opvattingen in beginsel mogelijk te maken, dan kan soms een vruchtbare botsing ontstaan tussen enerzijds een empirisch verkregen resultaat, anderzijds een filosofische these, die een diepliggende intuitie over onze voorstellingswijze van de werkelijkheid belichaamt.
In de filosofie van de wiskunde kunnen zowel het Logicisme van Frege als het Formalisme van Hilvert genoemd worden als filosofische posities over de aard van wiskundige kennis, die in een buitengewoon nauwkeurig geformuleerd onderzoeksprogramma konden worden vastgelegd, waardoor vervolgens de onhoudbaarheid van de posities aan het licht trad ${ }^{1}$. Wij zullen zien, dat iets soortgelijks mogelijk is met betrekking tot een bepaalde filosofische zienswijze over de aard van empirisch wetenschappelijke kennis.

1) Het bedoelde programma zag er voor het Logicisme aldus uit: Definieer alle wiskundige basisbegrippen in zuiver logische termen en laat vervolgens zien, dat wiskundige stellingen na vertaling overgaan in logische stellingen. Toen dit programma met grote logische precisie kon worden uitgevoerd werden de fundamentele moeilijkheden van de positie manifest.

Ook de tweede vraag zal ik bevestigend beantwoorden, zij het dat daarbij van een niet tè restrictieve interpretatie van de doelstellingen van het natuurkundeonderwijs dient te worden uitgegaan.

### EEN HARDNEKKIGE FILOSOFISCHE INTUITIE

Aan onze ideeën over de aard van wetenschappelijke kennis ligt een uiterst plausibele en daarom hardnekkige intuītie ten grondslag:
Onze wetenschappelijke theorieën geven in hun historische opeenvolging een steeds waarheidsgetrouwer beeld van de WERELD, zoals die onafhankelijk van ons bestaat.
Deze intuītie vindt zijn neerslag in én van de meest verspreide filosofische posities, het zgn. Realisme. In het formuleren van deze positie wordt in feite een meer nauwkeurige parafrase gegeven van de zojuist genoemde intuītie. Een realist zal de intuītie gaan herformuleren in thesen zoals:
$R_{1}$ De wereld is een totaliteit van entiteiten, welke in hun hoedanigheden onafhankelijk van het menselijk intellect bestaan.
$R_{2}$ Alle beweringen van een natuurkundige theorie $T$ hebben een bepaalde waarheidswaarde (waar òf onwaar).
$R_{3}$ De geaccepteerde wetten van $T$ kunnen onwaar blijken te zijn, doch $T$ benadert de waarheid beter dan de historische voorgangers van $T$.

Deze positie wordt echter door andere filosofen bestreden: Zo zullen de opponenten bijvoorbeeld stellen, dat de realist zijn opvatting over de aard van wetenschappelijke kennis moet beschrijven in termen van een bijzonder kwetsbare metafoor, te weten 'benaderen van de waarheid'. Anders gezegd: Een verder uitwerken van de realistische positie vereist zoiets als een correspondentietheorie van de waarheid; en die theorie is speculatief ${ }^{2}$ ). De realistische positie is derhalve punt van controverse. Zij is aantrekkelijk omdat zij dicht bij onze meest gewone intuities over kennis blijft; zij is riskant omdat men bij het verdedigen van de positie al spoedig tot aan de liezen in een moeras van metafysische speculaties rond ploetert.
Wij zullen nu in het voetspoor van B.C. van Fraassen ${ }^{3}$ ) kort schetsen op welke
2) Voor een nadere uiteenzetting, zie S.J.Doorman: 'Nieuw Realisme?' Kennis en Methode 1983 (VII).
3) B.C. van Fraassen: 'The Scientific Image' Oxford 1980 (i.h.b. hoofdstuk 2) B.C. van Fraassen: 'The Charybdis of Realism: Epistemological Implications of Bell's Ineaquality' Synthese 1982 (52).
wijze bepaalde ontwikkelingen in de natuurkunde onverwachts van grote betekenis zijn geworden voor deze controverse.

### BELL's RESULTAAT EN HET REALISME

De realistische positie is vooral terug te vinden in het geloof dat iedere door ons geobserveerde regelmaat in de verschijnselen een reële oorzaak moet hebben. Zo'n oorzaak stellen wij ons dan voor als éen of andere factor of hoedanigheid, welke onafhankelijk van ons (en dus ook onafhankelijk van onze meethandelingen) in de werkelijkheid bestaat en werkzaam is.
Nu hebben wij ons idee over de precieze beschrijfbaarheid van die oorzaken moeten afzwakken: de quantummechanica is géén deterministische theorie, doch heeft een intrinsiek probabilistisch karakter. Het is derhalve noodzakelijk naar een overeenkomstig zwakkere parafrase van ons realistische geloof in reële oorzaken te zoeken. Reichenbach formuleerde hiertoe zijn zgn. 'Principle of the Common Cause':
"If coinncidences of two events $A$ and $B$ occur more frequently than would correspond to their independent occurence then there exists a common cause $C$ for these events..."4).
Reichenbach gaf een nauwkeurige formulering voor dit beginsel; wij duiden hier kort de kern aan van zijn nadere toelichting.
Stel $p(X)$ beschrijft de kans van het optreden van gebeurtenis $X$; we weten dan dat er sprake is van een positieve correlatie tussen gebeurtenissen $A$ en $B$ indien $p(A \wedge B)>p(A) \cdot p(B)$.

Reichenbach noemt de gebeurtenis $C$ de gemeenschappelijke oorzaak van gebeurtenissen $A$ en $B$ indien:
(1) $C$ in het absolute verleden ligt van $A$ en $B$
(2) $p(A \wedge B I C)=p(A I C) \cdot p(B I C)$

Hierbij moet $p(X I Y)$ gelezen worden als 'de kans van het optreden van gebeurtenis $X$, gegeven het optreden van gebeurtenis $Y^{\prime}$.
Het beginsel van Reichenbach zegt dat er steeds bij een geconstateerde positieve correlatie zo'n gemeenschappelijke oorzaak te vinden is. De vraag die men nu kan stellen is deze: Zijn er uitkomsten denkbaar van fysische metingen, welke ons dwingen ons alledaagse geloof in reële oorzaken, zoals filosofisch geparafraseerd met Reichenbach's beginsel, op te geven? Bell's resultaat (de zgn. ongelijkheid van Bell) schijnt tot een bevestigend antwoord op deze vraag te leiden.
4) H.Reichenbach: 'The Direction of Time' Berkeley 1963.

Van Fraassen geeft een bijzonder fraaie behandeling van de Bell-ongelijkheid aan de hand van de bespreking van varianten van de bekende EPR-paradox van de quantummechanica ${ }^{5}$ ).
De beschrijving van de logische structuur van de argumentatie is mogelijk door te abstraheren van de fysische details. Wij gaan daartoe abstract een zgn. Links-Rechts-experiment beschouwen. Het handelt hierbij om metingen, die verricht worden op paren van individuen resp. paren van gebeurtenissen.
De metingen vinden steeds op afzonderlijke individuen uit een paar nà scheiding plaats in twee meetgebieden $G_{1}$ en $G_{2}$ die ver van elkaar verwijderd zijn. De lezer kan denken aan metingen aan protonen-paren. Wij zullen een heel specifiek soort links-rechts-experiment beschouwen, waarbij er een perfecte correlatie bestaat tussen de uitkomsten, die 'links' (d.i. in $G_{1}$ ) en 'rechts' (d.i. in $G_{2}$ ) gevonden worden bij meting aan de individuen uit een paar. Stel dat de metingen als bijzonderheid hebben dat wij steeds uit drie soorten meethandelingen kunnen kiezen; bij het proton-paar kunnen wij denken aan meting van het spinmoment langs respectievelijk de $X, Y$ of $Z-a s$. Stel voorts dat de uitkomst steeds tweewaardig is, d.i. 0 of 1 (respectievelijk ja of neen); bij het proton-paar vinden wij voor de afzonderlijke protonen langs de X-as bijvoorbeeld of opwaartse, of neerwaartse spin. Kortom: in de hier te beschouwen links-rechts-experimenten gaat het om metingen, die steeds links respectievelijk rechts (in $G_{1}$ resp. $G_{2}$ ) vanuit een bepaalde beginpositie worden verricht op de afzonderlijke individuen uit een daartoe gescheiden paar, langs éen van de drie assen $\{1,2,3\}$ met steeds éën van de twee uitkomsten $\{0,1\}$. Wij voeren enkele notaties in.
$\underline{l}_{\mathfrak{i}}=$ a betekent: "links in $\left(G_{1}\right)$ wordt uitkomst a gevonden bij meting langs as i aan het 'linker' individu van een paar".
$\underline{r}_{j}=b$ betekent: "rechts (in $G_{2}$ ) wordt uitkomst b gemeten langs as $j$ bij meting aan het 'rechter' individu van een paar".
Li betekent: Links is gemeten langs as $i$.
Rj betekent: Rechts is gemeten langs as $j$.
Bij betekent: Links en rechts is gemeten langs as i resp. j .
Hierbij geldt dus: \{a,b\}C \{0,1\} en \{i,j\}С\{1,2,3\}
5) Voor een beschrijving van de Einstein-Podolsky-Rosen paradox, zie b.v. H.J. Groenewold: "De 'Einheitlichkeit' van Einstein", Kennis en Methode 1979 (III), i.h.b. pag. 294-9.

Wij geven nu een nauwkeurige definitie van een perfect correlatieverschijnsel met een separabiliteit in een links-rechts experiment ${ }^{6}$ ).

Definitie: De gemeten kansen van een links-rechts-experiment karakteriseren een perfect correlatieverschijnsel met separabiliteit dan en slechts dan als die kansen voldoen aan de volgende eisen:

I Perfectie Correlatie: $p\left(\underline{1}_{i}=a \wedge \underline{r}_{i}=a \operatorname{IL} \mathcal{L} \wedge()=0\right.$
II Seperabiliteit $: p\left(\underline{1}_{i}=a I L i\right)=p\left(\underline{1}_{i}=a I L i \wedge R j\right)$

$$
p\left(\underline{r}_{j}=b I R j\right)=p\left(\underline{r}_{j}=b I L i \wedge R j\right)
$$

De beide beginselen zijn geformuleerd in termen van voorwaardelijke kansen. Daarmede wordt tot uitdrukkeing gebracht dat hier uitsluitend gesproken wordt over kansen, die ook werkelijk op grond van meetuitkomsten te testen zijn. Wij gaan ervan uit dat de twee meetgebieden voldoende ver van elkaar verwijderd zijn om onderlinge beīnvloeding van individuen uit een paar tijdens de metingen uit te sluiten. Dit wordt vastgelegd in II. De eerste, op de 'linker situatie' betrekking hebbende formule leest immers als volgt: de kans dat bij meting aan het 'linker' individu langs as $i$ de uitkomst a wordt gevonden, gegeven dat links langs as i een meting wordt verricht, is onafhankelijk van het feit of aan het 'rechter' individu van hetzelfde paar al dan niet een meting wordt verricht. De tweede formule legt hetzelfde vast voor de 'rechter' situatie. Laten wij nu aannemen dat er zulke verschijnselen zijn. Wij gaan vervolgens Reichenbach's voorstel inbouwen in deze situatie. Ons geloof in reële zaken zouden wij dan als volgt willen uitdrukken: Indien er bij een bepaald type links-rechts-experi-
6) Als voorbeelden kan men denken aan de eerder genoemde protonen-paren, waarbij meting aan de individuen uit één paar in $G_{1}$ en $G_{2}$ langs dezelfde as (b.v. met een Stern-Gerlach apparaat) steeds in de twee gebieden een tegengesteld gerichte spin geeft. d'Espagnat noemt een ander hypothetisch voorbeeld: Na scheiding wordt bij tweelingen onderzocht of zij de begaafdheid hebben voor het leren van één van drie talen, te weten Latijn, Grieks en Chinees. Bij ieder paar meet ik 'links' en/of 'rechts' (dus nà de scheiding) steeds de leerbegaafdheid m.b.t. éen der drie talen. Strikte correlatie zou hier bijvoorbeeld kunnen betekenen, dat altijd als één uit een tweeling wèl de begaafdheid heeft voor taal $X$, de ander dat ook heeft. Voor een uitvoerige discussie van zulke links-rechts-experimenten (ofwel metingen aan paren): B. d'Espagnat:
'In Search of Reality', Springer Verlag 1983.
ment sprake blijkt te zijn van een perfect correlatieverschijnsel met separabiliteit, d.w.z. indien de meetuitkomsten van dat experiment aan I en II voldoen, dat is er een gemeenschappelijke oorzaak (factor) A, die de strikte correlatie in Reichenbach's zin verklaart. Laten wij proberen een meer precieze parafrase van dit geloof vast te leggen in een definitie. Stel dat de oorzaak (factor) $A$ verschillende waarden quit een uitkomstenverzameling I aan kan nemen (waarbij wij $\underline{A}$ overigens niet rechtstreeks meten; $\underline{A}$ is een verborgen factor!). Wij noteren 'Bijq' voor 'links wordt gemeten langs as $i$, rechts langs as $j$ en A=q"

Definitie: Het perfecte correlatieverschijnsel in het links-rechts-experiment heeft een reële oorzaak dan en slechts dan als er een $A$ is waarvoor geldt:

1 Causaliteit : $p\left(\underline{1}_{i}=a \wedge \underline{r}_{j}=b\right.$ I Bijq $)=p\left(\underline{1}_{i}=a \quad\right.$ I Bijq $) \cdot p\left(\underline{r}_{j}=b\right.$ I Bijq)
2 Onafhankelijkheid: $p(\underline{A}=q)=p(\underline{A}=q I L i \wedge R j)$
3 Separabiliteit : $p\left(\underline{1}_{j}=a \operatorname{Ii} \wedge \underline{A}=q\right)=p\left(\underline{1}_{i}=a\right.$ I Bijq)

$$
p\left(\underline{r}_{j}=b I R j \wedge \underline{A}=q\right)=p\left(\underline{r}_{j}=b I B i j q\right)
$$

Eis 2 drukt uit dat factor A zijn waarden aanneemt onafhankelijk van het feit of er nu gemeten wordt in meetgebieden ja of nee.
Eisen 1 en 2 samen vormen een precieze parafrase van de realistische opvatting in termen van dit abstracte links-rechts-experiment, en wel in die zin dat een realist in deze parafrase stelt:
Ieder perfect correlatieverschijnsel in een links-rechts-experiment hééft een reële, d.i. een van ons onafhankelijke oorzaak die de correlatie verklaart.

De volgende lemmata volgen direct uit de definitie:
(1) $p\left(\underline{1}_{i}=a I L i\right)=p\left(\underline{r}_{i}=1-a I B i i\right)$
(2) $p\left(\underline{1}_{i}=a \operatorname{I} B i j q\right) \subset\{0,1\} ; p\left(\underline{r}_{j}=b \operatorname{I} B i j q\right) \subset\{0,1\}$
(3) $p\left(\underline{1}_{i}=a\right.$ I Bijq $)=0: \Leftrightarrow: p\left(\underline{r}_{j}=a\right.$ I Bijq $)=1$

Wij onderzoeken nu de kansen, dat links en rechts langs verschillende assen bij een meting dezelfde uitkomst 1 wordt gevonden. Wij willen in het bijzonder de kans beschouwen dat wij links langs as $i$ de waarde 1 en rechts langs as $j$ de waarde 1 vinden gegeven het feit dat links langs as $i$ en rechts langs as $j$ een meting is verricht. Noem die kans $p(i ; j)$. Ofwel: $p(i ; j)=p\left(\underline{1}_{i}=1 \wedge \underline{r}_{j}=1\right.$ I Bij).

**Theorema**

Zij gegeven een perfecte correlatie in een links-rechts-experiment; stel voorts dat er een reële oorzaak $A$ is die de correlatie verklaart.
Dan geldt: $p(1 ; 3) \leqslant p(1 ; 2)+p(2 ; 3)$.

Voor een schets van het bewijs verwijs ik naar de Appendix. In feite is het een volstrekt elementaire redenering over de verschillende kansen, welke optreden. Het theorema is evenwel van het grootste belang in verband met het volgende resultaat.

**Resultaat (Bell)**
A. Er zijn varianten van de EPR-paradox waarvoor geldt:
(1) Het zijn perfecte correlatieverschijnselen in links-rechts-experimenten met separabiliteit
(2) De quantummechanica voorspelt: $p(1 ; 3)>p(1 ; 2)+p(2,3)$.
B. Experimentele toetsing, gebaseerd op deze varianten, geeft steun aan de voorspelling van de quantummechanica.

Wàt kunnen wij hier nu uit concluderen?
In ieder geval kunnen wij constateren, dat de realistische interpretatie van de aard van wetenschappelijke kennis in de gegeven parafrase ('strikte correlaties hebben reële oorzaken, nader analyseerbaar met behulp van (1) - (3)') door de 'feiten' wordt weerlegd (cf. B!).
Immers, $A(2)$ is in tegenspraak met de ongelijkheid van het theorema, welke in de beschouwende parafrase van het realisme uit $\mathrm{A}(1)$ gededuceerd kan worden. Overigens, dit zegt nog niet wat er precies aan de hand is. Wij kunnen in feite kiezen uit ten minste drie reacties op het resultaat:
(1) Wij kunnen het realisme als weerlegd beschouwen
(2) Wij kunnen separabiliteit verwerpen ((3) speelt immers in de afleiding van het theorema een cruciale rol)
(3) Wij kunnen de parafrase verwerpen en op zoek gaan naar een andere precisering van onze oorspronkelijke, hardnekkige intuītie over het realisme. Meer in het bijzonder kan dit betekenen, dat wij naar een parafrase zoeken van ons geloof in reële oorzaken, welke ons niet in de geschetste tegenspraak verwikkelt.

Lezers zullen wellicht opmerken: Zo kan je natuurlijk altijd je aan de gevolgen van een test onttrekken. Is dit niet weer zoiets dat kenmerkend is voor de 'eindeloosheid' van filosofische discussies?
Echter, de hier geschetste situatie is ook in empirische wetenschappen niet onbekend: Echt cruciale experimenten, die logisch gesproken slechts éen mogelijke conclusie forceren, bestaan niet tenzij hoogstens op een triviaal niveau. Nochtans kunnen wij wèl constateren, dat een bepaalde plausibele versie van onze realistische intuities over het karakter van wetenschappelijke kennis kennelijk onverenigbaar is met onze meest fundamentele en goed gesteunde fysische inzichten van vandaag.

### BELANG VAN ONDERWIJS VOOR MONDIGHEID

De moraal voor de beantwoording van vraag 1 vat $i k$ aldus samen: Niet alleen lukt het ons binnen de empirische wetenschappen om onze voorstelling van de werkelijkheid, soms zelfs zeer drastisch, te corrigeren, doch ook kunnen wij ons soms kennelijk bevrijden van verkeerde voorstellingen over de aard van onze voorstellingswijze van de werkelijkheid.
Thans moeten wij ons afvragen of dit van belang kan zijn voor de inrichting van het natuurkunde-onderwijs.

Laat ik beginnen met op te merken dat deze uiteenzetting niet is bedoeld om te propageren dat de Bell-ongelijkheid en zijn gevolgen voor realistische kennis interpretaties reeds op de middelbare school behandeld moet worden. Ik koos dit voorbeeld slechts om op een hopelijk voor u enigszins aantrekkelijke wijze te onderstrepen dat ons alledaagse, intuītieve beeld van de aard van wetenschappelijke kennis problematisch is.

Waarom is dit van belang?
Laat ik vooropstellen dat mijns inziens het natuurkunde-onderwijs tenminste twee doelstellingen moet proberen te realiseren:

1. Leerlingen moeten vertrouwd raken met natuurkundige methoden, begrippen en basisbeginselen, welke in het vervolg-onderwijs dienen te worden verondersteld.
2. Leerlingen moeten inzicht krijgen in die aspecten van de natuurkunde, waaraan deze wetenschap zijn grote betekenis ontleend voor cultuur en samenleving. Anders gezegd: In een open, democratische samenleving moet een zo groot mogelijk deel der burgers op redelijke wijze kunnen deelnemen in debatten over de maatschappelijke gevolgen van bepaalde natuurkundige ontwikkelingen. Zelfs zij, die natuurkunde later niet meer tegenkomen, moeten derhalve toch een zo genuanceerd mogelijk beeld hebben van deze basiswetenschap.

De twee doelstellingen laten zich niet zo gemakkelijk verenigen. De realisering van de eerste doelstelling vraagt om een zekere mate van intellectuele disciplinering. Uiteenzettingen over de grillige ontwikkeling van natuurkundige kennis, over het voorlopige karakter van wetenschappelijke wetten, over het eigenaardige verband van theorie en alledaagse ervaring etc. zullen vanuit de eerste doelstelling vaak gezien worden als luxueuze uitwijdingen, die men zich nauwelijks kan veroorloven gezien de zware eisen, die men zich in dit opzicht door het vervolg-onderwijs laat stellen.
Vanuit de tweede doelstelling ligt de nadruk juist niet zozeer op de hoeveelheid kennis welke de leerlingen moet worden bijgebracht, dan wel op de mate van inzicht die de leerlingen moeten hebben in de natuurkundige benaderingswiize, in de wijze waarop natuurkundige kennis wordt opgebouwd en gecorrigeerd, in de beperkingen waaronder wij in natuurkundige opvattingen kunnen geloven.

Een volstrekte leek zijnde met betrekking tot onderwijskundige kwesties wil ik mij toch wagen aan het uitspreken van een wellicht volstrekt onjuist, nochtans sterk vermoeden dat bij mij leeft. Naarmate men meer de nadruk legt op alleen de eerste doelstelling zal men bijdrage aan de versterking van een populair beeld van de natuurkunde bij leken, waarbij deze discipline gezien wordt als een ontoegankelijke, moeilijke, nochtans onbetwijfelbare wetenschap, bestaande uit vaste wetten welke door een geheimzinnige elite worden ontdekt. En daarmee zal men indirect bijdragen aan het hoogst erratische karakter van maatschappelijke debatten over incidentele natuurkundige ontwikkelingen waarin diezelfde leken soms moeten participeren.
Als dit vermoeden juist is, en als het vormende karakter van onderwijs zoals dat in de tweede doelstelling is aangeduid, onontbeerlijk is voor een beter functioneren van wetenschappelijke elite's binnen onze democratie, dan zal duidelijk zijn dat men het belang van de eisen, die aan de hoeveelheid kennis gesteld worden door het vervolg-onderwijs, nog eens héël nauwkeurig zou moeten wegen. En het is ōōk uit gepaste bewondering voor de natuurkunde dat ik een grote nadruk op de tweede doelstelling zou willen bepleiten.

Samengevat: Het beeld dat wij hebben van kennis, en daarmede tevens het beeld dat wij hebben van onszelf, is voortdurend aan verandering onderhevig. De ontwikkeling van de natuurkunde is in dit opzicht öök van belang. De natuurkunde is niet alleen de wetenschappelijke basis van de hedendaagse techniek, zij is in diepere zin ook de basis van veel van onze inzichten in cultuur. Ik ben niet precies ingegaan op de vraag of dat terecht is, omdat ik niet precies
weet hoe ik die vraag zou moeten stellen. Ik constateer slechts dàt de vorm van onze samenleving diepgaand door de ontwikkeling van natuurkundige kennis beinnvloed wordt mede omdat natuurkunde in onze culturele traditie steeds als voorbeeld-wetenschap is gezien. Wil het onderwijs mondige burgers voortbrengen dan zal het vormende karakter van het natuurkunde-onderwijs niet verwaarloosd mogen worden. In dat geval zal de nodige ruimte gevonden moeten worden voor het inzichtelijke en doorleefbaar maken van de wijze waarop zelfs elementaire natuurkundige kennis in het verleden moeizaam werd opgebouwd via correcties van toen bestaande levendige voorstellingen van de fysische werkelijkheid. Natuurkunde-onderwijs dat zich slechts naar de eerste doelstelling voegt, zal uiteindelijk voor veel leerlingen een nutteloze investering blijven. Maar wellicht is in Uw onderwijspraktijk van een dergelijke verwaarlozing van de tweede doelstelling geen sprake. Mijn woorden zijn dus waarschijnlijk volstrekt overbodig, reden te meer om u te danken voor $U w$ geduld en aandacht.
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-046.jpg?height=1313&width=914&top_left_y=1425&top_left_x=921)

## Ioniserende straling, radioactiviteit en hun biologische gevolgen
 Prof de C.W. Bavenosien <br> Universiteit van Amsterdam $\ddagger$ <br> TNO, Rÿswyk

### Inleiding

De radiobiologie omvat de kennis van effecten die door verschillende soorten straling in biologische systemen kunnen worden geĩnduceerd. Deze effecten vertonen een grote diversiteit, variërend van breuken in macromoleculen, b.v. DNA, tot functie-stoornissen in organen, b.v. hersenen. Ze kunnen snel optreden, zoals bij inactivering van virussen, bacteriën en zoogdiercellen, maar ze kunnen ook laat, d.w.z. na vele jaren tot uiting komen, zoals bij de inductie van diverse vormen van kanker in bestraalde zoogdieren en de mens of bij genetische schade in generaties nakomelingen.

In het algemeen wordt de meeste aandacht besteed aan effecten van ioniserende straling, maar ook andere stralingssoorten, b.v. ultra-violet licht, kunnen in bepaalde opzichten overeenkomstige biologische verschijnselen veroorzaken.

Omdat in de radiobiologie straling het agens is dat de verschijnselen induceert, vormt de kennis van eigenschappen van verschillende soorten stralinc en van radioactieve stoffen een belangrijke basis voor deze wetenschap. Vele eigenschappen van straling zijn goed bekend door nauwkeurig physisch onderżoek. Zeer kleine maar ook heel hoge doses straling kunnen met diverse technieken goed worden gemeten, en daardoor is de mogelijkheid verkregen dosis-effect relaties kwantitatief te bepalen en te evalueren.

Met betrekking tot de relatie tussen de radiobiologie en haar toepassingsgebieden kunnen twee soorten gevolgen van bestraling worden onderscheiden. In de eerste plaats kan blootstelling aan straling schadelijke effecten veroorzaken, waartegen de mens zoveel mogelijk moet worden bescherm. Deze effecten omvatten o.a. de inductie van kanker en van afwijkingen in nakomelingen. Toepassingen van straling bieden anderzijds ook grote voordelen, o.a. voor de behandeling van kwaadaardige ziekten. Ongeveer de helft van alle patienten met kanker komt in de loop van hun ziekte in aanmerking voor radiotherapie,
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-048.jpg?height=933&width=1309&top_left_y=249&top_left_x=344)
welke deels curatief, deels palliatief is gericht. Ioniserende straling en radioactieve stoffen worden ook voor heel veel industriële toepassingen en in wetenschappelijk onderzoek gebruikt.

Onderzoek van de schadelijke effecten van straling en de bescherming daartegen is in de laatste jaren steeds belangrijker geworden. Als gevolg van natuurlijke stralingsbronnen en in de 20e eeuw in toenamende mate als gevolg van toepassingen van straling door de mens op het gebied van de geneeskunde, de wetenschap en de industrie, worden allerlei groepen personen blootgesteld aan ioniserende straling en radioactieve stoffen. Bij de toepassingen in de röntgendiagnostiek, de nucleaire geneeskunde en de radiotherapie wordt met deze blootstelling een duidelijk nut beoogd voor de individuele persoon die aan straling wordt blootgesteld. Hierbij moet echter dit nut steeds afgewogen worden tegen de risico's van de inductie van schadelijke effecten. Kennis der radiobiologie kan bevorderen dat de mogelijkheden van toepassingen van ioniserende straling en van radioactieve stoffen in de geneeskunde optimaal worden benut, terwijl schadelijke effecten zoveel mogelijk worden voorkomen.

Behalve bij toepassingen in de geneeskunde kunnen groepen personen worden blootgesteld aan ioniserende straling en radioactieve stoffen als gevolg van hun beroepsuitoefening, bijvoorbeeld personeel werkzaam in ziekenhuizen, laboratoria en de kernenergie industrie. Hierbij moet er naar worden gestreefd
de risico's van schadelijke gevolgen zodanig te beperken dat ze niet groter zijn dan in andere beroepen. Tenslotte worden grote delen van de wereldbevolking aan ioniserende straling blootgesteld door de verspreiding van radioactieve stoffen in de atmosfeer en de biosfeer, b.v. door explosies van kernwapens en de werking van kernenergie-reactoren. Daar hierbij geen direct nut voor individuele personen aanwijsbaar is, zullen de mogelijke schadelijke gevolgen moeten worden afgewogen tegen de eventuele nadelen van alternatieve oplossingen, b.v. andere technieken van energievoorziening.

Radiobiologische kennis wordt niet alleen direct toegepast op een aantal gebieden, zoals de radiotherapie, de arbeidshygiëne, milieuhygiëne, nucleaire geneeskunde en radiodiagnostiek, maar daarnaast zijn de resultaten van radiobiologisch onderzoek vaak van belang voor onderzoek in andere gebieden van de geneeskunde, met name van oncologie. In de eerste plaats is gebleken dat methoden en technieken die voor radiobiologisch onderzoek werden ontwikkeld, toepassing vinden bij ander onderzoek. In de tweede plaats kunnen vaak fundamentele mechanismen in biologische systemen, b.v. celproliferatie in normale weefsels en tumoren, goed worden bestudeerd door een nauwkeurig gedoseerde beschadiging aan te brengen en de reactie van cellen en weefsels daarop te onderzoeken. Zo kan inzicht worden verkregen in de proliferatie van cellen van een gezwel door de reactie op een bekende dosis straling te vervolgen. Al de genoemde verbindingen tussen de radiobiologie en andere gebieden van onderzoek veroorzaken een sterke wisselwerking tussen onderzoekers van verschillende disciplines, waardoor een belangrijke invloed wordt uitgeoefend op vele andere gebieden van de biologie en de geneeskunde.

### Dosimetrie
Om de relatie tussen de hoeveelheid ontvangen straling en de frequentie of de ernst van de veroorzaakte biologische veranderingen te beschrijven, moeten een aantal grootheden en daarbij behorende eenheden worden gedefinieerd. Een physisch, chemisch of biologisch effect van ioniserende straling wordt veroorzaakt doordat een deel van de energie van de straling in het blootgestelde weefsel wordt geabsorbeerd. Deze 'geabsorbeerde dosis' wordt uitgedrukt in de hoeveelheid energie die per massa eenheid wordt opgenomen. In samenhang met het SI eenheden stelsel, is een speciale eenheid gedefinieerd: 1 gray (Gy) $=1$ J. $\mathrm{kg}^{-1}$ medium. De vroeger gebruikte eenheid 'rad' $=0,01 \mathrm{~Gy}$.

Voor biologische effecten moet nog rekening worden gehouden met de hogere effectiviteit van sommige soorten straling, b.v. $\alpha$-straling of neutronenstraling in vergelijking met röntgenstraling of $\gamma$-straling. Daartoe is de eenheid 'dosisequivalent' ingevoerd met de eenheid sievert (Sv). $1 \mathrm{~Sv}=1 \mathrm{~J} . \mathrm{kg}^{-1}$. De vroeger gebruikte eenheid 'rem' $=0,01 \mathrm{~Sv}$.

Voor photonen en elektronen is de dosis-equivalent $H$ in Sv gelijk aan de geabsorbeerde dosis in Gy. Voor $\alpha$-straling van natuurlijke radioactieve stoffen is $1 \mathrm{~Sv}=0,05 \mathrm{~Gy}$, d.w.z. de 'Quality Factor', Q, is 20.

### Soorten effecten

Gegevens verkregen uit epidemiologisch onderzoek en experimenten met proefdieren hebben duidelijk bewezen dat ioniserende straling schadelijke effecten kan veroorzaken. Deze effecten worden in de eerste plaats onderscheiden naar het moment van optreden.

Vroege effecten kunnen binnen enkele uren of binnen enkele weken optreden. Tot deze effecten rekent men het beenmergsyndroom, het darmsyndroom en het centraal zenuwstelselsyndroom welke kunnen ontstaan na bestraling van het hele lichaam. Deze effecten treden pas op na relatief hoge doses, groter dan 100 rad $=1$ Gy. Deze effecten zullen dus alleen ontstaan na accidentele blootstelling aan straling. Veiligheidsmaatregelen moeten voldoende zijn om deze effecten te voorkomen.

Late effecten kunnen optreden na periodes van enkele maanden, maar ook nog na vele jaren of in volgende generaties. Men onderscheidt in de eerste plaats effecten waarvan alleen de frequentie maar niet de ernst van de schade toeneemt met de doses. Deze effecten worden wel met de term 'stochastisch' aangeduid. Hieronder vallen de inductie van vele soorten maligne tumoren en van genetische effecten. Er bestaat waarschijnlijk geen drempeldosis waarbeneden deze effecten niet worden geinduceerd. Andere soorten late effecten nemen zowel in ernst als in frequentie toe met de dosis. Men noemt dit 'nietstochastische' effecten. Men neemt veelal aan dat voor deze effecten een drempeldosis bestaat waarboven het effect pas wordt waargenomen. Tot deze effecten behoren weefselfibrose, vaatveranderingen en lenstroebeling. Een aparte categorie vormen nog de stoornissen in embryonale en foetale ontwikkeling, de zgn. teratogene effecten die echter als bijzondere vorm van somatische effecten moeten worden gezien.

### Stralingsbronnen

Overal op aarde dringt een deel van de kosmische straling door de atmosfeer heen en geeft aanleiding tot het ontstaan van verschillende ioniserende deeltjes. Daarnaast bevatten bijna alle materialen, voorwerpen en levende organismen van nature radioactieve stoffen. Ioniserende straling is dan ook een overal aanwezige component van het milieu, maar de ontvangen doses kunnen voor verschillende gebieden minstens een factor 2 variëren. Naast de natuurlijke straling wordt iedereen blootgesteld aan straling die het gevolg is van menselijke activiteiten, o.a. medische toepassingen van straling.

Over de stralingsdosis, die de bevolking in Nederland en in andere landen ontvangt, zijn veel gegevens bekend. Een samenvatting van de verschillende bijdragen is gegeven in tabel 2. Men kan hieruit afleiden, dat als gevolg van bronnen die altijd in de natuur aanwezig zijn geweest, een gemiddelde dosis van ongeveer $80 \mathrm{mrad}=0,8 \mathrm{mGy}$ per jaar wordt ontvangen. De dosis ontvangen door longweefsel is ongeveer $30 \mathrm{mrad}=0,3 \mathrm{mGy}$ hoger tengevolge van de inademing van het gas radon, dat uit de bodem en uit allerlei bouwmaterialen vrijkomt. De totale dosis in de longen zou dus ongeveer 1,10 mGy bedragen. Wanneer echter rekening wordt gehouden van de aard van de straling, dan moet aan de $\alpha$-straling van radon een groter gewicht worden toegekend, omdat dit type straling effectiever is voor het induceren van biologische effecten. Voor a-straling van radioactieve stoffen ligt de zogenaamde kwaliteitsfactor, Q, tussen 10 en 20. De eenheid, die is ingevoerd voor de stralingsdosis met correctie voor de kwaliteitsfactor, heet de sievert. Voor $\alpha$-straling van radon zou dan 1 Gy overeenkomen met 20 Sv . De dosis op de longen zou dus $80+30 \times 20=6,80$ mGy per jaar bedragen. Voor de meeste andere soorten straling heeft de kwaliteitsfactor een waarde 1 , dat wil zeggen 1 rad = 1 rem = 0,01 sievert.

Uit het tweede deel van tabel 2 blijkt, dat tengevolge van de toepassing van röntgenstraling in de geneeskunde een gemiddelde jaarlijkse dosis wordt ontvangen, die ongeveer de helft bedraagt van de dosis afkomstig van natuurlijke straling. De andere in tabel 2 genoemde bronnen leveren in vergelijking hiermee slechts een geringe bijdrage. Het is van belang hierbij op te merken, dat de aanvaardbaarheid van een bepaalde toepassing van straling niet alleen afhangt van de dosis die er het gevolg van is, maar ook van de grootte van het voordeel die deze toepassing oplevert.

### Effecten van ioniserende straling op de mens
 a. Vroege effecten

Wanneer een totale lichaamsbestraling wordt ontvangen van de grootte van $200 \mathrm{rad}(=2 \mathrm{~Gy})$ of hoger, kunnen er verschillende acute effecten optreden.

1. Het beenmergsyndroom, dood binnen 1-2 maanden (200-1000 rad $\gamma$-straling).
2. Het darmsyndroom, dood binnen 2 weken (1000-5000 rad $\gamma$-straling).
3. Het centraal zenuwstelselsyndroom, dood binnen 1-2 dagen (boven 5000 rad $\gamma$-straling).
Bij doses boven 100 rad kan misselijkheid, hoofdpijn en diarrhee optreden.
b. Late effecten

Enkele jaren tot enkele tientallen jaren na blootstelling aan kleine doses straling, van de orde van 50 rad of minder, kunnen late somatische effecten optreden. Hierbij wordt voornamelijk gedacht aan leukemie en andere vormen van maligne proliferatieve ziekten. In nakomelingen van bestraalde personen kunnen genetische afwijkingen optreden.
Voor beide soorten effecten geldt dat de 'spontaan' aanwezige frequentie wordt verhoogd. De kans op overlijden aan een vorm van kanker is 'normaal' 25 procent. Erfelijke ziekten worden 'spontaan' gevonden in ongeveer 10 procent van de levend geborenen.

Gegevens over het ontstaan van kanker bij de mens tengevolge van blootstelling aan straling zijn met name de laatste twintig jaar verkregen voor een aantal groepen personen. De belangrijkste serie gegevens is verkregen door onderzoek van overlevenden in Hiroshima en Nagasaki, die in 1945 blootgesteld werden aan straling van atoombommen. Van deze bevolking zijn sinds 1946 ongeveer 45.000 personen die doses tussen 1 en 1000 rad hadden ontvangen, nauwkeurig gevolgd en vergeleken met een groep van ongeveer 35.000 personen in dezelfde steden die niet bestraald waren of slechts heel geringe doses hadden ontvangen. Daarnaast zijn gegevens verkregen over groepen patienten die voor bepaalde ziekten met straling werden behandeld, over groepen personen die in industrieën werkzaam waren waar met radioactieve stoffen werd gewerkt, over een groep artsenradiologen die door hun werk aan straling werden blootgesteld en over groepen mijnwerkers die tijdens hun werk radioactieve gassen inademen. Van de verschillende soorten kanker waarover gegevens beschikbaar zijn, zullen slechts enkele aspecten worden genoemd.

Het is een algemene observatie dat na bestraling een aantal jaren verloopt voordat kanker wordt ontdekt. Deze periode noemt men de latente periode, welke voor leukemie minimaal enkele jaren bedraagt maar voor andere typen kanker 10 jaar of meer kan bedragen. Dit betekent niet dat na 10 jaar alle door straling veroorzaakte gevallen van kanker reeds direct optreden, want nieuwe gevallen kunnen gedurende vele tientallen jaren na bestraling nog worden gevonden. Alleen van leukemie is bekend, 0.a. door onderzoek van overlevenden in Hiroshima en Nagasaki, dat na ongeveer 25 jaar praktisch geen nieuwe gevallen meer worden waargenomen.

Na evaluatie van alle beschikbare gegevens samengevat in het meest recente rapport van de wetenschappelijke Commissie van de Verenigde Naties over effecten van straling (UNSCEAR) kan worden gesteld dat bij lage doses (< 10 rad) per rad ontvangen straling een kans bestaat van 20 per $10^{6}$ personen op het optreden van leukemie. Dit komt overeen met gemiddeld éen per $10^{6}$ personen per jaar over een risicoperiode van ongeveer 20 jaar. Deze waarde wordt o.a. gebruikt in de meest recente aanbevelingen van de Internationale Commissie voor Stralingsbescherming (ICPR).

Voor het ontstaan van borstkanker bij vrouwen die aan straling werden blootgesteld, blijken vrij grote verschillen in het risico te worden gevonden, variërend van 50 per $10^{6}$ personen afgeleid van gegevens uit Japan, tot 200 per $10^{6}$ personen per rad afgeleid van gegevens over groepen patiënten.

Voor het ontstaan van borstkanker zijn o.a. gegevens verkregen over groepen personen die met radium-houdende verf op wijzerplaten van horloges lichtgevende cijfers aanbrachten. Opname via de mond van radium dat $\alpha$-deeltjes uitzendt, bleek nog vele jaren later tot aantoonbare hoeveelheden radium in bot te leiden. De kans op botkanker afgeleid uit deze en andere gegevens, bedraagt per rem ongeveer 5 per $10^{6}$ personen.

Het is niet mogelijk in deze bijdrage alle risicowaarden te noemen en de wetenschappelijke achtergrond daarvan te bespreken. Een uitvoerige analyse is gegeven in het rapport van de Verenigde Naties 'Scientific Committee on the Effect of Atomic Radiation' (UNSCEAR, 1977). Samenvattend kan worden gesteld dat de ICRP in recente aanbevelingen betreffende beperking van stralingsdoses, voor de kans op overlijden na blootstelling aan röntgen- of $\gamma$-straling als gemiddelde over alle leeftijden van de blootgestelde personen, een waarde gebruikt van

100 per $10^{6}$ personen per rem ( $=0,01 \mathrm{~Sv}$ ) voor alle typen van kanker samen. Voor bestraling in de zeer gevoelige periode voor de geboorte is deze waarde waarschijnlijk nog een factor twee tot drie hoger. Een samenvatting van de risicofactoren is gegeven in tabel 3. In deze tabel is de eenheid rem gebruikt om aan te geven dat met een hogere effectiviteit van b.v. a-straling of neutronen rekening is gehouden.

Tabel 3: Risicofactoren voor overlijden aan verschillende typen kanker door ioniserende straling.

| orgaan/weefsel | risico per rem | risico periode <br> (jaar) | risico per rem per <br> jaar gedurende de <br> risicoperiode |
| :--- | :---: | :---: | :---: |
| beenmerg | $20 / 10^{6}$ | 20 | $1.0 / 10^{6}$ |
| long | $20 / 10^{6}$ | 40 | $0.5 / 10^{6}$ |
| bot | $5 / 10^{6}$ | 40 | $0.1 / 10^{6}$ |
| borst (vrouwen) | $65 / 10^{6}$ | 40 | $1.6 / 10^{6}$ |
| schildklier | $5 / 10^{6}$ | 40 | $0.1 / 10^{6}$ |
| andere organen <br> samen | $50 / 10^{6 * *}$ | 40 | $1.2 / 10^{6 * *}$ |
| totaal | $130 / 10^{6 * * *}$ |  |  |

* Afgeronde waarden per rem stralingsdosis.
** Verondersteld wordt dat individuele organen hoogstens een bijdrage leveren van $1 / 5$ van deze waarde.
*** Het totaal is voor een gemiddelde bevolking (mannen en vrouwen) berekend door de kans op borstkanker voor de helft mee te tellen..

Gegevens over genetische effecten zijn niet direct op epedemiologisch onderzoek gebaseerd maar grotendeels afgeleid van experimenten bij proefdieren. Men heeft berekend dat na een straling met 1 rad -straling per generatie 185 nieuwe gevallen per $10^{6}$ levend geborenen verwacht kunnen worden als de populatie een nieuwe genetische evenwichtssituatie heeft bereikt. Bij een generatieduur van 30 jaar komt 1 rad per generatie overeen met 33 mrad per jaar.

**Radiobiologische inzichten over effecten van lage doses**

In de meeste gevallen zijn de gegevens betreffende verschillende groepen blootgestelde personen te beperkt om voldoende nauwkeurig het verband tussen de dosis en de kans op effecten vast te stellen. Bovendien zijn de ontvangen doses veelal van de grootte van 50 rad en hoger. Naast resultaten van epidemiologisch onderzoek is het daarom nodig een tweede soort informatie te gebruiken voor de extrapolatie van beschikbare gegevens over tumorinductie bij de mens naar geringere doses, van de orde van 1 rad en lager.

Bij doses in het gebied tussen 50 en 500 rad zijn vele soorten radiobiologische experimenten met zoogdiercellen uitgevoerd, o.a. over inductie van chromosoomaberraties. Hieruit is gebleken dat, naast inductie door individuele ioniserende deeltjes, bij deze doses ook accumulatie van schade een belangrijke bijdrage kan leveren tot de totale frequentie van effecten. Daaruit volgt dat in dit dosisgebied de kans op effect sneller toeneemt dan evenredig met de dosis.

De kans op een bepaald type cellulaire verandering kan daarom bij benadering als volgt worden weergegeven:
Frequentie van een effect $F=p_{1} D+p_{2} D^{2}$ waarbij waarden van $p_{1}$ en $p_{2}$ afhangen van het onderzochte effect in de betreffende zoogdiercellen terwij1 waarvan van $p_{1} / p_{2}$ tussen 50 en 2000 rad blijken te liggen.

Een relatie van deze vorm blijkt ook een goede beschrijving te geven van de toename van kanker met de dosis gevonden in experimenten met muizen en ratten. Bij doses hoger dan 100 rad gaat ook veelal de inductie van celdood een rol spelen. Omdat alleen cellen die tot ongelimiteerde deling in staat zijn tot een tumor aanleiding kunnen
geven, neemt bij veel hogere doses de kans op ontwikeling van een tumor dan ook minder snel toe als zonder celdood verwacht zou worden. (Barendsen, 1978). Een belangrijk aspect dat hier niet uitvoerig kan worden behandeld, betreft de invloed van herstel van cellulaire schade tijdens langdurige bestraling en met lage doseringstempi. Dit herstel beīnvloedt de lineaire component in de dosiseffect relatie niet, maar vermindert de relatieve bijdrage van de quadratische component (Barendsen, 1979).

Met behulp van deze radiobiologische inzichten is het mogelijk de gegevens over kanker-inductie bij de mens, die betrekking hebben op doses van 50 rad en hoger, te extrapoleren naar lage doses. Hierbij moet natuurlijk rekening worden gehouden met het feit dat de beschikbare gegevens beperkt, en de groepen personen heterogeen zijn. Deze extrapolatie is ook door de International Commission on Radiological Protection (ICRP) in haar nieuwste aanbevelingen (publicatie nr. 26) toegepast.

**Aanbevelingen van de ICRP**
Op grond van inzichten en gegevens waarvan in het voorgaande enkele aspecten werden geschetst, zijn met betrekking tot de stralingsbescherming door de 'International Commission on Radiological Protection' drie uitgangspunten opgesteld die de blootstelling van personen aan ioniserende straling zoveel moeten beperken als verantwoord wordt geacht in verband met de voordelen die de toepassingen van straling in de geneeskunde, techniek, industrie en wetenschap bieden. Deze uitgangspunten kunnen als volgt worden omschreven:

1. Een bepaalde toepassing van straling is alleen gerechtvaardigd als er een nuttig doel mee gediend wordt dat groter is dan de nadelen van de blootstelling aan straling.
2. Indien aan een procedure een zeker nut wordt toegekend, terwijl als gevolg daarvan personen straling kunnen ontvangen, dan moet een procedure worden gevolgd waarbij de dosis voor die personen zo laag wordt gehouden als praktisch mogelijk is, mede beoordeeld in het licht van de voordelen die er tegenover staan, b.v. de behandeling van ziekten. Bij een belangrijk voordeel zal men een zekere blootstelling aan straling eerder accepteren, maar de laagst mogelijke dosis moet worden nagestreefd zonder de voordelen op te offeren.
3. De doses die personen mogen ontvangen worden volgens de Europese normen en de Kernenergiewet gelimiteerd tot bepaalde waarden, afhankelijk van de aard
van de bestraling en de groep personen die straling ontvangt. Voor personen die beroepshalve met straling in aanraking komen, is een hogere limietdosis vastgesteld ( 5 rem per jaar) dan voor overige leden van de bevolking ( 0,5 rem per jaar).

De toepassing van de nieuwe ICRP aanbevelingen voor de berekening van toelaatbare hoeveelheden en concentraties van radioactieve stoffen in het lichaam heeft geleid tot gecompliceerde berekeningen die niet meer eenvoudig na te rekenen zijn. De waarden van ALI's (annual limit of intake) zijn in een aantal gevallen hoger, maar ook in een aantal gevallen lager dan de waarden die tot nu toe golden volgens ICRP publicatie 2. Hierbij wordt rekening gehouden met opname via ademhaling of eten in het bloed, de verdeling over organen en weefsels en de uitscheiding.

### Literatuur

Barendsen, G.W. Fundamental aspects of cancer induction in relation to the effectiveness of small doses of radiation. In: Late biological effects of ionizing radiation, vol. II, Vienna, IAEA (1978) 263-275.
Barendsen, G.W. Influence of radiation quality of the effectiveness of small doses for induction of reproductive death and chromosome aberrations in mammalian cells. Int. J.Radiat. Biol. 36 (1979) 49-63.
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-058.jpg?height=900&width=1292&top_left_y=340&top_left_x=369)

## Henk Bos & zijn onmogelijke boemerang.

![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-058.jpg?height=1289&width=889&top_left_y=1460&top_left_x=576)

## Halfgeleidergeheugens, Massaartikelen en trekpaarden van de IC-industrie <br> J. Lohstroh 


### Abstract

Samenvatting: Zoals bekend zijn er aan computers drie functies te onderscheiden: geheugen. verwerking en in- en uitvoer. Dit artikel behandelt computergeheugens. Vroeger bestonden de werkgeheugens van computers gewoonlijk uit magnetische ringkernen; tegenwoordíg bestaan ze uit halfgeleiders in de vorm van integrated circuits - IC's. Geheugens zijn ook mas-sa-artikelen geworden. De IC-fabrikanten hebben gemerkt dat ervaringen. opgedaan hij de massaproductie van geheugens. ze een voorsprong geeft bij de vervaardiging van andere digitale IC-producten. In het artikel wordt aan de hand van een mechanisch model - het wateranalogon - uitgelegd hoe halfgeleidergeheugens werken; wat de uitdrukking'in het geheugen opslaan' precies betekent bij computers. Tot slot blijkt dat Europa en in toenemende mate ook de Verenigde Staten hij de productie van halfgeleidergeheugens door Japan worden afgetroefd. De Europese en Amerikaanse geheugenfirma's stellen echter alles in het werk hun marktaandeel terug.te winnen.


### Inleiding

In het begin van de jaren 70 bestonden de snelle computerwerkgeheugens voornamelijk uit magnetische ringkernen. Het re-search-potentieel stond toen nog sterk opgesteld om hieraan verdere verbeteringen aan te brengen en ook verdere miniaturisering door te voeren, maar het werd geleidelijk aan wel duidelijk dat de opkomende halfgeleider IC-technologie een sterke bedreiging voor de ringkern vormde. (IC staat voor 'inlegrated circuit': geïntegrcerde schakeling, cen halfgeleider kristal met daarop vele onderling doorverbonden transistoren, ook wel 'chip' genoemd naar de chip zelf die het lichaam van de geïntegreerde schakeling vorint.) De constructiemethode van ringkerngeheugens - het rijgen van losse ringetjes aan draden en het weven van deze

[^0]draden in de vorm van matten - bleef nl. inherent duur, bovendien blecf de schrijf- en leessnelheid van deze geheugens mocilijk te verhogen.
Verder blijven in IC's de te onthouden elcktrische computersignalen bewaard in elektrische vorm, namelijk in de vorm van elektrische lading, terwijl in magnetische geheugens de elektrische signalen vertaald mocten worden naar magnetische effecten en viceversa. In het laatste geval is er sprake van een zogenaamde hybride oplossing, terwijl er in het eerste geval sprake is van een monolitische oplossing die technisch aantrekkelijker en goedkoper is.

Inderdaad werd in de jaren zeventig aangetoond dat halfgeleidergeheugens goedkoper gemaakt kunnen worden, dan wel betere eigenschappen bezitten - sneller zijn en/of minder encrgie verbruiken. en in ieder geval een veel geringer volume beritten - zodat vandaag vrijwel alle ringkeruen uit onze computers verdwenen rijn.
Dat bovendien het aantal in gebruik zijnde
computers enorm is gegroeid: grote, kleine, business-, proces besturings- en home- of personal-computers, en bovenal de behoefte atan geheugencapaciteit per computer sterk is gestegen, maakt dat geheugens massa-artikelen zijn geworden. Deze massa-artikelen worden geleverd door een aantal elkaar sterk beconcurrerende IC-firma's, met name uit Japan, de Verenigde Staten en in mindere mate uit Europa. In deze concurrentiestrijd is sprake van een enorme druk op de prijs, en dientengevolge is er een zeer grote pressie on te komen tot efficiency-verbeteringen in de uit zeer veel gecompliceerde stappen bestaande fabricageprocessen. Deze verbeteringen betekenen vaak verdere miniaturiseringen in een al uiterst verfijnde technologie en worden overal in een bijna revolutionair tempo aangebracht. Zij vereisen cen groot aantal hoog gekwalificeerde arbeidskrachten en gaan ten koste van investeringen van vele miljoenen guldens aan apparaten.

Zoals voor vele ingewikkelde producten vervaardigd in massafabricage, geldt ook hier dat het aantal producten dat aan de eindtest voldoet (opbrengst), uitsluitend voldoende groot is ithdien alle processtappen vrijwel zonder fouten worden dourlopen; dit is alleen mogelijk indien er een voldoend grote productic is die het financieel mogelijk maakt om op allerlei plaatsen controle-apparatuur te plaatsen om een $k$ waliteitsverbeterende terugkoppeling op het productieproces te verzorgen, en indien de mensen die aan het productieproces deelnemen volduende praktijkervaring opdoen om vrijwel alle storende invloeden op dat productieproces de baas te kunnen. Dit effect wordt het 'learning curve'-effect genoemd. Dat wil zeggen: de praktijkervaring opgedaan met de geaccumuleerde productie reduceert de kostprijs van het product. Het aardige is dat deze kostprijsreductie, verkregen met massaproducten, ook van positieve invloed is op soortgelijke producten die in kleinere aantallen in dezelfde fabriek worden geproduceerd bijvoorbeeld signaalprocessoren en microprocessors.
Dit maakt dat geheugens bij uitstek learn-ing-curve'trekpaarden voor de digitale ICindustric zijn, en dat halfgeleiderfirma's
met digitale IC-producten het in het algemeen beter kunnen bolwerken indien zij geheugens in hun productiepakket hebben. Alle producenten kennen dat effect en doen dan ook hun best geheugens in hun productiepakket op te nemen.

Verder ligt in dit artikel de nadruk hoofdzakelijk op de vraag: 'hoe werken nu halfgeleidergeheugens?' Dit zal met een aanschouwelijk model voor niet-ingewijden worden geillustreerd. Vervolgens zullen enige facetten van de geheugentechnologie worden besproken, en tenslotte zal een korte beschouwing over de internationale situatie op het gebied van de productie van halfgeleidergeheugens worden gegeven.

### Dynamische en statische geheugens

Informatie-eenheden worden vrijwel allijd in de vorm van digitale bits opgeslagen, de zogenaamde logische enen en nullen ' 1 ' en ' 0 '. In halfgeleidergeheugens worden de enen en nullen gepresenteerd door het al of niet opgeladen zijn van elektrische condensatortjes. In de praktijk kent men twee soorten geheugens: dynamische en statische geheugens. Om het verschil duidelijk te maken bezien we eerst een aanschouwelijk model: het water-analogon. Dit water-analogon gaat niet voor $100 \%$ op, maar kornt zeer dicht bij de elektronische waarheid. Het is een zeer geschikt model om niet-clektronici een inzicht in de werking van geheugens te geven.

#### Het water-analogon

Het dynamische geheugen. Stel dat we informatie moeten bewaren in de vorm van water in emmers, warvan niet te zeggen is dat ze niet zullen lekken - later zal blijken dat elektronische emmers bij kamertemperatuar nooit lekvrij zijn - en dat een volle emmer een ' 1 ' voorsteit en een lege emmer cen '0'.
Figuur la toont hel patroon ' 1011 ', enige tijd na het volledig vullen van de eerste, derde en vierde emmer. Door de gaatjes in de bodems van de eminers zal de informatie na verloop van tijd weglekken en moeten de em-
mers weer bijgevuld worden binnen de tijd dat de snelst lekkende emmer leeg raakt, anders weten we immers niet meer welke em$\mathrm{mer}(\mathrm{s})$ bijgevuld moeten worden. Hiermee is het dynamische geheugen gekarakteriseerd
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-061.jpg?height=123&width=637&top_left_y=900&top_left_x=389)

Figuur la
Water-analogonmodel van een dynamisch geheugen. Het digitale informatienatroon 1011 ' is apgeslagen door middel van water in lekkende emmers. Om de informatie niet te verliezen moeten de emmers weer hijgevuld worden binnen de rijd dat de snelst lekkende emmer leeg raakt.
de inhoud van de emmers moet regelmatig worden aangevuld - 'refreshen’ genoemd omdat de informatie niet vast is, maar dynamisch.

Het statische geheugen. Om van het regelmatig bijvullen van de emmers af te komen kunnen we bij iedere emmer natuurlijk een bijvulautomaat bouwen die er voor zorgt dat cen volle emmer vol blijft, maar daarentegen een lege emmer niet mag bijvullen. Een dergelijke constructic is te maken met behulp van een extra emmer en met door 4 vlotters bediende kranen, waarvan I wee aanvulkranen en twee afvoerkranen zoals aangegeven in figuur 1 b . De toevoerkranen TK en TK2 werken precies zoals de vlotterkranen in toiletstortbakken: zolang een bepaald waterniveau nog niet bercikl is staan ze open. De afvoerkranen AK1 en AK2 zijn in de bodems van de enımers gemonteerd. Doordat emmer 1 vol is wordt de afvoerkraan AK2 van emmer 2 opengezet. Door nu de afvoerkraan een grotere doorstroomopening te geven dan de toevocrkraan TK2, blijft emmer 2 ongevuld en blijft daardoor de afvoerkraan van emmer 1 gesloten. De volle. maar lekkende, emmer I wordt nu automatisch door tocvoerkraan TKl op niveau gehouden. Met emmer I vol en emmer 2 leeg wordt een ' 1 'gerepresentecrd. Een ' 0 '
krijgen we bij de andere situatic: emmer 1 leeg en emmer 2 vol.
De symmetrische constructie van figuur lb wordt een 'flip-flop' genoemd. Het voordeel van de 'flip-flop' is dat hij automatisch in de goede stand blifft statan, maar dat er een extra emmer en veel extra kranen nodig zijn, en dat bovendien meer water-lees energie wordt verbruikt dan nodig is voor het compenseren van het lekverlies van de volle emmer; immers de bodenkraan van de lege emmer staat open terwijl de toevoerkraan open staat.
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-061.jpg?height=527&width=674&top_left_y=1088&top_left_x=1052)

Figuur Ib
Water-analogonmodel van een statische geheugencel hestaande uit twee lek kende emmers: I en 2. en 4 door viotters bediende kranen. De volle emmer wordt nu automatisch on niveau gehouden. door toevoerkraan TKI. terwijl de afvoerkraan (AKI) gesloten blijft door het laag hlijvende waterniveau in emmer 2
In de getekende situatie representeert de cel een ' 1 '; met emmer 2 vol en emmer 1 leeg zou de cel een ' 0 ' representeren.

#### De halfgeleidergeheugens

Dynamische geheugens. Figuur 2a toont het elektrisch schema van een dynamische geheugencel voor de opslag van ćén informaticbit. De informatie wordt beward in de vorm van lading in de condensator C. Een volle condensator representeert cen ' 1 ', een lege een ' 0 '. In feite is de condensator - binnen de stippellijnen - analoog aan een emmer met water zoals weergegeven in figuur la. Om lading aan te brengen - het schrijven - en uit te koppelen - het lezen - is nog een transistor

T aangebracht dic bediend wordt door een commandodraad WL - de woordlijn - en die de geheugencondensator in verbinding kan brengen met een leesdraad BL - de bitlijn. De transistor T is een zogenaamde N -kanaals MOS-transistor die geleidend wordt als de stuurelektrode potentiaal positief is. Een dergelijke transistor is op te vatten als een elektronische schakelaar die gesloten is, als de stuurelektrode positief is en geopend als die negatief is.
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-062.jpg?height=345&width=632&top_left_y=1008&top_left_x=390)

Elektrisch schema van een dynamis he halfgelei-der-geheugencel bestaunde uit een condensator $C$ en een transistor T. De condensator. binnen de stippellijnen, is analoog uan een lekkende emmer, zoals neergegeven in fig. Ia. In de condensator kan elektrische lading aangebracht wordenschrijven - en ingekoppeld worden - lezen - deor middel van de transistor $T$ die bediend wordt door commandodraad WL - de woordlijn - en leesdraad BL - de bitlijn. Een volle condensator representeert een ' 1 ', een lege condensator een ' 0 '.

In de laboratoria kan men nu met de meest geavanceerde technieken dynamische geheugenchips maken met 256 kilobit (kb). I $\mathrm{kb}=2^{10}=1024$; een 256 kb geheugen bezit dus 262.144 bjts. Met massa-productieprocessen is men nu volop bezig 64 kb dynamische geheugenchips te fabriceren; de overschakeling naar 256 kb voor massaproductie wordı binnen enkele jaren verwacht. In de geavanceerde 256 kb -technologie neemt een dynamische geheugencel één tienduizendste vierkante millimeter in beslag (ter vergelijking: 20 van deze geheugencellen passen in de doorsnede van een inenselijke haar). Dit oppervlak is zo klein dat een microscoop nodig is om zo'n geheugencel visueel waar te nemen. Het oppervlak van een volledige 256 kb geheugenchip is ongeveer $50 \mathrm{~mm}^{2}: 26$ $\mathrm{mm}^{2}$ voor de cellen en $24 \mathrm{~mm}^{2}$ voor de stuurelektronica; cen pinknagel. De stuurelektro-
nica is nodig om de geheugencellen te adresseren en om de geheugencellen regelmatig te 'refreshen'. Dit laatste moet om de 2 milliseconden gebeuren omdat het, ook theoretisch, onmogelijk blijkt lekvrije condensatoren te maken. Gedurende het 'refreshen' van de geheugenchip kunnen geen informatieaanvragen van buitenaf in behandeling worden genomen; dit is een principieel nadeel van het dynamische geheugen.

Stutische geheugens. Figuur 2b toont het elektrisch schema van een statische geheugencel; binnen de stippellijnen is het wateranalogon van figuur lb geldig. De transistoren zijn ook hier de zogeheten N -kanaals transistoren, die geleidend worden als een positieve spanning op de stuurelektrode wordt gezet. De twee emmers worden gerepresenteerd door de condensatoren Cl en C2. De toevoerkranen TK1 en TK2 worden gerepresenteerd door de weerstanden R1 en R2, de afvoerkranen door de transistoren AK1 en AK2. Om de cel te kunnen lezen en schrijven zijn koppeltransistoren aangebracht naar twee bitlijnen. Het blijkt in de praktijk dat een statische geheugencel 3 à 4 maal zoveel ruimte in beslag neemt als een
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-062.jpg?height=513&width=632&top_left_y=1664&top_left_x=1064)

Figuur 2h
Alahirisch schema van een statische geheugencel. Binne'n de stippellijnen is het water-analogon van figuur Ib geldig; zo worden de twee emmers gerepresemeerd door de condensutoren C1 en C2. de tweverkranen TKI en TK2 dowr de weerstanden R| en R2. de afvoerkronen door de transistoren AKI en.AK2. Om de cel te kunnen lezen en schrijven zijn koppeltransistoren aungebrucht naar tnice billijnen.
dynamische cel. De mcest geavanceerde statische geheugenchips zijn 64 kb groot en hebben geheugencellen van vier tienduizendste vierkante millimeter. Het chip oppervlak is ongeveer $36 \mathrm{~mm}^{2}: 26 \mathrm{~mm}^{2}$ voor de cellen en $10 \mathrm{~mm}^{2}$ voor de stuurelektronica. Het relatieve oppervlakte-aandeel van de stuurelektronica is veel kleiner dan in dynamische geheugens, omdat nu de informatie niet 'gerefreshed' behoeft te worden. Dit laatste is voor de computer-architectuur erg plezierig; er zijn nu geen verboden toegangstijden tot het geheugen. Statische geheugens worden daarom ook vaak toegepast op IC's waarop ook rekenschakelingen zijn ondergebracht, zoals microcomputerchips.
Als nadeel van de statische geheugens geldt natuurlijk de lagere pakkingsdichtheid en het hogere energieverbruik van de geheugencellen.

### Geheugen technologie

Gezien de beperkte lengte van dit artikel kunnen slechts enkele facetten van de geheugentechnologie worden behandeld; een grondige behandeling moet daardoor achterwege blijven. De meeste halfgeleidergeheugenchips worden gemaakt in cen extended
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-063.jpg?height=435&width=641&top_left_y=1724&top_left_x=369)

Figuur 3
SEM-npmame van de darsnede van pen $N$-kanaals transistor zoals die in geheugencellen voorkomt. De lengte van de witte referemtiestrepen onder in het beeld is 1 micrometer: cín duizendste millimeter.
Technolugie en opname: dr. H. A. Harwig. Philips Natturkundig Lahoratorium en dr W. Voncken. Valvo. Hamburg.

NMOS technologie: N-channel Metal Oxide Semiconductor. De standaard NMOStechnologie voorziet uitsluitend in N -kanaals transistoren en condensatoren; in de meer uitgebreide (extended) vorm kunnen ook weerstanden worden gefabriceerd, zodat daarin de statische geheugencel van figuur 2 b gemaakt kan worden.
De geheugenchips worden gemaakt op siliciumschijven met een diameter van 10 cm , hierop worden bijvoorbeeld 250 chips van 30 $\mathrm{mm}^{2}$ gemaakt, waarop uiterst kleine geometrische details van enkele micrometers duizendste millimeters - voorkomen. Deze geometrische details worden door middel van fotolitografie vanaf maskers op de siliciumschijf overgebracht. De transistoren, condensatoren en weerstanden worden gemaakt door middel van ionenimplantaties. diffusies, hoge temperatuurstappen, oxidaties, aanbrengen van extra halfgeleiderlagen en isolaticlagen, opdamptechnicken, etsbaden, enzovoorts. Dit alles dient te geschieden met een uitermate grote precisic in zeer stofarme ruimtes met behulp van zeer gespecialiseerde apparatuur plus een enorme proceservaring en daardoor ontstane procesbeheersing.
Figuur 3 toont een SEM-opname van de doorsnede van een $N$-kanaals transistor. SEM staat voor scanning electron microscope, een methode van microscopic mel een beter scheidend vermogen dan een normale optische microscoop. Figuur 4 toont een SEM-opname van enige statische geheugencellen; duidelijk kan men de geometrische details herkennen. Figuur 5 toont een microscoopopname van cen 16 kb statische geheugenchip, gemaakt in een bestaand NMOSproductieproces; de chipafmetingen zijn 6,3 bij $4,3 \mathrm{~mm}$. De geheugencellen zijn in twee matrices gegroepeerd; de stuurelektronica bevindt zich in het midden en aan de kopse kanten van de chip.
Door de wens steeds meer geheugencellen op één chip te integreren, staat de technologie voortdurend onder druk om naar steeds kleinere geometrische details te gaan. In de modernste productieprocessen zijn deze 2 à 3 micrometer; hiermee kan men nu in zeer grote aantallen 64 kb dynamische en 16 kb statische geheugenchips maken. In ontwik.
keling zijn nu details van 1,5-2 micrometer, waarmee hel mugelijk is 256 kb dynamische en 64 kb statische geheugens te maken. Figuur 6 geeft een overzicht van de ontwikkeling sinds 1975 en een mogelijke extrapolalie naar de toekomst.
De nieuwste procestrent in geheugens is de omschakeling van NMOS naar CMOS; CMOS staat voor Complementary Metal Oxide Semiconductor. In de CMOS-technologie kan men zowel N -kanaals transistoren maken, die geleidend worden met een positieve spanning op de stuurelektrode, alswel

Figuur 5
Microscospopname van een $16 \mathrm{~kb}(268 \mathrm{~kb})$ statische geheugenchip gentaakt in bestaand NMOSproductieproces. De chipafmetingen zijn $6,3 \mathrm{bij}$ 4.3 mm .

Chip ontwerp: ir. K. H. W. Salters en dr. J. J. M. Kisomen. Philips Elcoma.
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-064.jpg?height=1786&width=1325&top_left_y=589&top_left_x=418)

Figuur 4
Bovenaanzicht. SEM-opname, van enige statische geheugencellen zoals die aan het oppervlak van een geheugenchip door een microscoop te zien zijn. De lengte van de referentiestrepen onder in
hel beeld is 10 micrometer: tien duizendste millimeter.
Technologie en opname: dr. H. A. Harwig. Philips Natuurkundig Laboratorium en dr. W. Voncken. Valvo. Haniburg.

P-kanaals transistoren, die geleidend worden met een negatieve spanning op de stuurelektrode. Door nu gebruik te maken van P-kanaals transistoren in plaats van weerstanden in de statische geheugencel van figuur $2 b$ kan het stroomverbruik van de lege emmer (zic TK2 in figuur lb) geëliminecrd worden, waardoor het energieverbruik drastisch kan worden gereduceerd.
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-065.jpg?height=433&width=672&top_left_y=942&top_left_x=390)

Figutur 6
Overzicht van de productie van dynamische en statische geheugenchips sinds 1975 en een mogelijke extrapolatie naar de tockomist.

### Internationale geheugenproductie

Sinds 1975 is de halfgcleidergeheugen-productie flink op gang gekomen, vooral in de Verenigde Staten. Echter al snel hebben Japanse bedrijven zich zeer succesvol op de geheugens gestort, waardoor ze nu een groot, en zelfs voor de meeste typen geheugens het grootste, marktaandeel in handen hebben. Zo geldt bijvoorbeeld voor dynamische 64 kb geheugens in 1982 de volgende marktverdeling: Japan $66 \%$, VS $33 \%$ en Europa $1 \%$. Voor statische geheugens is het Japanse aandeel nog groter tot zelfs $95 \%$ voor CMOSstatische geheugens. De VS en Europa stellen nu alles in het werk om hun positie te verbeteren.
Door de enorme vraag naar gehcugens en de steeds meer geavanceerde technologieën grocien de verkoopcijfers naar steeds grotere hoogte en nemen de nieuwere typen het om de 4-6 jaar van de oudere over. Figuur 7
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-065.jpg?height=367&width=673&top_left_y=534&top_left_x=1055)

Figuur 7
Wereldwijde verkoon. in miljoenen stuks, van dynamische geheugens sinds 1975, met een mogelijk toekomstbeeld na 1982. Voor statische geheugens geld een dergelijk beeld voor 2.56 kh . I $k h .4 k b .16$ kh en $64 k h$ geheugens.
toont voor dynamische geheugens de wereldwijde verkoop in miljoenen stuks. Nu in 1982 beginnen de dynamische 64 kb geheugens fors aan te lopen: in 1986 wordt de aanloop van 256 kb geheugens verwacht, eventueel opgevolgd dwor 1 Mb geheugens in het begin van de jaren 90 . Voor statische geheugens, die steeds een factor 4 kleiner zijn in bitcapaciteit, geldt een vergelijkbaar beeld.
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-065.jpg?height=1142&width=790&top_left_y=1595&top_left_x=1074)

## Afscheid Herman Hooymayers en Hans Creton 
Toespraak van Wim Lignac oud bestuurslid WND 

Beste Herman en Hans, Dames en Heren,

Vlak na de tweede wereldoorlog ontwikkelde zich in vooruitstrevende onderwijskringen, zoals de Werkgemeenschap voor Vernieuwing van Onderwijs en Opvoeding W.V.O., een dadendrang tot verbetering van het onderwijs. Er ontstonden werkgroepen voor deelproblemen, waaronder een voor wiskunde. Namen als die van Freudenthal en wijlen mevrouw Ehrenfest staan voor de pioniers die met groot élan hun ideeën uitwisselden. De natuurkundigen benijdden die groep, die
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-066.jpg?height=887&width=786&top_left_y=693&top_left_x=1064) onder zo voortreffelijke leiding grote beloften voor de toekomst inhield. De fysici hoopten in professor Minnaert ook zo'n motor te vinden.
De werkgroep voor natuurkunde didactiek werd opgericht, mede door professor Minnaert, maar helaas meende deze het voorzitterschap te moeten weigeren. U moet bedenken, dat we toen leefden in een tijd van groeiend McCarthyanisme. Het heeft. hier geen vormen aangenomen zoals in de V.S., maar toch werd het bestaan van het Verbond van Wetenschappelijke Onderzoekers enige tijd bedreigd door de aanwezigheid van de saloncommunist Minnaert. Daarom verzocht hij mij het voorzitterschap op mij te nemen om niet bij voorbaat de Werkgroep een verdachte naam te bezorgen. Minnaert is steeds de trouwste bezoeker geweest van onze maandelijkst bijeenkomsten.

Ik sta even stil bij het ontstaan van de Werkgroep om te laten zien hoe belangrijk de rol van de motor erachter is. Ideeën omtrent het IOWO zijn door Freudenthal verwerkelijkt, maar de Werkgroep voor Natuurkunde Didactiek heeft 17 jaar moeten wachten op zijn grote leider, want die zat bij de oprichting nog op de schoolbank. Het was de didactiekdocent Krans die de aandacht vestigde op de veelbelovende jongeman Herman Hooymayers.

Tot omstreeks 1960 bestonden de maandelijkse bijeenkomsten uit individuele bijdragen van de leden. Er waren er nogal wat die iets origineels te bieden hadden. Denk maar aan namen die ook nu nog aan de meesten bekend zijn:
Dijkwel, Frederik, Krans, Rekveld, Steller, Wijnnobel en Zwaan uit Zaltbommel. In de jaren zestig zakte de belangstelling. Het beperkte kringetje van vaste bezoekers had aan elkaar niet zoveel nieuws meer te vertellen en de tijd van 7 tot halftien 's avonds was te kort voor diepgaande besprekingen.

Het was een goede gedachte
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-067.jpg?height=1078&width=561&top_left_y=828&top_left_x=161)

Herman Hooymayers in het bestuur te halen, een man met nieuwe ideeën en organisatietalent, die het plan voor het houden van de jaarlijkse Woudschotenconferentie lanceerde. U kent het succes ervan. Het ledental van omstreeks honderd steeg snel, terwijl de inhoud van de conferenties, vastgelegd in de goed verzorgde conferentieverslagen, een niveau had en heeft dat respect afdwingt.

Zoals gebleken is in zijn laboratorium, heeft Herman ook de gave van het kiezen van de juiste medewerkers en hen te stimuleren tot het ontplooien van hun gaven. Ook bij zijn inbreng voor het organiseren van de Woudschotenconferentie blijkt steeds hoe goed hij de wetenschappelijke kaart van Nederland kent en hoe goed hij aanvoelt, welke problemen bij de natuurkunde leraren als belangrijk genoeg voor een conferentie onderkend worden.
Ik feliciteer de Werkgroep ermee, dat 17 jaar na de oprichting een werkelijk goede leider naar voren is gekomen en ik dank Herman voor de grote inzet van zijn krachten gedurende de daarop volgende 17 jaar.

De goede kijk op mensen bij het kiezen van zijn medewerkers bleek ook uit de keus van Hans Créton, die ons helaas eveneens als bestuurslid gaat verlaten. Hij heet penningmeester, maar dat feit alleen zou mij geen stof kunnen leveren
voor woorden van grote waardering. Nou ja, ik ben dankbaar, dat er iemand was die de gelden goed beheerde en administreerde. Hij deed het nauwgezet; dat gaf een veilig gevoel, maar al te veel nadruk op zijn boekhouderskunst voel ik als een schouderklopje voor de jongste typiste. Een nieuwe boekhouder zullen we wel vinden, maar de persoon Hans Créton zullen we missen. Zijn bijdragen aan de conferenties zijn onschatbaar groot. Ik heb voldoende ervaring op dat gebied om te weten hoeveel denkwerk en concrete voorbereidingswerkzaamheden essentieel zijn voor het gesmeerd lopen van een conferentie. Of de deelnemers zich prettig voelen, niet opgejaagd en toch steeds op tijd, hangt in hoge mate af van de alertheid van de man achter de schermen. Als jij, Hans, iets toezegt, dan kan de ander erop rekenen, dat het op tijd gebeurt. En als jij iets van een ander verlangt verpak je je verzoek zo vriendelijk, dat de ander er niet over denkt het te weigeren; hij aanvaardt het als een opdracht. Dat is een benijdenswaardige omgangskunst. Ik ben je dankbaar, dat je bent zoals je bent en betreur je vertrek uit het bestuur.

Herman en Hans, aan jullie naam de zal de herinnering aan de Woudschotenconferentie verbonden blijven na je bestuurlijke daad van euthanasie, waarbij ik vurig hoop, dat jullie wel aan een testament hebt gedacht. Laat jullie ervaring niet verloren gaan! Jullie opvolgers zullen het al moeilijk genoeg hebben om de aan jullie persoonlijkheid gebonden kwaliteiten gelijkwaardig te vervangen.
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-068.jpg?height=839&width=1147&top_left_y=1796&top_left_x=426)

## Afscheid Hans Creton en Herman Hooymayers

Ineke Geuzebroek-Frederik, bestuurstid WN D

Dames en Heren, het huidige werkgroepbestuur heeft mij afgevaardigd om Hans en Herman te bedanken. Ze hebben beiden de laatste vijftien jaar het werkgroepgebeuren op een zeer sterke en persoonlijke manier ingekleurd, zoals u weet.

Wat komt er allemaal kijken bij zo'n conferentie-organisatie? Van buitenaf is dat moeilijk te doorzien. De zaak verloopt meestal vlot en toch zitten er nogal wat onduidelijke kanten aan:

- hoe worden bestuursleden bijvoorbeeld gekozen?
- wie 'loot' er tussen leden en niet-leden bij beperkte plaatsruimte op de conferentie? Enkele jaren geleden toen we in bescheidener oorden bijeen kwamen speelde dat volop.
- hoe ziet het jaarlijkse financiële overzicht er precies uit? Onze financiën zijn in goede handen kan ik u verzekeren, maar welke kascommissie controleert dat?
- wie verzint de conferentietitel? Het komt voor dat deze in februari, als het gebeuren al lang heeft plaatsgevonden, alsnog wordt vastgesteld.
- hoe verlopen de bestuursbijeenkomsten? Tja, daar moet je bij zijn.

De interacties tussen Herman en Hans vormen een spektakel op zich. Het lijkt erop of de heren geen groter genoegen kennen dan eens lekker te botsen, met ons als toeschouwer.

Hun aanwezigheid bij de conferentie zelf was ook altijd van heel verschillende aard. De één bewaakte het product, de ander het proces, zoals dat in het jargon heet. Herman was hier aanwezig en keek of het product goed genoeg werd. Hans zorgde achter de schermen dat alles perfect verliep.
Toch hebben zij ook veel gemeen. Bijvoorbeeld een zeer belangrijke karaktereigenschap: hun intuītie. Een intuītie die zich richt op geheel verschillende gebieden. Van Hans heeft mij altijd getroffen dat hij een zeer fijn ontwikkeld gevoel heeft voor menselijke relaties. De intuitie van Herman richt zich feilloos op structuren in onderwijsland, op haalbare zaken voor de natuurkunde didactiek.

Deze conferentie is dankzij beide ingrediënten gegroeid van een kleine bescheiden bijeenkomst tot een tamelijk massaal gebeuren. De werkgroep heeft zeer veel leden en de deelnemersaantallen aan de conferentie groeien nog steeds. Jullie hebben daar een zeer fijne neus voor gehad. We maken ons ook een beetje bezorgd over de diepere betekenis van jullie terugtrekken. Zou de conferentie een aflopende zaak worden? Ik hoop van harte van niet.

Onze dank aan Hans en Herman willen we met een cadeautje tot uitdrukking brengen. Het organiseren van conferenties brengt een aantal zakelijke contacten met zich mee, maar ook persoonlijke contacten van mensen die zich voor een gemeenschappelijke zaak inzetten. Met hulp van jullie medebestuursleden uit de loop der jaren hebben we een persoonlijk aandenken voor jullie verzameld. Ieder heeft éën bladzijde van deze multo gevuld met zijn herinneringen aan dat bestuursgebeuren. Er staan bijdragen in van mijnheer Krans, van mijnheer Lignac - oudere bestuursleden - en van ons, het huidige bestuur.

Ook namens u allen, leden van de werkgroep, heb ik een cadeautje. Meestal weet je daar als verzamelde goede gevers niet direct wat van af, vandaar dat ik het nu ook u ga tonen.
Wij hebben een bekende Nederlandse kunstenaar bereid gevonden iets moois voor jullie te maken. De bekendheid van die kunstenaar komt niet direct tot uitdrukking doordat hij in het Rijksmuseum exposeert of zoiets. Zijn bekendheid ligt veeleer op didactisch terrein (het is bovendien nog familie van me). Hij heeft een versiering voor jullie huiskamers gemaakt. Voor jou Herman, als stadsmens, een stadsgezicht. Voor Hans hebben we, met hulp natuurlijk, een werkstuk in andere sfeer uitgezocht. Een landschap. Hiermee kun je vast in vorm komen als je droomt van een boerderijtje in de verre toekomst.....
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-070.jpg?height=892&width=1684&top_left_y=2040&top_left_x=177)
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-071.jpg?height=2497&width=1706&top_left_y=252&top_left_x=142)
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-072.jpg?height=2518&width=1716&top_left_y=248&top_left_x=137)
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-073.jpg?height=2525&width=1741&top_left_y=248&top_left_x=103)
subgroep 1 :

## Lesmateriaal 'elementaire deeftjes' 

Ed Buijtenweg, thea Hunsutes, Henk 't Hooft, Piet trompenaars.

Op verzoek van de commissie die het NVON-zomercongres 1983 te Amsterdam organiseerde hebben we lesmateriaal over 'elementaire deeltjes' samengesteld. Reacties op dit lesmateriaal hebben ons doen besluiten een $2 e$ versie te maken. Het materiaal vormt ons fysisch afstudeeronderwerp. Uitgangspunt is een VWOlessenserie met een te kiezen omvang van 6 tot 15 uur. We denken dat er ook aardige ideeën in te vinden zijn voor HAVO-klassen.

Het materiaal bestaat uit een groot deel leerlingopdrachten verdeeld in zes hoofdstukken. Om de opdrachten theoretisch te ondersteunen en om achtergrondinformatie te verschaffen is een reader met korte leesteksten samengesteld. Elk hoofdstuk begint met een overzicht van de te behandelen onderwerpen en begrippen. Gekozen is voor een modulesysteem, de opdrachten staan min of meer los van elkaar. De docent(e) kan een keuze doen en zo de accenten leggen op die onderwerpen die hij/zij belangrijk vindt of wil uitdiepen. Naast de leerlingopdrachten en reader zijn er lijsten opgesteld met literatuurverwijzingen, audio-visueel materiaal en nuttige adressen. Tijdens de presentatie op de congressen hebben we een paar voorbeelden van 'practicummateriaal' getoond, waarmee de modellen van elementaire deeltjes in materie geillustreerd werden. Als voorkennis is het HAVO/VWO programma kernfysica verondersteld. In het door ons samengestelde materiaal komen weinig formules en mathematische afleidingen voor. Ook quantummechanische begrippen hebben we, daar waar het verantwoord leek, vermeden.
Het materiaal is bedoeld voor alle leerlingen, d.w.z. niet bij uitstek voor de in de natuurkunde getalenteerden.

### A: Materiaal in model

Een voorbereidend hoofdstuk waardoor leerlingen

- de gewenste associaties krijgen bij het begrip elementair deeltje
- zicht krijgen op het universeel geldig zijn van de natuurwetten
- kennis nemen hoe in de geschiedenis het beeld over de fundamentele bouwstenen van de materie telkens weer veranderde. In dit kader vooral aandacht voor het atoommodel uit de jaren ' 30.


### B: Quarks en leptonen

In dit hoofdstuk veel puzzelachtige opdrachten waardoor leerlingen

- weten dat protonen en neutronen samengesteld zijn uit quarks
- een aantal belangrijke eigenschappen van quarks leren kennen
- de generaties van leptonen leren.
- zicht krijgen op de systematiek en symmetrie bij de quark- en leptonenfamilie en bij de bouwregels voor baryonen en mesonen.


### C: Wisselwerkingen

Aan de hand van veel voorbeelden worden toegelicht

- de vier "klassieke" typen wisselwerking
- de veranderingen die de hoge energie fysica in dit klassieke beeld heeft aangebracht
- eigenschappen van wisselwerkingsdeeltjes (graviton, gluon, foton, $W^{+}, W^{-}$en $Z$ ).
- reacties beschreven met Feynmandiagrammen.


### D: Behoudswetten

We bespreken

- de essentiële rol van behoudswetten in natuurkundige theorieën
- absolute en niet-absolute behoudswetten
- nieuwe eigenschappen van quarks als: vreemdheid, tover, schoonheid
- het gebruik van behoudswetten als waren het meetinstrumenten, bij het controleren en voorspellen van reacties en berekenen van grootheden.


### E: Meettechnieken

Leerlingen maken kennis met

- de gigantische laboratoria en complexe meettechnieken van de hogere energie fysica
- CERN
- belangrijke typen versnellers en detectoren
- analyse van bellenvatfoto's.

### F: En verder.....
We discussiëren en filosoferen met de leerlingen over

- de opzet van het Nederlandse onderzoek in hoge energie fysica
- de maatschappelijke en culturele relevantie, de waarde van dit onderzoek
- de vraag waarom we steeds weer geboeid raken over de vraag wat de fundamentele bouwstenen van de materie zijn.

### Enkele reacties op ons materiaal
Je moet zeker in je onderwijs aan deze onderwerpen aandacht besteden. Het is iets wat nu speelt. Leerlingen zijn erin geīnteresseerd. Het is toch te gek dat we in feite met de natuurkunde in 1932 ophouden.

Moet je speculatieve theorieën bespreken? Kun je je niet beperken tot datgene waarover de 'geleerden het eens zijn' versus je moet natuurkunde niet als een triomftocht presenteren. Natuurkunde is een levend vak. Zoeken, zaken half begrijpen, verwarring, fouten maken is ook natuurkunde.

Je zou je tweede keuzeonderwerp al in de 5 e klas moeten kunnen doen en het liefst dan een onderwerp buiten de lijst. Jullie materiaal lijkt daar een geschikt voorbeeld voor.

Het is juist aandacht te besteden aan de ontwikkeling van theorieën en modellen in de natuurkunde en aan het waarom van wetenschappelijk onderzoek. Maar dit moet je niet beperken tot de hoge energie fysica. Je geeft een onjuist beeld van het feitelijke werk aan het onderzoek van elementaire deeltjes als je alleen kwalitatief/beschouwend te werk gaat en geen aandacht besteed aan kwantitatieve aspecten. Hoge energie fysica onderscheidt zich daarin niet van andere takken van de natuurkunde.

Een groot probleem is de leerlingen overzicht te geven van de behandelde onderwerpen, hun de rode draad te laten ervaren. Leerlingen voeren de opdrachten wel uit maar zien door de bomen het bos niet meer.

Moeten we de behandeling van dit type onderwerpen, zoals het werken met modellen, wel tot de bovenbouw uitstellen? Zijn er geen mogelijkheden voor een onderbouw c.q. MAVO-versie?

Nadere informatie bij de sectie natuurkunde van
d'Witte Leli
Rapenburgerstraat 173
1011 VM Amsterdam
Telefoon: 020-240640.

Voor Nikhef en CERN bij Nikhefvoorlichting
J. Oberski

Postbus 41882
1009 DB Amsterdam
Telefoon: 020-5929111.

Bestellen:
2e versie door overmaking van $f$ 6,50 op postgiro 3251900 t.n.v. d'Witte Leli te Amsterdam, onder vermelding van: 'natuurkunde, elementaire deeltjes'.
le versie (wat dikker en completer maar daardoor minder geschikt als leerlingenmateriaal) door overmaking van $f 10,00$ op bovengenoemd postgironummer.
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-077.jpg?height=921&width=1307&top_left_y=1903&top_left_x=531)
subgroep 2 :

## Mogelijkheden van hoge energie fysica in het vwo

Jar Louwens

Bij een cursus 'Hoge energie fysica' kan je vele kanten uit. Het accent kan worden gelegd op onder meer

- de structuren in de verzameling elementaire deeltjes
- de productie van deeltjes (SPS, enz.)
- de detectiemethoden (detectoren, experiment opstellingen
- de filosofische aspecten
- de meer fundamentele theoretische modellen.

Al met al een breed gebied en wanneer 'Hoge energie fysica' ooit keuzevak VWO wordt, dan zal zeker een keuze gemaakt moeten worden.

Voor het Mollerinstituut in Tilburg is door ondergetekende een cursus ontwikkeld die van alles wat heeft en waarin een practicum, te weten de analyse van een tiental bellenvatfoto's, een centrale plaats inneemt. De cursus omvat circa 28 lessen van elk 45 minuten.
De opzet is in grote lijnen als volgt:
a) algemene inleiding
b) behoudswetten
c) practicum bellenvatfoto's
d) experimenteel gedeelte
e) nieuwe ontwikkelingen.
ad a) In de inleiding worden een aantal uiteenlopende zaken behandeld zoals: een eerste kennismaking met elementaire deeltjes, bespreking van de vier wisselwerkingen, het begrip kans, relativistische relatie tussen energie en impuls, deeltjes-golf dualiteit, onzekerheidsrelaties enz.
ad b) Hier wordt het begrip kwantumgetal ingevoerd. Er worden uiteraard de meeste absolute en niet-absolute behoudswetten besproken. Hierbij wordt veel gebruik gemaakt van in hoofdstuk 1 opgedane kennis.
ad c) Het practicum is feitelijk niet het derde hoofdstuk. In feite worden de foto's, min of meer in volgorde van complexiteit, in de loop van de cursus doorgewerkt. Dit wordt gedaan via een stapsgewijze instructie die tot op zekere hoogte bovendien kan bijsturen.

Ondanks deze bijsturing blijft er nog veel speurwerk over. Bij de analyse van de foto's komen veel zaken, welke eerder zijn besproken, aan de orde. Problemen die bij vrijwel elke foto opduiken zijn bijv.:

- welke wisselwerking was in het spel?
- was het een verval of een interactie?
- waren er neutrale deeltjes (impulsbehoud!)
- bepaling van de totale begin-energie
- selectie van mogelijke processen m.b.v. de behoudswetten.
ad d) Hier worden de versnellers en de detectoren behandeld. Er worden bepaalde meetmethodes besproken. Zaken die aan de orde komen zijn bijz.
- hoe maak je een bundel $\mathrm{K}^{-}$mesonen
- voor- en nadelen van SPS t.o.v. opbergringen
- meting van levensduur van een deeltje.
ad e) In het laatste gedeelte van de cursus komt het quarkmodel ter sprake vrij uitgebreid zelfs want de lading van de quarks wordt er bijvoorbeeld 'uit het model' gehaald. Maar ook onderwerpen zoals de relatie tussen dracht van de wisselwerkingen en de massa van de drager, de unificatie van de wisselwerkingen, kleur, het toenemend aantal quarks en leptonen en 'bunch hunting' komen ter sprake.

Hoewel de cursus is geschreven voor NLO studenten is ze, in grote lijnen, voor VWO leerlingen zeker toegankelijk. De hoeveelheid stof is weliswaar te groot maar er is zonder al teveel moeite wel wat te snoeien.
Ik geef de cursus al sinds een jaar of zes en mijn ervaringen zijn zeker positief. Mijn ervaring is ook dat zonder de analyse van de bellenvatfoto's de cursus aanzienlijk in waarde zou dalen; het zou veel te veel 'droogzwemmen' zijn geweest.
subgroep 4 :

## Relativiteitstheorle

### Ruimtetijd Diagram

Voorval: Fysische gebeurtenis met een scherp bepaalde plaats op een scherp bepaalde tijd.

Wereldlijn: Voorvallen in de geschiedenis van een deeltje vormen een wereldlijn.

### Inertiaalsystemen

Referentiesysteem: Achtergrond van waaruit de beweging van een deeltje wordt beschreven.

Inertiaalsysteem: Een referentiesysteem
waarin versnellingsmeters geen uitslag vertonen.

Voorbeelden inertiaalsystemen: Vrij
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-080.jpg?height=281&width=673&top_left_y=898&top_left_x=1104)
ref.sys. aarde ref.sys. trein vallende lift. Satelliet. Zij kunnen bestaan vanwege unieke eigenschap gravitatie: Alle puntdeeltjes bewegen hetzelfde vanuit dezelfde beginsituatie.

Aarde (laboratoriumstelsel): Niet-inertiaalsysteem. Valt voor die proeven als inertiaalsysteem op te vatten waarin de gravitatie geen rol van betekenis speelt.
Betekenis intertiaalsystemen: Zie $1^{e}$ postulaat van Einstein.
Eigenschap inertiaalsystemen: Bewegen eenparig ten opzichte van elkaar, als zij in elkaars buurt zijn.

Gevolg eigenschap: Wereldijnen inertiële waarnemers zijn recht (in het ruimtetijd diagram van een inertiaalsysteem).

### Postulaten Einstein

$1 e$ : Alle inertiaalsystemen zijn fysisch gelijkwaardig.
2e: Licht haalt licht niet in. (In een inertiaalsysteem beweegt licht rechtlijnig.)
( $1^{\mathrm{e}}$ postulaat betekent verwerping ethertheorieën.
$2^{e}$ postulat volgt uit waarneming dubbelsterren.)

### De radarmethode: Bepaling coördinaten voorval
Conventie: $t$ - en $x$-as 20 dat wereldiijnen
lichtpulsen evenwijdig of loodrecht.
(bijv.: 1 cm op t-as: 1 jr
1 cm op x -as: 1 jr )
Elementen radarwaarneming aan voorval P .
Voorval 0: Tijd van inertiële waarnemer $\boldsymbol{Z} \approx 0$
Voorval E: Emissie radarpuls. Tijd $\tau^{e}$
Voorval P: Zendt puls terug naar waarnemer.
Voorval A: Aankomst radarpuls bij inertiële waarnemer. Tijd $\tau^{\boldsymbol{a}}$

Vraag: Helk tijdstip $t$ geeft de klok van de inertiële waarnemer aan als het voorval P plaats vindt?

Antwoord: Gelijktijdigheidsdefinitie van Einstein.
Voorval O bij de inertiële waarnemer dat midden tussen $E$ en $A$ gebeurt is per definitie gelijktijdig met $P$.

Met andere woorden: De tijd t gemeten bij het voorval $Q$ is:

$$
t=\frac{1}{2}\left(\tau^{a}+\tau^{e}\right)
$$

en de inertiële waarnemer zal ook aan voorval $P$ dit tijdstip toekennen.

Gevolg: De reistijd van de radarpuls van inertiële waarnemer naar $P$ (heenweg) is gelijk aan de reistijd van de puls van $P$ naar de waarnemer (terugweg).
Heenweg:

$$
t-\tau^{e}=\frac{1}{2}\left(\tau^{a}-\tau^{e}\right)
$$

terug : $\tau^{a}-t=\frac{1}{2}\left(\tau^{a}-\tau^{e}\right)$
Definitieve afstand $x$ van $P$ tot inertiële waarnemer:

$$
x=\frac{1}{2} c\left(\tau^{a}-\tau^{e}\right)
$$

Bepaling snelheid deeltje:

 $v=\Delta x / \Delta t$

$\Delta t, \Delta x$ witgedruct in wavenemings.
grootheden $\Delta \tau^{a}$ en $\Delta T^{e}$
$\begin{aligned} & \Delta t=\frac{1}{2}\left(\Delta \tau^{a}+\Delta \tau^{e}\right) \\ & \Delta x=\frac{1}{2} c\left(\Delta \tau^{a}-\Delta \tau^{e}\right)\end{aligned}, \begin{aligned} & b_{j v} v \\ & \Delta t=t_{2}-t_{1}=\frac{1}{2}\left(\tau_{2}^{a}+\tau_{2}^{e}\right)-\frac{1}{2}\left(\tau_{1}^{a}+\tau_{1}^{e}\right)= \\ & =\frac{1}{2}\left(\tau_{2}^{a}-\tau_{1}^{a}\right)+\frac{1}{2}\left(\tau_{2}^{e}-\tau_{1}^{e}\right)=\frac{1}{2}\left(\Delta \tau^{a}+\Delta \tau^{e}\right)\end{aligned}$
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-082.jpg?height=775&width=526&top_left_y=561&top_left_x=1366)
lnverse:
$\Delta \tau^{a}: \Delta t+\frac{\Delta x}{c}$
$\Delta \tau^{e}=\Delta t-\frac{\Delta x}{L}$

### Doppler-factor en optellen van snelheden

Betekenis gelijkwaardigheid voor radarwaarneming.
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-082.jpg?height=411&width=520&top_left_y=1919&top_left_x=247)

Signaal van $W$ naar $W^{\prime}$
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-082.jpg?height=433&width=554&top_left_y=1888&top_left_x=1130)

Signaal van W' naar W

Tijdsduren van emissie en aankomst hebben vaste verhouding:
Voor $W$ naar $W^{\prime}: \frac{\Delta \tau^{a^{\prime}}}{\Delta \tau^{e}}=K_{W \rightarrow W^{\prime}}$
Voor $W^{\prime}$ naar $W$ : $\frac{\Delta \tau^{a}}{\Delta \tau^{e^{\prime}}}=K_{W^{\prime} \rightarrow W}$

Gelijkwaardigheid inertiële waarnemers betekent:

Dus

$$
K_{w \rightarrow w^{\prime}}=K_{w \prime \rightarrow w}=K
$$

![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-083.jpg?height=129&width=991&top_left_y=416&top_left_x=450)

 factor $K$ en snelheid.

Bij de radarwaarneming rechts geldt:
$\left.\begin{array}{l}\Delta \tau^{\prime}=K \cdot \Delta \tau^{e} \\ \Delta \tau^{a}=K . \Delta \tau^{\prime}\end{array}\right\} \Rightarrow \Delta \tau^{a}=K^{2} \Delta \tau^{e}$
Gevolg:

$$
K=\sqrt{\frac{\Delta \tau^{a}}{\Delta \tau^{e}}}=\sqrt{\frac{\Delta t+\frac{\Delta x}{c}}{\Delta t-\frac{\Delta x}{c}}}=\sqrt{\frac{1+\frac{v}{c}}{1-\frac{v}{c}}}
$$

Inverse:

$$
v=\frac{\Delta x}{\Delta t}=c \cdot \frac{\Delta \tau^{a}-\Delta \tau^{e}}{\Delta \tau^{a}+\Delta \tau^{e}}=c \cdot \frac{K^{2}-1}{K^{2}+1}
$$

![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-083.jpg?height=614&width=443&top_left_y=455&top_left_x=1399)
$W$ ' heeft snelheid
v t.o.v. W

Interpretatie van K: Doppler-factor.
Signaal van $W^{\prime}$ naar $W$ :
In $\Delta \tau^{\boldsymbol{e}^{\prime}} N$ trillingen uitgezonden, dus: $\quad \Delta \tau^{e^{\prime}}=N . T .{ }^{\prime}=N \cdot \frac{\lambda^{\prime}}{c}$
In $\quad N$ trillingen aangekomen, dus: $\quad \Delta \tau^{a}=N . T .=N . \frac{\lambda}{c}$
Dit betekent in $\Delta \tau^{\mu}=K . \Delta \tau^{e^{\prime}}:$

$$
\lambda=\lambda^{\prime} \sqrt{\frac{1+\frac{v}{c}}{1-\frac{v}{c}}}
$$

$\boldsymbol{\lambda}^{\prime}$ : golflengte bron
$\boldsymbol{\lambda}$ : golflengte waarnemer.
Optellen van snelheden.
$v$ : snelheid deeltje t.o.v. N
$v^{\prime}: ~ s n e l h e i d ~ d e e l t j e ~ t . o . v . ~ H ' ~$
$v_{r}$ : relatieve snelheid van $W^{\prime}$ t.o.v. W
$\left(v_{r}^{\prime}=-v_{r}\right.$ : relatief $W_{\text {t.o.v. }} W^{\prime}$ ).
Analoog: $K, K^{\prime}, K_{r}$.
Er geldt: $\Delta \tau^{\prime}=K^{\prime} \cdot \Delta \tau e^{\prime \prime}$
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-083.jpg?height=254&width=888&top_left_y=2138&top_left_x=503)

Snelheid

$$
v^{\prime}=c \cdot \frac{K^{2}-1}{K^{2}+1}=c \cdot \frac{\left(K^{\prime} \cdot K_{r}\right)^{2}-1}{\left(K^{\prime} \cdot K_{r}\right)^{2}+1}=c \frac{\frac{1+\frac{v^{\prime}}{c}}{1-\frac{v^{\prime}}{c}} \cdot \frac{1+\frac{v_{r}}{c}}{1-\frac{v_{r}}{c}}-1}{\frac{1+\frac{v^{\prime}}{c}}{1-\frac{v^{\prime}}{c}} \cdot \frac{1+\frac{v_{r}}{c}}{1-\frac{v_{r}}{c}}+1}=\ldots=\frac{v^{\prime}+v_{r}}{1+\frac{v^{\prime} v_{r}}{c^{2}}}
$$

### Eigentijd

Meting eigentijd.
Deeltje van voorval $P$ naar voorval $Q$.
Eigentijd: Tijd gemeten door inertiële waarnemer die met deeltje meereist.
Met radar kan ook andere inertiële
waarnemer de eigentijd $\Delta \tau$ bepalen:
$\left.\begin{array}{l}\Delta \tau=K . \Delta \tau^{e} \\ \Delta \tau a=K . \Delta \tau\end{array}\right\} \Rightarrow \Delta \tau^{2}=\Delta \tau^{a} . \Delta \tau^{e}$
Direct gevolg: Tijddillatatie
$x$ en $y$ positieve grootheden
Rekenkundig gemiddelde: $\frac{1}{2}(x+y)$
Meetkundig gemiddelde: $\sqrt{x \cdot y}$
Er geldt:
$\sqrt{x \cdot y}<\frac{1}{2}(x+y)$
Gevolg:
$\Delta \tau<\Delta t$
Een paradox?
Voor waarnemer: $\boldsymbol{\Delta} \boldsymbol{\tau}$ gemeten door bewegende klok. Tijddillatatie betekent dat bewegende klokken langzamer lopen dan stilstaande.
Echter: Voor deeltje is $\Delta t$ gemeten door bewegende klok. Geldt dus ook $\boldsymbol{\Delta t} \leqslant \boldsymbol{\Delta} \boldsymbol{\tau}$ ?

Oplossing paradox: Gelijktijdigheid is relatief.
Voor inertiële waarnemer:
$R$ (midden tussen $E$ en $A$ ) gelijktijdig met $Q$.
Voor deeltje:
$S$ (midden tussen $E^{\prime}$ en $A^{\prime}$ ) gelijktijdig met $R$ en later dan $Q$.
Schema:
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-084.jpg?height=463&width=951&top_left_y=2090&top_left_x=260)
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-084.jpg?height=2071&width=684&top_left_y=344&top_left_x=1287)

De waarnemer trekt de conclusie dat $\Delta t$ de tijd is tussen $P$ en $Q$. Voor de waarnemer is de eigentijd $\Delta \tau$ tussen $P$ en $Q$ met een bewegende klok. Dus $\Delta \tau<\Delta t$ voor waarnemer.
Voor het deeltje geldt de conclusie: $\Delta t^{\prime}$ tijd tussen $P$ en $R$, en voor het deeltje is $\Delta t$ tussen $P$ en $R$ met een bewegende klok. Dus voor het deeltje : $\Delta t<\Delta t^{\prime}$

Eigentijd en coördinaten.
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-085.jpg?height=218&width=919&top_left_y=807&top_left_x=439)

Omdat $\Delta x=v . \Delta t$ volgt hieruit:

$$
\Delta \tau=\Delta t \cdot \sqrt{1-\frac{v^{2}}{c^{2}}}
$$

(tijddillatatie van Einstein).
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-085.jpg?height=467&width=441&top_left_y=804&top_left_x=1368)

### Veroudering van een tweeling
I en II vormen een tweeling.
I blijft eenparig bewegen ten opzichte van een inertiaalsysteem. II verlaat I
(voorval P) en komt later weer terug bij I (voorval Q).

Eigentijd van I.
Eén inertiële waarnemer die meereist met I meet $\Delta \tau_{\mathrm{I}}$ tussen P en Q .

Eigentijd van II.
Vele inertiële waarnemers zijn nodig om de eigentijd tussen $P$ en $Q$ te meten. Bijv. reist rechts eerst (1) mee die dan meet: $\Delta \tau_{1}$ daarna (2) die meet $\Delta \tau_{2}$ en (3) meet $\Delta \tau_{3}$. De eigentijd voor II tussen $P$ en $Q$ is dan:

$$
\Delta \tau_{\text {II }}=\Delta \tau_{1}+\Delta \tau_{2}+\Delta \tau_{3}
$$

![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-085.jpg?height=769&width=357&top_left_y=1691&top_left_x=1456)

Er geldt ('klokparadox'):

$$
\Delta \tau_{I}>\Delta \tau_{I}
$$

Dus I veroudert meer dan II.
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-086.jpg?height=907&width=1298&top_left_y=270&top_left_x=377)

Voorbeeld van bewijs.
II eenparig weg van I (tussen $P$ en $T$ ).
II meet dan $\boldsymbol{\Delta} \boldsymbol{\tau}_{\boldsymbol{q}}$. II eenparig terug naar I
(tussen $T$ en $Q$ ). II meet dan $\Delta \tau_{2}$.
I doet radarmeting aan $T$. $S$ is voor I
gelijktijdig met $T$. I meet eerst $\Delta t_{4}$
(tussen $P$ en $S$ ) en dan $\Delta t_{2}$ (tussen $S$ en $Q$ ).

$$
\begin{aligned}
& \Delta \tau_{I}=\Delta \tau_{1}+\Delta t_{2} \\
& \Delta \tau_{\pi}=\Delta \tau_{1}+\Delta \tau_{2}
\end{aligned}
$$

![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-086.jpg?height=586&width=277&top_left_y=1748&top_left_x=1548)
met $\Delta \tau_{1}<\Delta t_{1}$ en $\Delta \tau_{2}<\Delta t_{2}$
Praktisch rekenen met $\Delta \tau^{2}=\Delta t^{2}-\frac{\Delta x^{2}}{c^{2}}$

### Lengtecontractie

Inertiële waarnemer W' gaat met snelheid $v$ over een lat die stilstaat in het inertiaalsysteem van $W$.

Lengte lat voor $\mathrm{W'}^{\prime}$ :

$$
L^{\prime}=v . \Delta \tau
$$

Lengte lat voor $W$ :

$$
\mathrm{L}=\mathrm{v} \cdot \Delta \mathrm{t}
$$

$\mathrm{L}=\mathrm{v} \cdot \Delta \mathrm{t}$
Substitutie in $\Delta \tau^{2}=\Delta \mathrm{t}^{2}-\frac{\mathrm{x}^{2}}{\mathrm{c}^{2}}$ levert
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-087.jpg?height=323&width=505&top_left_y=952&top_left_x=319)
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-087.jpg?height=671&width=514&top_left_y=532&top_left_x=1312)

Dus lat korter ininertiaalsysteem met $W^{\prime}$ waarin lat beweegt dan in inertiaalsysteem van $W$ waarin lat stil staat.

Enkele andere onderwerpen.
Hoofdstuk I : Zie voorafgaande. Verder: Geen dwarscontractie. Aberratie sterlicht. Lichtkegels en causaliteit.
Hoofdstuk II : Energie en impuls. Resp. $U=m c^{2} \cdot \frac{\Delta t}{\Delta \tau} \quad p=m \frac{\Delta x}{\Delta \tau}$
Hoofdstuk III : Algemene relativiteitstheorie. Gravitatie-roodverschuiving. Afbuiging sterlicht door zon. Zwarte gaten. Kosmologie.

## Wetenschapsvisie' en -onderwïs
 Kees Hferringman

De wetenschapsfilosofieën van Mach en Einstein aan Europese zijde en die van het Pragmatisme aan Amerikaanse zijde hebben minstens twee kenmerken gemeenschappelijk:

- Uitgangspunt van wetenschapsbeoefening zijn onze ervaringen (in de breedste zin opgevat), niet de dingen of verschijnselen om ons heen. Wat wij als zodanig benoemen is immers niets anders dan het product van onze ervaringen. Wetenschapsbeoefening vermeerdert en verrijkt onze ervaringswereld. Vroegere ervaringen kunnen daarbij getransformeerd worden. Daardoor ontstaan nieuwe en verderreikende beelden van wat wij de "werkelijkheid" noemen.
- Als wetenschap ons nieuwe en verdere beelden van de wereld verschaft is wetenschap instrumenteel: ze geeft ons meer greep op de wereld. In de woorden van Ernst Mach: "Het is biologische taak van de wetenschap om het volledig ontwikkelde individu een zo volmaakt mogelijk hulpmiddel te verschaffen waarmee hij zich kan oriënteren. Geen enkel ander wetenschapsideaal kan verwezenlijkt worden en elk ander moet zinloos zijn.
De Amerikaanse filosoof John Dewey benadrukt het instrumentele karakter van natuurkundige wetten in een kort artikel voor natuurkundeleraren:
" Almost all intellectual subjects have inherited notions of law from earlier thought which are essentially "metaphysical" in character - in the bad sense of metaphysical. Laws are conceived either after the analogy of jural and legal ordinances as cast iron decrees which somehow "govern" facts and events; or else as mere sequences and coexistences that happen to be uniformly repeated in these facts and events. Conceived in either of these ways laws lack intellectual vitality and significance. Instead of being organic aids to thinking, they mark fixed external limits that have been set to thinking. The very notion of law becomes a confusing puzzle. Logically, laws are the general method by which we introduce continuity and order in experiences otherwise discrepant and mixed up. They are instrumentalities of bridging over the gap in our experience of things; they are instrumentalities of reducing seeming conflicts of harmony."

Wat heeft dit enigszins kaal aandoende instrumentalisme voor het onderwijs te betekenen?
We beperken ons hier tot de betekenis van de ervaring die in bovengenoemde visies zo centraal staat. In "Democracy and Education" beschrijft Dewey de nieuwsgierigheid (reeds in de oudheid als de basis voor wetenschapsbeoefening beschouwd) als een niet op zichzelf staande faculteit, maar als een noodzakelijk gevolg van wat ervaring is:
"Curiosity is not an accidental isolated possession; it is a necessary consequence of the fact that an experience is a moving, changing thing, involving all kinds of connections with other things. Curiosity is but the tendency to make these conditions perceptible." Wat moeten opvoeders (leraren?) hiermee?
"It is the business of educators to supply an environment so that this reaching out of an experience may be fruitfully rewarded and kept continuously active. - - - One may cook, or hammer, or walk, and the resulting consequences may not take the mind any farther than the consequences in the literal - or physical - sense. But nevertheless the consequences of the act remain far-reaching. - - - To cook is to utilize heat and moisture to change the chemical relations of food materials; it has a bearing upon the assimilation of food and the growth of the body. The utmost that the most learned men of science know in physics, chemistry, physiology is not enough to make all these consequences and connections perceptible. The task of education, once more, is to see to it that such activities are performed in such ways and under such conditions as render these connections as perceptible as possible." Kan men zich een kortere en betere filosofische rechtvaardiging voor het nieuwe vak Natuuronderwijs wensen?
Hij dateert van 1916.
subgroep 6

## Natuurkunde rond 1900

Bram ten Hacty Frunk Sener

'Natuurkunde rond 1900' is een lesthema dat op dit moment ontwikkeld wordt voor VWO-5 binnen het samenwerkingsverband PLON-UVA-RUG.
In het voorjaar van 1984 moet het via de proefscholen voor het eerst in gedeelten de klas in.

Globale opzet van het thema.
fase 1: Negentiende eeuwse natuurkunde van deeltjes en golven via experimenten en leesteksten. Aan de orde komen bijvoorbeeld Brownse beweging, Dopplereffect, interferentie, polarisatie, diffusie. Leerlingen moeten een goed beeld ontwikkelen van het deeltjes wereldbeeld en het golf wereldbeeld.
fase 2: Waarneming en theorievorming. Daarbij is het de bedoeling dat leerlingen inzien dat het interpreteren van waarnemingsresultaten afhankelijk is van het wereldbeeld. Het is daardoor tevens een inleiding op wetenschapsontwikkeling en (heel voorzichtig) wetenschapsfilosofie.
fase 3: In drie paralelle stromen worden m.b.v. historisch materiaal de 'nieuwe stralen' geīntroduceerd.
Kathodestralen - Röntgenstralen - Radioactieve stralen.
fase 4: Onder de titel 'Engelsen en Duitsers' willen we in spelvorm nagaan hoe rond 1900 de discussie over het deeltjes/golf karakter van kathodestralen is verlopen. De theorievorming uit fase 2 wordt gebruikt om de strijd tussen Herz/v.Lenard enerzijds en Thomson anderzijds te doorgronden.
In het echt wint Thomsom's deeltjesmodel; in het spel op dit moment ook.
fase 5: Verdere voortgang der fysica: foto-elektrisch effect, Planck, DavissonGermer, dualiteit, complementariteit.
Na de informatie-overdracht moet duidelijk worden via herbespreking van het spel uit fase 4 dat èn Thomson èn Herz gelijk hadden.

In de Woudschoten-workshop hebben we beide keren het spelverloop van fase 2 en fase 4 nagespeeld. De discussie spitste zich toe op de haalbaarheid van het rollenspel 'Engelsen en Duitsers' gezien de fysische interpretaties en gedachtensprongen die van leerlingen worden geëist.
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-091.jpg?height=920&width=1321&top_left_y=1808&top_left_x=482)
subgroep 8 :

## Mogelijke gevolgen van recent wetenschapsonderzoek voor het natuurkunde onderwijs 

Wiehe Byiker

In beide groepen is gediscussieerd naar aanleiding van de stelling dat in het huidige natuurkunde-onderwijs een verouderd beeld van natuurwetenschappen aan leerlingen wordt overgedragen; mogelijkheden om een beeld over te dragen dat meer met de werkelijkheid overeenstemt werden besproken.

Uitgangspunt van deze discussie vormde het artikel van Wiebe Bijker: 'Het beeld van de natuurwetenschappen in ons onderwijs - Mogelijke gevolgen van recente wetenschapsfilosofische inzichten voor de didactiek der natuurwetenschappen', Faraday, vol. 51 (juni 1982), 79-85. Hieronder volgt een korte samenvatting.

1. In het huidige natuurkunde-onderwijs wordt impliciet veelal het volgende beeld van natuurwetenschappen overgedragen, ze zijn:

- belegen
- almachtig
- van mensen vervreemd
- waardevrij
- rationeel
- bron van technische innovaties.

2. Dit beeld klopt niet met recente inzichten in hoe het wetenschapsbedrijf reilt en zeilt en in wat de aard van wetenschappelijke kennis is.
3. Conclusie: ze houden leerlingen min of meer voor de gek.
4. En bovendien: het verouderde beeld (zie 1) is didactisch erg belemmerend en voor een opvoeding tot mondige burgers zelfs schadelijk.
5. Een nieuw en beter beeld van de natuurwetenschappen heeft tenminste de volgende elementen:
natuurwetenschappen

- ontwikkelen zich nog dagelijks
- kunnen talloze problemen niet oplossen
- kunnen daarentegen ook een bijdrage geven aan de oplossing van belangrijke maatschappelijke problemen
- zijn niet waardevrij, maar dragen op velerlei manieren de waarden in zich van de culturele en sociale omstandigheden waarin ze zijn ontwikkeld
- hebben een complexe relatie met techniek en met de maatschappij
- ontwikkelen zich allerminst rationeel.

6. Er zijn vele manieren om dit betere beeld van de natuurwetenschappen aan leerlingen over te dragen. Het gaat daarbij uiteraard om impliciet overdragen: we moeten niet les gaan geven over bovenstaande beeldelementen. Woorden als 'waardevrij', 'rationeel', etc. hoeven nooit in de klas te vallen terwijl je toch een beter beeld met je onderwijs overdraagt.
Voorbeelden van didactische middelen, onderwerpkeuze en dergelijke, die daaraan een bijdrage kunnen leveren worden genoemd in bovenstaand Faradayartikel en in de 'Verantwoording bij Exact Natuurkunde' (Meulenhoff Educatief, Amsterdam).
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-093.jpg?height=1371&width=1626&top_left_y=1276&top_left_x=182)
subgroep 10:

## Leservaringen met electronica

ㄱ. Verstappen<br>th. Römgens<br>E. Hon

De inleiders hebben ervaring opgedaan met (delen uit) het PLON-thema 'elektronica' in 5-HAVO. De houdt onder meer in het bestuderen en onderzoeken van componenten (condensator, diode, transistor, ldr en $n t c$ ) en van min of meer eenvoudige schakelingen (b.v. knipperlicht, regelsystemen met ldr of ntc, en/of poort, versterker en zender). Daarnaast komen vaste stof fysica, ontwikkeling en productie van chips en een eerste aanzet in de richting van informatica en automatisering aan de orde.
Ondanks vergelijkbare parallelgroepen werden beide bijeenkomsten goed bezocht. De reacties zowel op de proefversie van het themaboek als op de bijbehorende examenvragen waren positief. Voor de deelnemers zou 'elektronica', ondanks de onbekendheid met het onderwerp en zijn praktische mogelijkheden, een welkome aanvulling op het HAVO en/of VWO curriculum zijn; dit onder voorwaarde dat elders in de leerstoflijst wordt geschrapt zodat er tijd voor vrijkomt.
Tijdens de werkgroep is veel tijd besteed aan het doorbladeren van het themaboek, bespreking van werkwijzen en lessenplan en het bekijken en doen van de opgestelde proefjes. Er bleef daarom weinig tijd over voor het beoordelen van de selectie die door PLON is gemaakt uit de uitgebreide hoeveelheid stof die onder het hoofd 'elektronica' kan vallen. Enkele opmerkingen wil ik hier kort weergeven:

- Waarom 'oriëntatie op het thema'? Leerling kennen de scheiding sterkstroom en zwakstroom niet. Allerlei begrippen roepen bij hen associaties op waardoor ze op het verkeerde been worden gezet (bijv.: digitaal $\rightarrow$ horloge; transistor $\rightarrow$ radio). Door dit beeld te verbreden wek je bij meer leerlingen de interesse.
- Waarom het historisch perspectief van buizen (kort) via halfgeleider componenten naar I.C.'s? Waarom de productie van I.C.'s als onderdeel. De natuurkunde en de techniek achter elektronica zijn niet statisch. De huidige stand van zaken is geen eindpunt. Met het historisch perspectief kun je duidelijk maken waarom juist nu de automatisering als een golf over ons heen komt. Dat is ook van belang voor een reële beroepskeuze. I.C. productie-technieken
wijzen ook naar een grens in het miniaturiseren. De toekomst kan heel goed een sprong naar volkomen afwijkende principes meebrengen.
- Waarom transistor als schakelaar in plaats van een versterker?

Voornamelijk omdat het eenvoudiger is, in HAVO wel wenselijk.

Hieronder een schematisch overzicht van de 'elektronica'. De cursief gedrukte onderdelen komen in de proefversie van dit PLON-thema voor.
N.B. In december 1984 komt de definitieve versie van 'elektronica' uit. Dan voor ieder te bestellen.

 A. ELEKTRONISCHE COMPONENTEN

- weerstanden, condensatoren
- buizen
- NTC, LDR
- diodes, transistors
- FET, LED, piëzo-kristal
B. EENVOUDIGE DEELSCHAKELINGEN

Hieronder verstaan we schakelingen, waarvan de werking nog te begrijpen is als samenspel van losse componenten. Dit in tegenstelling tot de complexe schakelingen.

B1. ANALOGE DEELSCHAKELINGEN

- spanningsdelers
- RC-netwerken
- buizenversterkerschakelaar
- transistorversterker
- oscillator

B2. DIGITALE DEELSCHAKELINGEN

- transistorschakelaar
- trigger
- geheugenschakeling
- en/of/inverter-poort
C. COMPLEXE (EVT. GEīNTEGREERDE SCHAKELINGEN)

C1. ANALOOG

- frequentiefilters
- operationele versterkers
- differentiërende /integrerende schakelingen
- oscillators

C2. DIGITAAL

- digitaal/analoog converter
- analoog/digitaal converter
- schuifregisters
- micro-processors
- computers
D. PRINCIPES VOOR HET MAKEN VAN SCHAKELINGEN
- terugkoppelen
- moduleren/demoduZeren
- multiplexen
E. TOEPASSINGEN VAN SCHAKELINGEN
- versterkers, zenders, radio
- analoge meet- en regeltechniek
- terugkoppelen
- digitaliseren/coderen
- multiplexen
- automatisering bij telefoon, bank, procestechniek
- gegevensverwerking en opslag
- streepjescode, magnetische sleutel
- verkeersregeling.
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-096.jpg?height=906&width=1302&top_left_y=1833&top_left_x=532)
subgroep 12 :


## Online toepassing van de microcomputer in experimenten op school: demonstratie van een rotatie - experiment 

M. un Burt, A.Hartsuyjker, B. van Apppet

### De computer in on-line toepassingen
De microcomputer wordt binnen schoolpractica reeds gebruikt voor het uitvoeren van rekenkundige bewerkingen, het opstellen van tabellen en het tekenen van grafieken. Hierbij worden de gegevens nadat ze van de apparatuur zijn afgelezen via het toetsenbord in de computer gestopt en door het programma verwerkt (off-line).

Bij het vastleggen van dynamische grootheden is het, bij snelle bewegingen, niet eenvoudig de plaats als functie van de tijd te meten. Koppeling van de proef aan de microcomputer biedt dan de mogelijkheid een aantal mechanicaproeven uit te voeren die met traditionele apparatuur niet of moeilijk te meten zijn (on -line).

De gekozen toepassing in deze subgroep moet gezien worden als een 'voorbeeld' van on-line toepassing.
Aangezien statica en rotatie deel uitmaken van het VWO eindexamen natuurkunde 1984 is gekozen voor een experiment waarbij het traagheidsmoment van een roterend voorwerp wordt bepaald.

Bij het uitwerken van dit voorbeeld komen allerlei zaken aan de orde, zoals:

- het omzetten van fysische grootheden in elektrische spanning
- het omzetten van de spanning in een logische 0 of 5 V (interface)
- koppelen aan de microcomputer
- ontwerpen van een machinetaalprogramma voor de eigenlijke (snelle) metingen
- ontwerpen van programmatuur voor de verwerking van de meetgegevens
- bouwen van de experimenteeropstelling
- gebruikersvriendelijkheid van de opstelling en programmatuur
- didactische aspecten (plaatsing binnen de stof, werkvorm)

Zaken die vragen en problemen oproepen die door een docent die zich op dit terrein wil bewegen, niet gemakkelijk zijn op te lossen. Eigenlijk is het alleen doenlijk als een team van docenten zich op dit pad beweegt. Dan blijkt ook dat met de opgedane ervaring een volgend experiment veel vlotter van stapel loopt In de subgroep zijn de van bovengenoemde onderdelen er een aantal aan de orde geweest. Ze worden hieronder gedemonstreerd.
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-098.jpg?height=1285&width=1255&top_left_y=586&top_left_x=578)

### Omzetting van fysische grootheden in spanning
De te meten fysische grootheden zijn hier tijd en hoek. Zie figuur 1. In deze figuur is schematisch aangegeven hoe dat gerealiseerd wordt. De binnenste transducer (opneemelement dat fysische grootheid omzet in spanning) registreert hoekverdraaiingen van $45^{\circ}$
(iedere overgang van zwart naar wit of omgekeerd). De buitenste transducer dient als referentie. De gebruikte transducer (zie figuur 2) bestaat uit een combinatie van een LED die infrarood licht uitzendt en een fototransistor die het teruggekaatste licht registreert.
Voor de tijdmeting zie 'koppeling aan de microcomputer'.
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-099.jpg?height=677&width=1235&top_left_y=300&top_left_x=364)

### Demonstratie 1

Gedemonstreerd is hoe met behulp van een Assembler een kort machinetaalprogramma gemaakt wordt. In dat programma wordt de VIA-kaart aangesproken en gekeken naar de status (hoog/laag) van poort A. De werking van het programma is gedemonstreerd.

### Demonstratie 2

De demonstratie van het rotatie-experiment is voorafgegaan door een theoretische inleiding. Hiervoor wordt verwezen naar het artikel van Bas van Poppel en Fred van 't Hul in Faraday, dec. 1983, pag. 186.
Uit een analyse van de meetgegevens volgt een waarde voor het traagheidsmoment. Deze waarde klopt binnen ca. $6 \%$ met de waarde zoals die uit een theoretische berekening volgt.
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-099.jpg?height=756&width=1246&top_left_y=1921&top_left_x=344)

### Omzetting van spanning in logische 0 of 5 V

Met behulp van de schakeling van figuur 3 kan de door de transducer geleverde spanning worden omgezet in een logische 0 of 5 V , afhankelijk of er een zwart of een wit vlak voor de transducer staat.
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-100.jpg?height=764&width=1423&top_left_y=621&top_left_x=257)

### Koppeling aan de microcomputer
In het blokschema van figuur 4 is te zien hoe de koppeling van de interface naar de Apple II tot stand is gekomen. Gebruik is gemaakt van een VIA-kaart in slot 2 (VIA: Versatile Interface Adapter).
Deze kaart levert een groot aantal functies, waaronder twee poorten die als inof uitgang zijn te programmeren, en een tweetal timers die zo zijn geprogrammeerd dat zij tezamen een klok vormen waarop bij elke hoekverdraaing van $45^{\circ}$ de tijd is af te lezen.
De juiste werking van de VIA-kaart programmeert men met behulp van de controleregisters. Zit de Via-kaart eenmaal in de computer, dan fungeert deze als een stukje van het geheugen van de computer.

### Ontwerpen machinetaal programma voor het meetgedeelte
Ingegaan is op de structuur van de microcomputer en microprocessor van de Apple, omdat enige kennis daarvan noodzakelijk is voor het schrijven van een machinetaalprogramma. Vervolgens is een kort en beperkt overzicht gegeven van de instructieset van de microcomputer.
De functie van een Assembler is ter sprake geweest en het gemak daarvan bij het schrijven en verbeteren van machinetaalprogramma's. Zie figuur 6 voor een flowdiagram van het machinetaalprogramma.

FLOW=DIAGRAM MACHINEKODEPROGRAMMA ROTATIEEXPERIMENT
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-101.jpg?height=2494&width=1613&top_left_y=283&top_left_x=253)
subgroep 13 :

## Meetcomputter en electronische bounstenen op het proktikum

W. van Hassert, I de Brum

In deze werkgroep werd informatie gegeven over een tweetal nascholingscursussen, die in de jaren 1981-1983 aan de T.H. Twente zijn gehouden:

- Toepassingen Elektronica op Natuurkunde Practica
- Meten via de Computer

Elke cursus bestond uit 6 lesmiddagen van 3 uur.
Deze cursussen streefden uitdrukkelijk naar een werkelijk gebruik van het gebodene in de schoolpraktijk. Dat gebeurde o.a. door 'drempels' weg te nemen, zoals (bij 'Toepassingen Elektronica')

- een oplossing voor het probleem van de montage, door gebruik van een insteekbordje
- een universele voedingsbron, n.1. een g Volts batterij
- veel praktische tips, aansluitschema's
- introductie van enkele universeel toepasbare geinntegreerde circuits (IC's).

Bij 'Meten via de Computer' werd er voor gezorgd, dat de deelnemers naar huis gingen met een eenvoudige computer en een interface, waarmee men thuis of op school rechtstreeks aan de slag kon gaan.

De ervaringen van een deelnemende docent waren als volgt:
Een cursus elektronica en meten via de computer is voor een 'elektronisch ongeschoolde' docent een echte verrijking van zijn kennis en vaardigheden. Er gaan plotseling mogelijkheden open voor tal van (demonstratie)proeven in het onderwijs.
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-102.jpg?height=912&width=967&top_left_y=1834&top_left_x=895)

Bij de onderhavige cursussen werd dit bereikt door:

- Actief deel te nemen aan de cursus, veel thuis oefenen aan de (praktische) huiswerkopdrachten. Deze opdrachten konden alleen worden opgelost door voortdurend contact met de meetapparatuur. Dat kost veel tijd: ongeveer 25 uur per lesmiddag van 3 uur.
- De onmisbare hulp van een T.O.A., die kennis heeft van elektronica. Zodra in het onderwijs toepassingen worden gerealiseerd, moet de T.O.A. schakelingen op prints ontwerpen, vervaardigen, afmonteren en van een behuizing voorzien. Tijdens de werkgroep werden twee toepassingen van de 'meetcomputer' getoond:

1. Het verzamelen van meetwaarden, het opslaan ervan in het geheugen en vervolgens het uitlezen van de meetwaarden op een oscilloscoop.
Men zag proeven over het opladen/ontladen van een condensator, over de temperatuurstraling van een ontbrandende lucifer en over de registratie van inductiespanningen.
2. Het aansturen van meetapparaat met behulp van door de computer gegenereerde pulsen. In dit geval werd een elektronenflitser als stroboscoop gebruikt, met flitsfrequenties van ca. 1 Hz . Hiermee kan men lichtsterke stroboscopische foto's maken van bijvoorbeeld bewegende personen.
Hier niet getoond, maar door een programmawijziging goed te realiseren, is het genereren van flitsen die geen constant tijdsinterval hebben, b.v. voor opnamen van vallende voorwerpen.
Bijzonder aardige toepassingen zijn ook mogelijk met de computer als regelaar in een regelkring. Behalve in bepaalde thematische onderwijssituaties (PLON) kan dit worden gedacht in het technisch onderwijs.

Vanuit de cursus Toepassingen Elektronica werden schakelingen getoond met geīntegreerde circuits, als

- operationele versterker
- blok generator met NE 555
- sinusgenerator met XR 2206
- AD-omzetter.

Met deze dingen raakt men vertrouwd, door er zelf schakelingen mee te bouwen, zelf variaties en combinaties te proberen etc. De cursus dient er vooral voor te zorgen dat men aan de gang blijft. Niettemin is het denkbaar, dat zo'n cursus ook in schriftelijke vorm wordt uitgegeven (is inmiddels voor "opamps" beschikbaar). Men mist dan uiteraard de mogelijkheid terug te vallen op de cursusleiding en, vooral mist men, de stimulerende aanwezigheid van mede-cursisten.
oubgroep 14 :

## Modelproef Computertomografie 

A.L. Ellermeyer
R. Wilders
P.Sloot

In 1980 is bij het Medisch Natuurkundig Practicum een begin gemaakt met de ontwikkeling van een experiment dat het principe van de computertomografie duidelijk moest maken aan eerstejaars medisch studenten. De ontwikkeling van dat experiment is toen niet afgerond.
In 1983 is bij de afdeling didactiek de draad weer opgevat. Er is een lessenreeks 'afbeeldingstechnieken' ontwikkeld die is bedoeld voor 5 VWO, maar waarvan het experiment, de ct-proef, ook voor medisch studenten gebruikt gaat worden.

### WAT IS COMPUTERTOMOGRAFIE?

Computertomografie is een moderne, geavanceerde afbeeldingstechniek uit de medische praktijk. Met behulp van röntgenstraling wordt een vlakke doorsnede van het lichaam in kaart gebracht. Het te bekijken vlak wordt in een groot aantal richtingen doorgelicht. Daarbij lopen de röntgenstralen, anders dan bij het conventionele doorlichten in het vlak. Bij elke meting wordt de verzwakking in de materie tussen röntgenbron en detector bepaald. Denken we nu het vlak opgebouwd uit cellen, elk met een eigen verzwakking, dan kunnen we met al die metingen bepalen hoe de verzwakkingsverdeling over de cellen van het vlak is. Een computer is daarbij
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-104.jpg?height=940&width=717&top_left_y=1677&top_left_x=1074) onontbeerlijk.

### HOE WERKT DE CT-PROEF?

Met relatief eenvoudige middelen, zoals het Philips röntgendemonstratieapparaat, de bijbehorende GM-telbuis en de Apple II microcomouter, wordt een ct-scanner nagebootst. Daarmee worden de verzwakkingscoëfficiënten bepaald van onbekende vloeistoffen die zich in de cellen van een rozet bevinden.
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-105.jpg?height=708&width=725&top_left_y=674&top_left_x=225)

Wij kozen het hierbij afgebeelde rozet van zeven cellen. Dit rozet kan in negen richtingen doorgelicht worden: $A B, B C, C D, D E, E F, F A, A G D$, BGE en CGF.
We lichten het rozet in elk der negen richtingen gedurende 10 s door, terwijl zich in de cellen de onbekende vloeistoffen bevinden. Dit levert ons negen getallen (aantallen 'counts' van de GM-telbuis).
Daarnaast lichten we het rozet in elk der negen richtingen door, terwijl
alle cellen met water gevuld zijn. Dit levert ons eveneens negen getallen (aantallen 'counts' van de GM-telbuis).
Zo vinden we in totaal achttien getallen (aantallen 'counts'). Met deze getallen en één extra gegeven kunnen we, via het computerprogramma, voor elke cel de relatieve verzwakkingscoëfficiënt $\tilde{\mu}$ van de onbekende vloeistof bepalen.

### DE LESSENREEKS, HET LESSENMATERIAAL

Mede op grond van ervaringen opgedaan met leerlingen van 'Fons Vitae' het 'Het Amsterdams Lyceum' zijn wij tot de volgende opzet van de lessenreeks gekomen: LES 1 en LES 2 (elk één lesuur): introductie afbeeldingstechnieken. Ter ondersteuning: algemene tekst over afbeeldingstechnieken, diaserie.

LES 3, LES 4 en LES 5 (elk één lesuur): voorbereiding op het experiment. Ter ondersteuning: practicumhandleiding, vragen en opdrachten.

Is $\mu$ de verzwakkingscoëfficiënt van de onbekende vloeistof en is $\mu$ water die van water, dan is $\tilde{\mu}=\frac{\mu}{\mu}$; $\tilde{\mu}$ is dus een dimensieloos getal waaraan we de mate van verzwakking ${ }^{\mu}$ van de onbekende vloeistof kunnen aflezen. Water fungeert als 'standaard'.

LES 6/7 (twee lesuren achtereen): uitvoering van het experiment (meten, verwerken met de computer, uitwerken resultaten).
Ter ondersteuning: practicumhandleiding, practicummateriaal, computerprogramma.

LES 3 (eeen lesuur): afronden van het onderwerp 'afbeeldingstechnieken'.

We geven nu een korte beschrijving van het materiaal dat bij deze lessen gebruikt wordt.
Ter introductie is er een algemene tekst over afbeeldingstechnieken, bestemd voor leraren en leerlingen. Hierin worden drie technieken besproken: computertomografie, echoscopie en de NMR-techniek.
Er is een diaserie die op deze tekst is afgestemd.

Verder is er voor de leerlingen een practicumhandleiding. Hierin wordt aandacht besteed aan aard en oorsprong van röntgenstraling, verzwakking van röntgenstraling, detectie van röntgenstraling, modelkeuze, berekening van de verzwakkingsverdeling en foutenbronnen.
Het laatste deel van de handleiding fungeert als leidraad voor de uitvoering van de ct-proef. In dit deel zijn dan ook de meetbladen opgenomen. In de practicumhandleiding zijn verscheidene vragen en opdrachten te vinden.

Speciaal voor de ct-proef is in de instrumentenmakerij een serie vloeistofhouders en 'tafeltjes' vervaardigd.

Er is een computerprogramma voor het berekenen van de verzwakkingscoëfficiënten bij het model van de ct-proef. Het is een BASIC-programma voor de Apple II microcomputer.

In de handleiding voor de leraar is extra informatie over de ct-proef te vinden: de benodigdheden, wat theorie, een foutenanalyse, meetresultaten, een listing van het computerprogramma, enzovoorts.

De afdeling didactiek der natuurkunde biedt de mogelijkheid de ct-proef uit te voeren bij het Natuurkundig Practicum. Er is voldoende apparatuur aanwezig om met een niet al te grote groep ( 15 à 20 leerlingen) het experiment uit te voeren. Een deel van de apparatuur is uitleenbaar.

### WAT STEEK JE ALS LEERLING VAN DE LESSENREEKS OP?

De voornaamste verdienste van de lessenreeks lijkt ons dat je als leerling op betrekkelijk eenvoudige wijze inzicht krijgt in de toepasbaarheid van de natuurkunde. Je ziet hoe de natuurkunde in combinatie met wiskunde en informatica een geavanceerde medische techniek kan opleveren.
Om te beginnen laten de lessen over afbeeldingstechnieken je al zien hoe verschillende stukken natuurkunde een belangrijke rol spelen in de medische praktijk. In de daarop volgende lessen wordt de computertomografie verder uitgediept. Daarbij komt aan de orde:

- Wat is, hoe ontstaat röntgenstraling?
- Verzwakking van röntgenstraling; de verzwakkingswet.
- Detectie van röntgenstraling; de GM-telbuis.
- Hoe bootsen we een ct-scanner na? Modelkeuze.
- Foutenbronnen; stabiliteit van de röntgenbron, transmissie van röntgenfotonen, dode tijd van de GM-telbuis.
- Wat is iteratief proces? Een stukje wiskunde en informatica.

Hieronder is het schema van de lessenreeks weergegeven:
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-107.jpg?height=1477&width=1461&top_left_y=1410&top_left_x=306)

VRAGEN?
Met vragen over de lessenreeks 'afbeeldingstechnieken', bijvoorbeeld 'Hoe kom ik in het bezit van het lesmateriaal?', kunt u zich wenden tot de Afdeling didactiek der Natuurkunde van de Universiteit van Amsterdam, Nieuwe Achtergracht 170, 1018 WV Amsterdam, Telefoon: 020-522 2963/2860.
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-108.jpg?height=904&width=1308&top_left_y=1565&top_left_x=301)
subgroep 16

## Energiediscussie in de klas

B. Taverne

De Stichting voor Milieu-educatie bestaat sinds 1975 en heeft zich vooral bezig gehouden met het samenstellen van energie-materiaal. De start werd in feite gegeven toen op de Nationale Onderwijs Tentoonstelling in 1974 een pro-kernenergie tentoonstelling verscheen. Als reactie erop werd de expositie 'Energie Educatief' gemaakt, welke door de Stichting in 1983 werd vervangen door 'Tegen de Stroom in'. Beide exposities hebben tal van plaatsen aangedaan op verzoek van scholen, vormingscentra, bibliotheken en gemeenten. 'Tegen de stroom in' is ook nu nog te huur.
Uit de vraag naar educatief lesmateriaal bij de exposities kwam het project 'Energie, waar komt zij vandaan?' voort. Vanaf juli 1969 wordt gewerkt aan lesmateriaal over energie in de wereld, bestemd voor de bovenbouw van VWO en HAVO. In het materiaal wordt het energieprobleem op verschillende manieren benaderd.

energie, waar komt zij vandaan? lessen over energie, milieu en derde wereld.

> Ten eerste is er de ecologische kant. We gaan in op het ontstaan van in de aarde vastgelegde energie (fossiele bronnen), de ordening die op de aarde kon ontstaan dank zij de energie van de zon, en de afbraak van die ordening, die een gevolg is van een te hoog energieverbruik in het Westen. Ten tweede is er de historische kant. We beschrijven de maatschappijvormen sinds de oertijd, en laten in historisch perspectief de samenhang zien tussen de matschappijvorm, energievormen en verbruik, technische hulpmiddelen, machtsverhoudingen en de omgang met de natuur.
Ten derde is er de economische kant. Op welke wijze is onze samenleving economisch georganiseerd, hoe werkt die organisatie in op het energieverbruik en hoe kun je
met of zonder een verandering in de economie een energetisch en ecologisch verantwoorde samenleving opbouwen. Tenslotte is er de mondiale kant. De voornaamste fossiele energiebronnen die open staan voor export komen voor in de landen van de Derde Wereld. De aldaar toegepaste energiebronnen zijn echter andere: hout, mest, dier- en mensarbeid. Er zijn duidelijke relaties tussen de vormen van energieverbruik in de Derde Wereld en het onvermogen om er een gezonde en menselijke samenleving op te bouwen. De onttrekking van energie aan de Derde Wereld is een belangrijke
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-110.jpg?height=1296&width=932&top_left_y=343&top_left_x=918) oorzaak voor de daar bestaande problemen.

De lessenreeks bestaat uit elf lespakketten. Elk pakket bevat een uitvoerige docentenhandleiding en volledig uitgewerkt leerlingenmateriaal. Bij enkele pakketten zijn extra hulpmiddelen verkrijgbaar zoals fotocollages, een diaserie ('Een Energieke Samenleving, 1983), tekeningen en spelen.
De opbouw van de lessen maakt het mogelijk elk pakket afzonderlijk te gebruiken. Voorts kan het materiaal zowel door één docent(e) alsook in een samenwerking van docenten gebruikt worden. In dat laatste geval kan het dienen als onderdeel van thematisch- of projectonderwijs. Het leerlingenmateriaal kan door de docent(e) zelf gecopieerd worden.

Op de Woudschotenconferentie is in een presentatie aan de orde geweest, hoe ook in het vak van natuurkunde met dit materiaal gewerkt kan worden. De nadruk lag op het gebruik van het 'Eilandspel', een soort maatschappelijke discussie op klasniveau over energie. Dit spel wordt in vereenvoudigde vorm gebruik door het PLON in haar eerste opzet voor VWO-energie-lesmateriaal.

Docenten, die het material, zo ook het Eilandspel, willen nebruiken, moeten wel bereid zijn over de grenzen van het vak heen te kijken. Door leerlingen wordt daar veelal gunstig op gereageerd. Zo stellen ze nadat ze het Eilandspel gespeeld hebben wel, dat ze nu tenminste zien hoe sterk de beschikbaarheid van energie een rol speelt voor de samenleving en de manier, waarop die georganiseerd is.

De Stichting voor Milieu-educatie stelt verder materialen samen over afval, milieu en natuur in de stad. Men kan gratis folders aanvragen.

Het lesmateriaal 'Energie, waar komt zij vandaan?' kost inclusief verzending $f 50,00$. Men bestelt via giro 3180199. Het adres: Oude Gracht 42, 3511 AR Utrecht, telefoon 030-333357.
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-111.jpg?height=820&width=1186&top_left_y=1942&top_left_x=159)
subgroep 17 :

## Windmolens in het onderwijs

*Egbert Bausma*

De belangstelling voor deze subgroep was nogal groot. Op zich is dat niet zo vreemd, immers in Nederland zijn drie zaken vanzelfsprekend:
fietsen, wind en molens
Het is wèl verbazingwekkend dat deze dingen nauwelijks een rol spelen in het natuurkunde-onderwijs in ons land. Te verwachten is dat in een niet al te verre toekomst dit anders zal zijn, daar de roep om binnen het natuurkunde-onderwijs meer aandacht te besteden aan de relatie natuurkunde-techniek, steeds sterker wordt. Met name het ontwerpen en maken van een kleine windmolen kan voor leerkracht en leerlingen de interactie tussen natuurkunde en techniek duidelijk maken.

Het bouwen van een kleine windmolen kan op een aantal plaatsen binnen het Nederlandse middelbare onderwijs gebeuren. Of dit nu plaatsvindt bij natuurkunde en techniek of bij algemene technieken of bij een energieproject of binnen éen of ander samenwerkingsverband van vakken en leerkrachten, dan is het zaak er als natuurkundeleraar(es) voor te waken dat het eindproduct (de molen) niet 'af' is, maar nog vele mogelijkheden tot experimenteren biedt.
Het stellen van deze eis vraagt een molenontwerp waarbij steeds heel eenvoudig:

- een andere wiekvorm gemonteerd kan worden
- het aantal wieken gevarieerd kan worden
- een andere generator geplaatst kan worden
- de overbrenging tussen wieken en generator veranderd kan worden
- de kruiing veranderd kan worden.

Het vergelijken van dergelijke verschillende molentypen kan eenvoudig via het relateren van windsnelheidsmetingen aan metingen van het elektrisch geleverde vermogen (via spanning- en stroommeting). Voor het meten van de geleverde elektrische energie en voor het bepalen van rendementsfactoren zijn duurmetingen nodig. Koppeling aan een microcomputer of microprocessor is dan vanzelfsprekend.

Bij een kleine windmolen voor het onderwijs denk ik aan het volgende:
Wieken:

- wiekdiameter 1 meter
- zogenaamde pijpwieken, gezaagd uit pvc-pijp

Generator: - speelgoed elektromotortjes

- cassetterecorder motortjes

Overbrenging: - meccano wielen (snaar en ketting)

- lego kettingwielen.

Binnen het kader van dit verslag is de ruimte te beperkt om aan te geven hoe de wiekvorm gekozen wordt en hoe de keuze van de generator dan de overbrenging bepaalt.
Eind mei 1984 verschijnt er bij de afdeling natuurkunde van de lerarenopleiding ZWN te Delft een uitgebreide bouwbeschrijving van een goed functionerende kleine windmolen die tegen weer en wind bestand is en waarmee uitgebreid geëxperimenteerd kan worden. De materiaalkosten voor deze molen zijn ongeveer f 40, $=$. Heeft U belangstelling dan kunt u ons bellen, tel. 015 - 134947, toestel 149.
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-113.jpg?height=1322&width=913&top_left_y=1456&top_left_x=572)
subgraep 18

## Het stralingspracticum

 *Amoud Pollman Reb van Haren*

Gegeven: Het Ioniserend Stralings Project (ISP) voldoet op uitstekende wijze aan de vraag op scholen naar experimenten met radioactieve bronnen en röntgenstralen.

Uitgangspunt: Het is wenselijk om de experimenten in een voor de leerlingen herkenbaarder kader te plaatsen.
Werkwijze: $\quad$. Zoek zoveel mogelijk relevante wetenschappelijke en maatschappelijke toepassingen bij de ISP-experimenten en verwerk deze in de handleidingen en/of leesteksten.
2. Zoek experimenten bij voorbeelden uit het "dagelijk leven".

Wij hebben dit besproken met drs. Th. Heij, een van de ontwikkelaars van het ISP. Er zal door hem een docentenhandleiding worden gemaakt voor docenten die vooraf op school iets aan het practicum willen doen. Zo kan het ISP beter op school voorbereid en ingeleid worden en zal er voor docenten die daaraan behoefte hebben materiaal zijn om als extra achtergrond-informatie voor de leerlingen te copiëren.
Hier volgen nu alvast een aantal ideeën, die uitvoerbaar zijn.
röntgenstraling - loden jas als voorbeeld afscherming

- afschermende werking van loodglas toegepast bij manipulators e.d.
- gebroken varkensbot, ingesmolten in plastic
- onderkaak van mens met tanden
afschermende werking van materialen waarin gedumpd wordt:
- beton
- water
- aarde
- zout
stencil "bepaal je eigen stralingsbelasting"

```
industrie: - diktemeting
    - tegengaan statische elektriciteit door ionisatie
    - brandmelder
wetenschap: - braggreflectie bij kristalonderzoek
    - elektriciteitsbron bij poolexpedities e.d.
ouderdomsbepaling:
- citroenplantje of riet als model, gebruik kort levend barium
medische toepassingen:
- citroenplantje als model bloedbaan
- röntgen diagnose
diverse bronnen in natuurlijke omgeving:
- Spa bronwater indampen
- urine indampen
- gesteentes (lenen bij aardrijkskunde)
- thoriumzouten (lenen bij scheikunde)
- campinggaz: lampekousje (thorium)
- oude wijzerplaten met lichtgevende cijfers
bouwmaterialen: - gipsplaten
- beton, hout.
Er bestaan reeds diverse teksten over toepassingen en voorkomen van radioactieve bronnen en straling in de maatschappij.
Het PLON-thema "Ioniserende Straling" en de bijbehorende docentenhandleiding (AVOL) geeft veel van deze teksten, o.a. over gevolgen van straling, een Geiger-Müller teller om zelf te bouwen en een diaserie die is samengesteld uit opnamen in het Academisch Ziekenhuis van Utrecht. Verder zijn er achtergrondteksten over de brandmelder en over risico's van röntgenstraling. Indien u geīnteresseerd bent, kunt u natuurlijk wachten op het boekje dat het ISP nu ontwikkelt, maar u kunt ook contact opnemen met ondergetekenden.
```

subgroep 19

## Werken met fotografische materialen

*Hubert Biezeveld*

Tijdens een practicum werd getoond hoe deze foto gemaakt kan worden.
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-116.jpg?height=1474&width=1056&top_left_y=1281&top_left_x=438)
subgroep 20 :

## 'Natuurkunde aan den lijve', lesmateriaal over medische toepassingen in de natuurkunde


*Jico Buis, Bas van Cramenburght, Bert de Vries, Rund Serwald.*

In het reguliere natuurkundeprogramma voor bovenbouw HAVO/VWO ontbreekt (o.a.) het onderwerp medische fysica. Medische toepassingen van de natuurkunde komen in de praktijk slechts incidenteel in de klas aan de orde, terwijl het onderwerp zich toch bij uitstek daartoe leent. Het sluit immers goed aan bij de belevingswereld van de leerlingen. Bovendien zullen veel leerlingen het aantrekkelijk vinden om kennis te maken met een overgangsgebied van natuurkunde met andere vakken (biologie en medische wetenschap).
De NVON-zomerconferentie 1983 was een goede aanleiding om lesmateriaal over medische toepassingen van de natuurkunde te gaan vervaardigen. Tijdens de Woudschotenconferentie presenteerden we het lesmateriaal nog eens voor nieuwe belangstellenden.
'We' zijn: Nico Buis (docent natuurkunde bij D'Witte Leli), Bas van Cranenburgh en Bert de Vries (studenten wis- en natuurkunde bij D'Witte Leli) en Ruud Seewald (leraar natuurkunde aan het College Leeuwenhorst te Noordwijkerhout en part-time medewerker van de Afdeling didactiek der Natuurkunde van de U.v.A.).

In deze bijdrage zullen we de opzet en inhoud van het vervaardigde lesmateriaal bespreken. Aan het slot stellen we nog enkele praktische zaken aan de orde.

### Opzet

Het ontwikkelde lesmateriaal is bedoeld voor leerlingen van de bovenbouw HAVO/VWO. We realiseren ons dat op dit moment experimenteren hiermee vrijwel uitsluitend mogelijk is op het VWO (als experimentele keuzegroep die bij het schoolonderzoek getoetst wordt).
Bij het vervaardigen van het lesmateriaal is sterke nadruk gelegd op leerlingexperimenten. Een deel ervan wordt door de leerlingen aan zichzelf en aan elkaar uitgevoerd. De overige proeven worden uitgevoerd aan fysische modellen.

### Verkenning
In 'Natuurkunde aan den lijve'beperken we ons toto de natuurkundige aspecten van het hart, de bloeddruk, het oog en de spierkracht. Bij de uitwerking kozen we voor de volgende opzet.
[^1]Het begin is voor alle leerlingen gelijk: de Verkenning. Daarin wordt kennis gemaakt met de vier onderwerpen hart, oog, bloeddruk en spierkracht. Dat gebeurt via leesteksten en proefjes, die in de vorm van een circuitpracticum zijn opgesteld. De leerlingen werken in tweetallen. De volgorde van de vier onderwerpen en van de proeven bij één onderwerp is niet van belang. Aan het einde van de Verkenning kiest een groepje leerlingen voor één van de vier onderwerpen.

### Keuzedeel

Bij het keuzedeel gaan de leerlingen dieper in op één van de onderwerpen oog, hart, bloeddruk, spierkracht. Een belangrijke plaats wordt ingenomen door een experiment aan een fysisch model. Verder is er nieuwe schriftelijke informatie. Aan het einde van de tekst van elk keuzedeel staan enkele suggesties voor verder onderzoek. Tot slot kan elk groepje verslag uitbrengen aan de rest van de klas over wat men gedaan en geleerd heeft. Op deze manier wordt de kennis bij elk groepje gemeenschappelijk gemaakt. Afhankelijk van de functie van deze presentatie, zullen hieraan van te voren eisen moeten worden gesteld.

### Tijdsplanning
Als mogelijke planning stellen we ons het volgende voor:
les $1 \mathrm{t} / \mathrm{m} 5$ inleiding + verkenning
les $6 \mathrm{t} / \mathrm{m} 10$ werken aan het keuze-onderwerp
les 11 voorbereiding van de presentaties
les $12+13$ presentaties
les 14 proefwerk
les 15 nabespreking proefwerk + evaluatie.

### Beoordeling

Het beoordelen kan bijv. als volgt op drie onderdelen gebeuren.

1. De leraar/lerares beoordeelt de resultaten van de vragen en opdrachten van het keuze-onderdeel (gelijke beoordeling voor alle leerlingen van een groepje).
2. De medeleerlingen beoordelen de presentatie van een groepje.
3. De leraar/lerares beoordeelt een afsluitend proefwerk.

### Inhoud
Verkenning
Oog - leesteksten: Bouw, Details zien, Licht op staafjes en kegeltjes

- proeven: blinde vlek, gezichtsveld, gezichtsscherpte, contrast en oogmodel

| Hart | - leesteksten: Werking van het hart, Electrocardiogram <br> - proeven: bepaling van hart- en ademhalingsfrequentie, de 'Waagschaal ${ }^{1}$ |
| :---: | :---: |
| Spierkracht | - leesteksten: Bouw, Peesweefsel, Zenuwen <br> - proeven: knijpkracht, sprongkracht, biceps |
| Bloeddruk | - leesteksten: Bloed, Bloeddruk, Hoge Bloeddruk, Bloedsomloop <br> - proef: bepaling bloeddruk. |
| Opmerking | : De resultaten van verschillende proeven worden op een overzicht van de hele klas verzameld. Een groepje met een bepaald keuzedeel kan die resultaten gebruiken. |
| Keuzedelen |  |
| Hart | - proef: Maken van een elektrocardiogram <br> - leesteksten: Ontwikkelingen in de elektrocardiografie; hoe ontstaat een elektrocardiogram (met dia's) <br> - proef: Het hartdipoolmodel |
| Oog | - Het oogmodel (o.a. oogafwijkingen) <br> - proef: De lange karakteristieken (kijkend naar een lichtsignaal met geringe helderheidsmodulaties bij verschillende frequenties) |
| Bloeddruk | - leestekst: Bloedsomloop, Theoretisch bloeddrukmodel <br> - proef: Mechanisch bloeddrukmodel |
| Spierkracht | - Nog niet klaar op het moment van deze conferentie. |

### Enkele opmerkingen

- Op het moment van deze conferentie moest het keuzedeel Spierkracht nog verder worden uitgewerkt. Als dat deel klaar is, moeten we de gehele tekst nog eens critisch bekijken. Vervolgens willen we de beschikbare tekst laten lezen aan een aantal deskundigen op het gebied van de medische fysica.
De tekst moet nog aangevuld worden met een docentenhandleiding (o.a. over apparatuur), lijst met moeilijke woorden, literatuurlijst t.b.v. de leerlingen.
- De proeven van de keuzedelen moeten beschikbaar komen voor de scholen. Wil een leraar/lerares dit lesmateriaal binnenkort uitproberen, dan kunnen de proeven van de keuzedelen uitgevoerd worden bij de Vakgroep Fysische Experimenteerkunde van de U.v.A.
- Helaas is op dit moment nog niet bekend hoe 'Natuurkunde aan den Lijve' functioneert in de klas. Wil je dit lesmateriaal uitproberen, meld je bij ons aan!
- Het complete lesmateriaal is te verkrijgen door f $7,=$ over te maken op postgiro 3251900 t.n.v. D'Witte Leli te Amsterdam, onder vermelding van 'Lesmateriaal natuurkunde: 'Natuurkunde aan den Lijve'.
- Voor vragen e.d. kun je contact opnemen met Nico Buis, D'litte Leli sectie natuurkunde, Rapenburgerstraat 173, 1011 VM Amsterdam (tel. 020-240640).
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-120.jpg?height=1313&width=907&top_left_y=1446&top_left_x=930)

Bijlage bij subgroep 20:

Een van de belangrijkste toepassingen van een microcomputer bij natuurkunde experimenten is het gebruik ervan als x-t-schrijver (voor langzame verschijnselen) of als storage-scoop. Bij het opnemen van een ECG wordt het spanningsverschil geregistreerd tussen twee plaatsen op de huid, bijv. tussen de linkeren rechterarm. De spanningsverschillen die optreden in korte piekjes zijn van de orde van grootte van 1 mV .
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-121.jpg?height=439&width=1517&top_left_y=999&top_left_x=275)

Om variërende spanningen met een computer te registreren, wordt de spanning eerst d.m.v. een AD- (analoog naar digitaal) converter omgezet in een getal tussen 0 en 255. Dit getal wordt via de USER-port in de microcomputer (een Commodore-64) ingelezen.
De hier gebruikte AD-omzetter is vorig jaar op onze afdeling ontwikkeld en is speciaal bedoeld voor toepassing binnen het onderwijs*. Omdat de AD-converter een ingangsspanningsbereik heeft van $0-5 \mathrm{~V}$, is een voorversterker nodig. Deze voorversterker is uitgevoerd met 4 Op-Amp's; de versterker is ingesteld op ca. 5000 maal. De voorversterker heeft twee signaalingangen waarop de huidelektroden worden aangesloten. de versterker versterkt het spanningsverschil tussen deze twee ingangen (verschilversterker). Eén van beide benen van de proefpersoon wordt bovendien geaard (verbonden met de massa-aansluiting van de voorversterker).

[^2]Naast bovengenoemde 'hardware' die nodig is om het signaal in een voor de computer bruikbare vorm te brengen, is programmatuur nodig om de informatie in te lezen en te verzamelen, voor het grafisch weergeven van die informatie, en voor nadere verwerking ervan. Deze programatuur is voor een deel geschreven in Basic en voor een deel in machinetaal. Het inlezen en verzamelen van de inkomende data moet vrij snel gebeuren; om geen details in het ECG te verliezen is het nodig om tenminste 100 maal per seconde de spanning vast te leggen. Omdat, net als bij een oscilloscoop, het signaal continu grafisch wordt gedisplayed, moet ook dit snel gebeuren. Dit betekent dat zowel de meetroutine als de display-routine geschreven moesten worden in machinetaal.
Het programma bestaat uit twee blokken, namelijk 1) het meetgedeelte en 2) het verwerkingsdeel. In het meetgedeelte werkt de computer als storage-scoop; je kunt door indrukken van een willekeurige toets het spoor dat het laatst getekend wordt, vasthouden. Met het verwerkingsgedeelte kun je door het aangeven van de plaats van de pieken, de frequentie bepalen.
Dit experiment was tot nog toe voor scholen te duur. Met een basisuitrusting, micro en AD-omzetter, kost deze proef nog slechts enkele tientjes:
subgroip 21 :

## Adviezen van docenten bij de keuze van Wis-, natuur. en scheikunde voor de bovenbouw

werkgroep meisjes en natourteunde-

De workshop van de NVON-groep Meisjes en Natuurkunde besteedde aandacht aan een enquête die uitgevoerd is door de Contactgroep emancipatie binnen rijksonderwijs. Dit is een groep docenten van rijksscholen voor voortgezet onderwijs die zich bezighoudt met verschillende onderwerpen, zoals: het rijksleerplan, het studie- en beroepskeuze materiaal. De groep heeft ook een enquête gehouden onder de zestig rijksscholen voor vwo, havo en mavo, en de voorzitter van de groep, mevrouw A.Korving, heeft hier een en ander over verteld. Aan de leerlingen van het voorlaatste leerjaar werd gevraagd of wiskunde, natuurkunde en scheikunde door hun docenten (dekanen, mentoren en vakdocenten) als eindexamenvak werden aan- of afgeraden.
Het bleek dat wiskunde, natuurkunde en scheikunde meisjes vaker werd af- dan aangeraden. Bij jongens is het net andersom. Om de vakken als eindexamenvak vaker aan- dan afgeraden te krijgen, moeten meisjes in veel gevallen een hoger rapportcijfer hebben dan jongens.
Enkele cijfers, toegespitst op het vak natuurkunde: in 5-vwo wordt natuurkunde door de vakdocent aangeraden aan $19 \%$ van de jongens, aan $8 \%$ van de meisjes. Natuurkunde wordt afgeraden aan 9\% van de jongens, aan $23 \%$ van de meisjes. In 4-havo wordt natuurkunde door de vakdocent aangeraden aan $29 \%$ van de jongens, aan $8 \%$ van de meisjes. Natuurkunde wordt afgeraden aan $17 \%$ van de jongens, aan $42 \%$ van de meisjes. Natuurkunde werd in 5 -vwo door de vakdocent aangeraden als eindexamenvak bij een rapportcijfer van minimaal 6 voor jongens, 7 voor meisjes. In 4-havo zijn de cijfers voor beide groepen leerlingen 7.

Na de uiteenzetting van mevrouw Korving ontstond een levendige discussie tussen de ongeveer 30 deelnemers. De meeste natuurkunde docenten getuigden van hun ervaring dat meisjes slechtere resultaten behalen in de hogere leerjaren. Ze hadden daar weinig verklaringen voor.
Vanuit de groep Meisjes en Natuurkunde werd naar voren gebracht dat dit kan liggen aan het image van het vak, dat voorbereidt op door mannen overheerste technisch-wetenschappelijke beroepen. Veel vrouwelijke natuurkunde docenten zijn er evenmin. Binnen de leerboeken vindt men weinig vrouwen en weinig voor vrouwen relevante onderwerpen.
(Onbewuste) meningen van docenten over meisjes kunnen doorwerken in haar zelfbeeld en zelfvertrouwen. Vanuit de docenten bleek veel bereidheid om iets aan hun onderwijs te veranderen ten gunste van meisjes. De allesoverheersende vraag hierbij was: geef concrete informatie en concrete handreikingen.
Als mogelijke acties werden gesuggereerd:

- Meer onderwerpen die - naar ervaring uitwijst - meisjes meer aanspreken: over natuurkunde en samenleving, samenhang met het menselijk lichaam (biologie), historische ontwikkelingen. Het MENT-project maakt hier materiaal voor. (MENT staat voor meisjes, natuurkunde en techniek).
- Een bemoedigende houding van de leerkracht, zodat het meisje gestimuleerd wordt. Echter weer niet zodanig, dat bij meisjesprestaties met veel minder genoegen genomen wordt.
- Attent zijn op wat in practica gebeurt: doen meisjes ook technische handelingen.
- Een goede begeleiding en beroepskeuzevoorlichting door de dekaan.
- Meer voorlichtingsmateriaal voor docenten die daadwerkelijk aan de slag willen, met concrete tips.


## diversen

## Markt
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-125.jpg?height=897&width=1297&top_left_y=1608&top_left_x=236)
de wandelgangen
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-126.jpg?height=2494&width=1678&top_left_y=252&top_left_x=143)
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-127.jpg?height=2291&width=1697&top_left_y=258&top_left_x=156)

## Forumdiscussie

![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-128.jpg?height=411&width=874&top_left_y=302&top_left_x=866)

Toelichting op de stellingen

* Stelling: HET EXAMEN MOET MEER VOORSPELBAAR ZIJN.
(J. van Galen)

Deze stelling is ingegeven door de slechte examenresultaten landelijk gezien. Er is een grote discrepantie tussen wat leerlingen leren en de problemen waarvoor ze op het examen geplaatst moeten worden.
Er moet meer duidelijkheid zijn t.a.v.:
a) onderwerpen waarover gevraagd zal worden op het examen
b) de vorm van het examen; we houden te rigide vast aan het 4 -vragensysteem, waardoor deze vragen een vorm krijgen die in een schoolsituatie niet te realiseren valt. Leerlingen komen ook wat vorm betreft onvoorbereid op het examen.
c) niveau: aangegeven zou moeten worden hoeveel procent van de vragen op productieniveau, hoeveel procent op inzichtniveau enz. aangeboden zullen worden.

* Stelling: DE LEERSTOF DIENT EEN OMVANG TE HEBBEN VAN 70 à $80 \%$ VAN DE HUIDIGE LEERSTOF.
(G. Verkerk)

In 1975 heeft de examenprogrammacommissie de principiële uitspraak gedaan dat het examenprogramma ruimte moet bieden voor eigen invulling door scholen (uiterlijk $20 \%$ ). De praktijk wijst uit dat het huidige programma (de verplichte leerstof) $100 \%$ van de tijd in beslag neemt. Hierdoor blijven practicum, (praktisch) schoolonderzoek, keuzeonderwerpen en vernieuwingsactiviteiten, zaken die slechts in de marge van het onderwijsgebeuren kunnen plaatsvinden.
Ik pleit voor een differentiële invulling van 20 à $30 \%$ van het examenprogramma, waarvoor het examenprogramma wel aanwijzingen mag (moet) bevatten.
Kernleerstof en differentieel gedeelte worden getoetst in het schoolonderzoek.

* Stelling: DE HUIDIGE EXAMENPROGRAMMA'S ZIJN ONVERANTWOORD EENZIJDIG GERICHT OP HET GEVEN VAN KENNIS VOOR STUDIE EN BEROEPSOPLEIDING.
(A. van der Valk)

Voor studie en beroep is meer nodig dan deze kennis; zoals zelfstandigheid, creativiteit, vermogen om kennis te verwerven, vermogen om eigen kennis over te dragen enz.
In onderwijs en dus ook examenprogramma moet aandacht zijn voor drie belangrijke componenten:
a) voorbereiding op studie en beroep
b) inleiden in werkwijze en structuur van de wetenschap
c) persoonlijke ontplooiing leerling.

Stelling: HET EXAMEN DIENT OPGEBOUWD TE ZIJN VOLGENS DE SCHIJF VAN 5:
$30 \%$ wetenschappelijke regels en begrippen
$15 \%$ experimentele vaardigheden
$20 \%$ technische inhouden w.o. medische
$15 \%$ natuurkunde en samenleving
20\% keuze waaronder zelfstandig onderzoek.
(H.F. van Aalst)

Het examen dient betrekking te hebben op het onderwijs dat in de 2 à 3 jaar voorafgaande aan het examen is gegeven. In de huidige examenpraktijk is dat te weinig het geval.

Het eindexamen: De vijf gebieden dienen herkenbaar te zijn in het examen. Ook voor het keuzegedeelte dienen richtlijnen in het examenprogramma te worden opgenomen.
Alvorens echter het examenprogramma wordt vastgesteld, dient wel de discussie gevoerd te worden over de vraag wat je precies met het natuurkunde-onderwijs wilt.

### Discussie

H. F. v Aalst

Ik wil kort reageren op de stelling van Van Galen. Ik ben het eens met de stelling waar deze vraagt om een duidelijk examenprogramma.
Wat de uitvoering van de stelling betreft ben ik tegen een duidelijkheid die wordt nagestreefd door doelstellingenlijsten.
Ik ben meer voor een globale aanduiding in termen van gebieden waar vragen over worden gesteld en vraagtypen, aangevuld met een set voorbeeldopgaven die uit de examenpraktijk is voortgekomen.
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-130.jpg?height=935&width=1306&top_left_y=250&top_left_x=367)
J. V. Galen

Misschien moeten we in de beschrijving van het examenprogramma niet zo ver gaan als in het doelstellingenboekje, maar het moet toch wel in die richting gaan.
N.N.

De examenstof is steeds hetzelfde en de manier van vragen is na al die jaren wel duidelijk. Het examen is hierdoor wel voorspelbaar.
J.v.Galen

Op het laatste havo-examen komen vragen voor met een diepgang, die ik van te voren niet had kunnen voorzien. Ook in het examenprogramma vind ik hiervoor geen aanwijzingen. Wat ik in de les doe gaat in het algemeen niet zo ver als het examen. Ook de vorm van mijn vragen is heel anders. De leerling is dus op het examen in een situatie die heel anders is dan die hij kent uit zijn onderwijs.
G. Beukema

Moet het examen, leraar- of leerstofgericht zijn?
J.v.Galen

Mijn stelling is, dat uit het examenprogramma moet blijken wat voor problemen de leerlingen op examen voorgelegd krijgen. De vragen moeten ook goed gespreid zijn over de leerstof.

G. Verkerk

Ik wil reageren op Van Galen en Van Aalst.
Ik ben tegen een examenprogramma in een vorm zoals het doelstellingenboekje van de NVON. Dit leidt tot verstarring van onderwijs en belemmert vernieuwingen.
J.v.Galen

Misschien is een examenprogramma in een vorm zoals de NVON-leerstofformulering te fijnmazig. Mijn stelling is, dat een examenprogramma alleen bestaand uit een leerstoflijst te vaag is.

P. J.Wippoo

Ik vind het jammer dat al onze aandacht ook nu weer uitgaat naar het CS. Wij zouden ons meer moeten inzetten voor het SO om dit beoordelingsmoment als gelijkwaardig en even waardevol als het CS geaccepteerd te krijgen.

G.Verkerk

Van Aalst stelt dat ook het keuzegedeelte centraal getoetst zou kunnen worden. Ik ben het daar niet mee eens, omdat je daarmee de eigen inbreng van de scholen weer inperkt. Ik vind dat het differentiële gedeelte in het SO moet worden getoetst. Ik onderschrijf dus het pleidooi van de heer Wippoo voor een gelijkwaardige plaats van het SO naast het CS.
H.E.v.Aalst

Ik maak me zorgen over de gevolgen van een te strenge scheiding van CS en SO . Nu al zien we dat onderwerpen naar het SO worden verwezen, niet omdat ze zo school- of leerlingspecifiek zijn, maar omdat men geen raad weet met centrale toetsing. Juist hierdoor krijgt het SO zijn slechte naam, omdat centraal gezien het zicht ontbreekt op de kwaliteit van de toetsing. Ik pleit voor één examen, waarin een redelijk vloeiende overgang is tussen opgaven die centraal gemaakt worden, opgaven die op de school uitgevoerd worden maar waarvoor wel centrale richtlijnen zijn (ik denk maar aan opsteltitels) en ook een aantal toetsvormen die geheel onder de verantwoordelijkheid van de school vallen.

H. P. Hooymayers

Kennelijk is het CS niet in staat bevonden die zaken te toetsen die veel leraren belangrijk vinden. Je zou er dan voor kunnen pleiten het CS een onbelangrijker gedeelte van het examen te laten zijn en bijvoorbeeld die gewichtsfactoren CS:SO een verhouding 1 op 2 te geven.
H.F.v.Aalst

Dit sluit ook de ontkoppeling uit. Je stelt het eindcijfer vast op basis van het geheel.
H.P. Hooymayers

Ja, maar dan zouden op het CS alleen die onderwerpen getoetst moeten worden, die voor de vervolgopleiding belangrijk zijn.
Laat het daarbij. Daardoor wordt het CS wel een stuk onbelangrijker.
P. J.Wipgoo

Ik denk dat het nodig is het publiek, maar ook collega's te laten zien hoe belangrijk en waardevol het SO is. Mijn pleidooi richt zich ook op handhaving van een verhouding 1:1. Er moet onderzoek gedaan worden naar wat het SO allemaal meet en welke know how er met betrekking tot het SO al is opgebouwd. Mijn stelling zou zijn: SO moet hoger gewaardeerd worden.

Kramer

Er is in de loop der jaren al zo veel leerstof uit het havo-programma verdwenen. De leerlingen die op het havo zitten zijn nogal veranderd. Ik wil er een stelling aan toevoegen n.l. zit op dit moment een havo(vwo)leerling nog wel op het havo (vwo)?
A. $\underline{v}$. d. Valk

Natuurlijk zit een havo-leerling nog wel op het havo. De vraag is of de havoleerstof nog wel past bij deze leerling. De huidige leerling komt met een ander beeld van wat hij met de leerstof in de toekomst wil doen op school. De leerstof sluit niet meer aan bij wat de leerling verwacht. Daardoor ontstaat er kortsluiting.
U.v.Galen

Ik sluit mij daarbij aan.

Kramer

We zien dat steeds meer de vrije ruimte die er is in b.v. het vwo-programma wordt gebruikt voor de kernleerstof. Gewoon omdat leerlingen, die toch als eerste doelstelling hebben te slagen voor het examen, die tijd nodig hebben. Wijst dit er niet op dat te veel leerlingen zitten die dit niveau niet aankunnen.
Ik ben voorstander van vooraf te spreken b.v. via een examencommissie, wat we met het vwo/havo/mavo onderwijs willen en welk niveau we willen bereiken en de leerlingen daarop te selecteren en niet andersom. De geconstateerde kortsluiting tussen eisen en aanbod is niet alleen een natuurkundeprobleem, ook wiskunde en scheikunde kent een groot aantal onvoldoendes op het eindexamen.
Het is dus een algemeen probleem. Het aspect van het verschoven leerlingbestand mag dus niet onbesproken blijven.
Met stelling zou zijn: Eerst inhoud en niveau vaststellen en dan pas leerlingen toelaten.
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-133.jpg?height=539&width=1278&top_left_y=271&top_left_x=367)

Voorzitter

We zullen nu de mening peilen van de zaak over de verschillende stellingen.

```
Stelling_kramer
Eerst inhoud vaststellen, dan pas leerlingen toelaten.
Mee eens: 60 (aanwezigen) - niet mee eens: 20
Stelling P J.Wippoo
Schoolonderzoek moet hoger gewaardeerd worden.
Mee eens: 70 - niet mee eens: 15
Stelling_U.v.Galen
Eindexamenprogramma moet duidelijker.
Mee eens: 25 - niet mee eens: 25
Stelling_G.Verkerk
20 à 30% ruimte in examenprogramma voor eigen invulling door scholen.
Mee eens: 80 - niet mee eens: 7
Stelling_A.v.d.Valk
In examenprogramma evenwichtige aandacht voor: voorbereiding, kennismaken met
wetenschap, ontplooiing leerling.
Mee eens: 60 (aanwezigen) - niet mee eens: 40
Stelling_H.F.v.Aalst
Het examenprogramma moet worden opgebouwd volgens de schijf van 5.
Mee eens: 80
- niet mee eens: 6.
```

## Evaluatie
s. groothuis, j.weterings, j. kok

In deze evaluatie proberen we indrukken, sfeer en meningen van Woudschotenbezoekers weer te geven. Daarbij baseren we ons op gesprekken die we met ongeveer 70 à 80 personen gehouden hebben.
Eën ding is ons daarbij vooral opgevallen: vanaf vrijdagmiddag zes uur werden juist aan ons enkele duidelijke vragen gesteld: "Heeft Hooymayers ruzie gehad binnen de Werkgroep?", "Gaat het slecht met de gezondheid van Hooymayers?", "En waarom gaat Créton weg?" en "Zo oud is Hooymayers toch ook nog niet?". Het was haast een vast gespreksonderwerp voor ons. Daarnaast werd er nog over andere onderwerpen gepraat zoals lezingen, verslag en werkgroepen. Onze bevindingen geven we hieronder weer.

De lezingen:

1. Ir.G.G.Piepers: 'Proefprojecten van het nationaal ontwikkelingsprogranma windenergie; organisatie en uitvoering'.

Een heldere, gevarieerde lezing, zo was de mening van veel Woudschotendeelnemers, die veel weetjes en feitjes bevatte. Een grote groep vond de informatiedichtheid wat aan de lage kant. Met name de mensen die het onderwerp in de literatuur hadden bijgehouden, hoorden weinig nieuws. De bezadigde manier van spreken maakte het voor veel toehoorders moeilijk de aandacht bij de voordracht te houden. Daarbij gaf een enkeling aan dat dit ook wel eens te maken zou kunnen hebben met het einde van de werkweek en met de lange reis naar Noordwijkerhout. Maar in het algemeen was men toch wel tevreden over deze voordracht.
2. Prof.Dr.G.'t Hooft: 'Elementaire deeItjes en het ijkprincipe'.

Een merkwaardig verschijnsel deed zich voor bij deze lezing. Het merendeel der conferentiegangers gaf volmondig toe dat de inhoud hen grotendeels 'boven 't Hooft' ging. Daar stond tegenover dat bijna iedereen wel gefascineerd heeft zitten luisteren en kijken. De uitstekende presentatie met de fraaie plaatjes werd veelvuldig geprezen. "Het was boeiend om naar te luisteren, maar ik heb er weinig van begrepen" was een veel gehoorde reactie.

De meer ingewijden vonden het geheel zeer interessant en knap aan elkaar geknoopt, al vonden zij het jammer dat de spreker teveel in een uur wilde vertellen zodat hij zijn verhaal niet helemaal kon afmaken. Een aantal deelnemers wilde zich verder verdiepen in deze materie en hoopte in het verslag relevante en geschikte literatuurverwijzingen te vinden.
3. Prof.Dr.S.J.Doorman: 'Natuurkunde, filosofie en onderwijs'.

Als er een applausmeter op de conferentie aanwezig was geweest, dan had Prof. Doorman hoge resultaten geboekt. Ondanks het vroege (zaterdag) ochtend uur en ondanks het late tijdstip voor menigeen de avond ervoor, wist Doorman door zijn boeiende verteltrant de zaal in vervoering te brengen. Veel toehoorders vonden dit een interessante en goed gebrachte lezing. Mocht er iemand door de toevoeging 'hoogleraar in de wijsbegeerte' op het verkeerde been gezet zijn, Doorman hielp hem dan snel uit zijn droom. Na tien minuten waren de eerste, statistische formules al geprojecteerd. Een aantal deelnemers raakte de draad gaandeweg het verhaal kwijt, juist vanwege de veronderstelde voorkennis. Desondanks bleef men geboeid luisteren. Door zijn manier van betogen en door de uitdagende stellingen wist Doorman zijn toehoorders steeds te prikkelen. Sommigen betreurden het wel dat hij zijn laatste stelling over het natuurkundeonderwijs, door tijdgebrek niet kon onderbouwen.

Voor velen gaf deze lezing stof om over na te denken en meerdere malen gaf men aan het juist bij deze lezing jammer gevonden te hebben dat er geen discussie mogelijk was.
4. Prof.Dr.G.W.Barendsen: 'Ioniserende straling, radioactiviteit en hun biologische gevolgen'.

De lezing van Prof. Barendsen vond men goed gebracht. Hij was duidelijk en goed te volgen. Men reageerde op de inhoud van het gebodene minder unaniem. Een aantal deelnemers gaf aan hiervan al op de hoogte te zijn, zodat men weinig nieuws hoorde. Liever had men gezien dat Prof. Barendsen op een aantal details dieper was ingegaan. Anderen vonden dat er binnen de lezing te veel wetenschappelijke feitjes en resultaten werden gegeven, waar men niets mee kon doen. Aan de andere kant waren er deelnemers die zeiden het leuk te vinden dat deze problematiek eens op een rijtje werd gezet. Sommigen zagen daarbij ook mogelijkheden om een en ander te gebruiken in hun lessituatie.
5. Dr.J.Lohstroh: 'Chips wat zit er in en hoe werken ze'.

Ook over de laatste voordracht van 'Woudschoten 1983' was het publiek verdeeld in twee kampen. De kenners vonden het betoog niet opwindend nieuw, al was er waardering voor het geboden overzicht: "Plezierig om alles op een rijtje te krijgen".
De niet-ingewijden in de elektronica waren van mening dat ze teveel specifieke informatie kregen van een te hoog niveau. "Moeilijk" en "Buiten mijn bereik" waren de geluiden uit dit kamp.
Allerwegen was er overigens veel lof voor het prettige tempo en de goede presentatie.

### De Subgroepen

Het zou ondoenlijk en onmogelijk zijn op alle subgroepen apart in te gaan. In het algemeen vond men dat er een leuke sfeer in de subgroep was. In een subgroep was men zelfs zo enthousiast bezig dat de lunch werd overgeslagen. Een aantal keren werd aangegeven dat een subgroep niet zo goed liep of niet informatief was. Dit weet men o.a. aan de grootte van de subgroep of de gekozen werkwijze.
Tijdens de interviews bleek dat de deelnemers diverse en soms tegenstrijdige verwachtingen hadden van een subgroep. He noemen:

- In de subgroepen moet men door kunnen discussiëren over de lezingen, zeker als men geen gelegenheid heeft om vragen te stellen na een lezing.
- In de subgroepen moet men bezig zijn met concretisering naar de praktijk, ze hoeven niet aan te sluiten bij een lezing.
- Subgroepen moeten meer gelegenheid bieden tot contact met andere deelnemers.
- Subgroepen zijn primair om zelf te leren. Er hoeft geen direct nut voor de lespraktijk te zijn.

Men waardeerde in het algemeen de grote keuzemogelijkheid. Verder pleitte een aantal deelnemers ervoor de tijd voor de subgroepen te vergroten ten koste van de lezingen; d.w.z. een extra ronde subgroepen.

### De Markt

In het algemeen werd de markt gezellig, interessant en overzichtelijk genoemd. Een bezwaar vond men wel dat het bedrijfsleven wat sterker vertegenwoordigd was dan de zelfbouwers. Dit laatste - zo vermoedde men - hing samen met de grote drempel die veel deelnemers ervaren om zelf met hun product (schoolonderzoek) op de markt te gaan staan.

Dat de markt toch vele goede tips en ideeën opleverde moge blijken uit de vele verzoeken die wij ontvingen om de adressen van de exposanten in het verslag af te drukken.
Men had wat problemen met het tijdstip waarop de markt open was; op de vrijdagavond sloeg namelijk bij velen de vermoeidheid toe. Zij hadden geen puf meer om uitgebreid te genieten van al het tentoongestelde. Er was op dat moment meer behoefte aan een ontspannende borrel en babbel. Als alternatieve 'markttijd' werd menigmaal de zaterdagmorgen voorgesteld.

### Forumdiscussie

Het laatste onderdeel van de conferentie was het forum over het eindexamen. De discussie kwam langzaam op gang. Toch vonden de aanwezigen de gedachtenuitwisseling zinvol. De stellingen hadden echter wat uitdagender moeten zijn en hadden van te voren op papier toegelicht kunnen worden. Het stemmen en het 'stemmen tellen' werd door velen als onzinnig beschouwd.
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-137.jpg?height=897&width=1299&top_left_y=1551&top_left_x=385)

### Wensen voor een volgende Woudschotenconferentie
Er waren weinig mensen ten aanzien van de opzet van volgende conferenties. In het algemeen zou men wat meer tijd willen hebben voor informele contacten (b.v. bar eerder open en markt naar zaterdag). Veel deelnemers vonden het jammer dat er geen tijd was voor discussie na de lezingen. Als mogelijkheid werd ook geopperd: discussie met een lezinghouder in een subgroep. Sommigen zouden graag meer subgroepen willen bezoeken en dan één à twee lezingen minder. Over de onderwerpen van de laatste Woudschotenconferenties was men zeer tevreden. Het programma van dit jaar had volgens sommigen een grote overlap met de NVON zomer-conferentie.
Suggesties voor onderwerpen van volgende conferenties waren: 'Duidelijkheid over de lijn van het natuurkunde-onderwijs (PLON versus traditioneel, het eindexamen hinkt nu op twee gedachten)', 'Resultaten van de A.R.V.O. II', 'Invulling, normering en opzet van het praktisch schoolonderzoek', 'De micro-computer in de natuurkundeles', 'Het HAVO programma' en 'De consequenties van de huidige onderwijspolitiek voor het natuurkunde-onderwijs'.
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-138.jpg?height=888&width=1273&top_left_y=1724&top_left_x=390)
## de flappen

Op of
Op-of aanmerkingen over tere conferentie maxi ti wetilizy mogelijechediu puct deeiname. en een extra subgroep. Ponding
ONEENS!
IS DIT NU didactIEK?
Het innemen van een realistische positie (Dooman) beverdert het uitbreken van chip-kanker (Lohstroh + Barendsen). is er een straling'stherapie misschien?

Rob van Haren
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-139.jpg?height=122&width=1004&top_left_y=1426&top_left_x=284)
Telkens vöt in werkgroap "nagesprek met lezinghonder"
( 2 eker als er blikkbaar geen tija roor na-ciokussic is)
$\left.\begin{array}{l}\text { * vragenrondes (kort, strak) } \\ \text { * eenzijdige letingan, helaas! }\end{array}\right\}$
Meer tyex rudnef wiw de vucuitet; dornmige weikgroepen (m.n. dic mét sippacitumi) haor de mostet.
$\therefore$ FORUM (?): WEINIG KREATIEVE ONTWIKKELING
ZONDE VAN DE TYD
mee cens idem

Informatie / ecerstof die in een subgroep geprexenteerd wordt moet dain ook verkriggtaar siju

Onderwerpen voon het volgande jaar
Integrarie HAVL Viol buathinue
How eind ex.
(Algemene) Technick III LEZING ONDERWERP RUIMTEVAART (ESTEC-NOORDWYK)
De rob vail de gysicus op eev afderiivg Radio Theraple
Hoc leven laerengen natmerkunde III
![](https://cdn.mathpix.com/cropped/2025_01_29_84bbc6d6c73617495a8ag-140.jpg?height=76&width=607&top_left_y=1122&top_left_x=400)
De filosofische kant van de natuurkunde
Ruinute - onderzock
Commumicatie. I
Houd de lezingen op lit nivecun! prima zo!
Relati examen-programma's - Leerplan en nitvoering!
Sterrekunde $\rightarrow$ zonnestelsel, elementarce deeltjes
$\rightarrow$ Westerbork, kosmologie ent ent

Experimenticu ub husswerk
discussie over landelifk beleid ta.v. leerstof examenprogramma en eventuele ontkoppeling schoolondertwek met di reht betrokhenen van ministerie en commissie


[^0]:    Dr. ir. J. Lohstroh is als coördinator van een halfgeleidergehcugen-ontwerpgroep verhonden aan het Philips Natuurkundig Laboratorium in Eindhoven.

[^1]:    Verkenning
    In 'Natuurkunde aan den lijve' beperken we ons tot de natuurkundige aspecten van het hart, de bloeddruk, het oog en de spierkracht. Bij de uitwerking kozen we voor de volgende opzet.

[^2]:    * De AD/DA-omzetter is leverbaar via Malmberg/Fysica

